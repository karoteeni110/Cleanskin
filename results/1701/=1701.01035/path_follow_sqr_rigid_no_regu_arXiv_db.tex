% \documentstyle[11pt,bezier,]{article}
 \documentclass[11pt,bezier,]{article}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}



\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{subfigure}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{color}

\usepackage[linesnumbered,ruled,]{algorithm2e}
% \usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false,citecolor=blue,linkcolor=blue]{hyperref}


 
 
\topmargin=0.40in
\textheight=8.5in
\textwidth=6.2in
\topmargin=-0.08in
\oddsidemargin=.10in
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}
\renewcommand{\theequation}{\arabic{equation}}
\renewcommand{\baselinestretch}{1.3}    % for double space
\newenvironment{altproof}{\par\noindent{\bf Alternate Proof:}}{\hfill$\Box$\par}
\newcommand{\opprob}{F_p\!\!\mid_{S^*}}
\newcommand{\spX}{{\it X}}

\newcommand{\myBox}{\squareforqed}

% Various defines
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{dfn}{Definition}
\newtheorem{cor}{Corollary}
\newtheorem{prop}{Proposition}
\newenvironment{proof}{\par\noindent{\bf Proof:}}{\hfill$\myBox$\par}
%\newcommand{\beq}{\begin{eqnarray}}
%\newcommand{\eeq}{\end{eqnarray}}
\newcommand{\lin}{{\rm lin}}
\newcommand{\co}{{\rm co}}
\newcommand{\cch}[1]{\overline{\co(#1)}}
\newcommand{\blackhole}[1]{}
\newcommand{\mysup}{\rm sup}
\newcommand{\st}{\;{\rm s.t.\ }}
\newcommand{\ip}[2]{\left\langle#1,#2\right\rangle}
\newcommand{\define}{\stackrel{\rm def}{=}}
\newcommand{\sign}{\rm sign}
\def\binom#1#2{{#1\choose#2}}


\newcommand{\bR}{\bbf R}
\newcommand{\bN}{\bbf N}
\newcommand{\bZ}{\bbf Z}
\newcommand{\bC}{\bbf C}



\newfont{\bbfv}{   msbm5}                      %  5 pt
\newfont{\bbfvi}{  msbm6}                      %  6 pt
\newfont{\bbfvii}{ msbm7}                      %  7 pt
\newfont{\bbfviii}{msbm8}                      %  8 pt
\newfont{\bbfix}{  msbm9}                      %  9 pt
\newfont{\bbfx}{   msbm10}                     % 10 pt
\newfont{\bbfxi}{  msbm10 scaled\magstephalf}  % 11 pt
\newfont{\bbfxii}{ msbm10 scaled\magstep1}     % 12 pt
\newfont{\bbfxiv}{ msbm10 scaled\magstep2}     % 14 pt
\newfont{\bbfxvii}{msbm10 scaled\magstep3}     % 17 pt
\newfont{\bbfxx}{  msbm10 scaled\magstep4}     % 20 pt
\newfont{\bbfxxv}{ msbm10 scaled\magstep5}     % 25 pt


\def\bbf#1{{\relax\rm%\the\fontdimen6\the\font
\ifdim\the\fontdimen6\the\font<7pt         % 5pt font or smaller
 \mbox{\bbfv #1}%
\else\ifdim\the\fontdimen6\the\font<7.6pt  % 6pt font
 \mbox{\bbfvi #1}%
\else\ifdim\the\fontdimen6\the\font<8.25pt % 7pt font
 {\ifmmode\mathchoice{\mbox{\bbfvii #1}}
  {\mbox{\bbfvii #1}}{\mbox{\bbfvi #1}}
  {\mbox{\bbfv #1}}\else{\bbfvii #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<8.85pt % 8pt font
 {\ifmmode\mathchoice{\mbox{\bbfviii #1}}
  {\mbox{\bbfviii #1}}{\mbox{\bbfvi #1}}
  {\mbox{\bbfv #1}}\else{\bbfviii #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<9.7pt  % 9pt font
 {\ifmmode\mathchoice{\mbox{\bbfix #1}}
  {\mbox{\bbfix #1}}{\mbox{\bbfvi #1}}
  {\mbox{\bbfv #1}}\else{\bbfix #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<10.5pt % 10pt font
 {\ifmmode\mathchoice{\mbox{\bbfx #1}}
  {\mbox{\bbfx #1}}{\mbox{\bbfvii #1}}
  {\mbox{\bbfv #1}}\else{\bbfx #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<11.4pt % 11pt font
 {\ifmmode\mathchoice{\mbox{\bbfxi #1}}
  {\mbox{\bbfxi #1}}{\mbox{\bbfviii #1}}
  {\mbox{\bbfvi #1}}\else{\bbfxi #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<13pt   % 12pt font
 {\ifmmode\mathchoice{\mbox{\bbfxii #1}}
  {\mbox{\bbfxii #1}}{\mbox{\bbfviii #1}}
  {\mbox{\bbfvi #1}}\else{\bbfxii #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<15pt   % 14pt font
 {\ifmmode\mathchoice{\mbox{\bbfxiv #1}}
  {\mbox{\bbfxiv #1}}{\mbox{\bbfx #1}}
  {\mbox{\bbfvii #1}}\else{\bbfxiv #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<18pt   % 17pt font
 {\ifmmode\mathchoice{\mbox{\bbfxvii #1}}
  {\mbox{\bbfxvii #1}}{\mbox{\bbfxii #1}}
  {\mbox{\bbfx #1}}\else{\bbfxvii #1}\fi}%
\else\ifdim\the\fontdimen6\the\font<23pt   % 20pt font
 {\ifmmode\mathchoice{\mbox{\bbfxx #1}}
  {\mbox{\bbfxx #1}}{\mbox{\bbfxiv #1}}
  {\mbox{\bbfxii #1}}\else{\bbfxx #1}\fi}%
\else                                      % 25pt or larger
 {\ifmmode\mathchoice{\mbox{\bbfxxv #1}}
  {\mbox{\bbfxxv #1}}{\mbox{\bbfxx #1}}
  {\mbox{\bbfxvii #1}}\else{\bbfxxv #1}\fi}%
\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi}}


% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{amsfonts}
% \usepackage{mathrsfs}
% \usepackage{subfigure}
% \usepackage{epsfig}
% \usepackage{graphicx}
% \usepackage{color}
% 
% \usepackage[linesnumbered,ruled,]{algorithm2e}

\setcounter{page}{1}

\begin{document}

\title{\Large\bf 
Path-following based Point Matching  using Similarity Transformation} 

\date{}

\author{\begin{tabular}[t]{c@{\extracolsep{4em}}c@{\extracolsep{4em}}c} 
 Wei Lian \\ \\
Dept. of Computer Science,
Changzhi University   \\
Changzhi, Shanxi, P.R. China, 046031  \\
E-mail: lianwei3@foxmail.com 
\end{tabular}}


\maketitle

%\bibliographystyle{plain}

%I don't know why I have to reset thispagestyle, but otherwise get page numbers 
\thispagestyle{empty}
\subsection*{\centering Abstract}
%IEEE allows italicized abstract
{\em To address the problem of 3D point matching 
where the poses of two point sets are unknown,
we adapt a recently proposed path following based method to use similarity transformation
instead of the original affine transformation.
The reduced number of transformation parameters leads to 
more constrained and desirable matching results.
% much better robustness to disturbances.
% in the case of 3D matching .
Experimental results  demonstrate  better robustness of the proposed method over
% over the previous method.
 state-of-the-art methods.}








\section{Introduction}

Point matching %where the poses of two point sets are unknown
is a  challenging  problem with applications in 
computer vision and pattern recognition. 
% Disturbances such as non-rigid deformation, positional noise,
% outliers and occlusion often makes this problem difficult.
% To address this problem,
% se difficulties,
% different approaches have been proposed.
% which can be classified based on whether point correspondence and / or spatial transformation is explicitly modeled.
% \begin{inparaenum}[\bfseries\upshape 1\upshape)]
% \item 
% % There are methods which only  modeling point correspondence:
% Point matching can be posed as a  graph matching problem.
% The integer projected fixed point method \cite{GM_IPFP} optimizes a quadratic
% objective by  gradient descent interleaved with projection onto discrete constraint set.
% The reweighted random walk method \cite{GM_RRWM} manages 
% the reweighting jumps to  enforce the matching constraints.
% The max pooling matching method \cite{GM_maxPool} 
% tweaks the power method %by using maximization operation 
% to better cope with  outliers.
% % State-of-the-art graph matching methods include
% % the spectral method \cite{GM_spectral},
% % the integer projected fixed-point method \cite{GM_IPFP}
% % and the reweighted random walk method \cite{GM_RRWM}.
% As the above methods only consider pairwise affinities between point correspondences,
% they are unable to cope with salient non-rigid deformations such as scaling and shear.
% To address this issue,
% methods based on tensor have been proposed \cite{GM_tensor,GM_tensor_block}.
% But the use of tensor causes these methods to have a  high demand for memory.
% % Among different types of graph matching methods,
% What's related to our algorithm are 
% those methods based on the path following (PF) strategy  \cite{GM_path_follow}, % are more closely related to our algorithm,
% % where
% which works by constructing an interpolation function 
% % is constructed
% between a concave and a convex function
% and
% gradually transitioning from the convex function to the concave function
% % dynamically changing the weights of the two terms 
% so as to avoid being trapped in local minima.
% Quadratic polynomial is used to construct the concave function in \cite{GM_PF_quadratic2}
% and extended to  construct both the convex and concave functions  in~\cite{GM_PF_quadratic}.
% To address this problem,
% different methods have been proposed.
% Point matching can be accomplished via matching distributions.
% % viewing point set as a result of sampling from a distribution.
% % Among them,
% The coherent point drift (CPD) method \cite{CPD} poses point matching 
% as fitting a Gaussian mixture model (GMM) representing one point set to another point set.
% The GMM based registration (gmmreg) method \cite{kernel_Gaussian_journal} uses two GMMs to model two point sets
% and the $l_2$ distance between them is minimized.
% Instead of directly aligning two distributions representing two point sets,
% the moments of distributions were matched in~\cite{algebraic_moment}.
% % which results in a system of polynomial equations.
% % which can  be solved by algebraic geometric techniques.
% %
% % The method is rotation invariant.
% But the method is  sensitive to occlusion and outliers due to  use of moments.
% Recently,
% the kernel mixture model, an extension of GMM model,
% was used to construct tensor fields in \cite{mixture_tensor}
% where high level information was utilized to improve matching performance.
% Point matching can be accomplished by solving for both point correspondence and spatial transformation.
% The iterative closest point (ICP) algorithm \cite{ICP,ICP2} alternates between 
% recovering point correspondence %based on transformation 
% and updating transformation. %based on point correspondence.
% But the optimization process of ICP is unstable 
% % prone to being trapped in local minima 
% due to the discrete nature of point correspondence.
To solve this problem,
the robust point matching (RPM) algorithm \cite{RPM_TPS} 
% is a popular matching algorithm
% where  
% soft assign and 
% relaxes point correspondence to be fuzzily valued and
uses deterministic annealing for optimization.
But it needs regularization to avoid  undesirable matching results and
has the tendency of aligning the mass centers of two point sets.
To address this issue,
Lian and Zhang reduced
the objective function of RPM to a  concave function of the point correspondence variable
and  used the branch-and-bound (BnB) algorithm for optimization  \cite{RPM_concave,RPM_model_occlude}.
% the objective function of RPM is globally minimized 
% by  eliminating the transformation variable 
% and using the branch-and-bound (BnB) algorithm for optimization
These methods are  more  robust, % than RPM, 
but their  worse case time complexity is  exponential  due to use of BnB.
% Besides, 
% the number of correct matches needs to be known a priori in \cite{RPM_model_occlude},
% which is quite restrictive in practice.
To address this issue,
Lian used the path following (PF) strategy \cite{GM_PF_quadratic} to optimize the objective function of \cite{RPM_model_occlude}
% of RPM
% via appending 
by adding a convex quadratic term to the objective function and dynamically changing the weights of the  terms
\cite{RPM_PF_aff}.
% This method has both good robustness and computational efficiency.


% \end{inparaenum}
But
in the case of 3D matching, 
the method of \cite{RPM_PF_aff} is experimentally shown to only perform well when the transformation is regularized,
% in which case, 
while there are problems where the poses of two point sets are unknown 
which call for matching methods where the transformations are not regularized.
The reason 
that the method of \cite{RPM_PF_aff} performs poorly 
% when the transformation is not regularized
is that it uses  affine transformation
% in case of 3D matching
which has large number of parameters,
thus resulting in high degree of transformation freedom and unconstrained matching results.
To address this issue, 
we modify  the method to use similarity transformation
whose number of parameters is considerably smaller. %than that of affine transformation.
% thus the matching results are more constrained and desirable. % than when using the affine transformation.
%  Due to  nonlinearity of 3D similarity transformation,
% % it  is a nontrivial task to extend
% this is a nontrivial extension of
% the method of \cite{RPM_PF_aff} to the case of  similarity transformation.
% To improve the convergence speed of the adopted path following optimization algorithm,
% we further 

% Based on the fact that 
% our objective function can be reduced to a function of few variables,
% % of the RPM objective function (as a function of only point correspondence)
% % is  of low rank,
% we further propose a novel low rank convex quadratic term  for use in the PF algorithm.
% Compared with the generic convex quadratic  term used in \cite{RPM_PF_aff},
% our convex term is  based on data  and leads to a PF algorithm 
% which converges faster.
 
% In summary, we made the following two-folds contributions in this paper:
% \begin{enumerate}
%  \item We 
% %  propose a similarity transformation based point matching algorithm
% adapt the method of \cite{RPM_PF_aff} to use  similarity transformation
% %  The smaller number of transformation parameters leads to 
% % so as to achieve 
% which results in much better robustness
% % for the 3D matching problems.
% % which has  better robustness %than using affine transformation
% %  to disturbances 
% in the case of 3D matching.
% % as compared with the method of \cite{RPM_PF_aff}.
%  \item 
% We propose a novel low rank convex quadratic term
% for use in the PF algorithm 
% which leads to improved convergence property.
% % with results in better algorithm convergence.
% % quadratic convex term is proposed for use in the .
% 
%  \end{enumerate}


 
%  \section{Related work}
 

 

\section{
The RPM objective function
\label{sec:RPM}
}


Suppose we are to match
% there are 
two point sets   
% model set 
\scalebox{1.}{$\mathscr X = \{x_i , 1\le i\le m\}$}
and 
%  scene set 
$\mathscr Y = \{y_j , 1\le j\le n\}$ in $\mathbb R^d$.
For this problem, 
RPM uses the following
% models point matching as 
 mixed linear assignment$-$least square model:
% The regularization term in our objective function comes from the sum of
% squared Euclidean distances between the matched points:
% simplified objective function of
% the RPM algorithm \cite{RPM_TPS},
% which has the following form:
\begin{align}
&\min\ \Phi(P, s,R, t){=}
\sum_{i,j}p_{ij}\| { y}_j-sR  x_i {-}  t\|^2 %\notag\\
% &+\gamma g(s,R)
-\mu 1_m^\top P1_n \notag\\
 &\quad= 1_m^\top P  {\widetilde y} + s^2 {\widetilde x}^\top P  1_n 
 - 2s\cdot \text{tr}(R X^\top P Y )
 + 1_m^\top P1_n \|  t\|^2  
   \notag \\
&\qquad -2  t^\top (Y^\top P^\top  1_m   - s R X^\top P   1_n)  
-\mu 1_m^\top P1_n  \label{E_lin_tr} \\
 &s.t.\ \  P 1_n\le1_m, \quad 1_m^\top P\le 1_n,   
%  \ 1_m^\top P 1_n\ge k, 
 \quad P\ge 0, \label{inequal_assign_const} \\
&\ \qquad \underline{s}\le s \le \overline{s} \label{s_range}
\end{align}
Here we use
% restrict the type of transformation to be 
similarity transformation
with $R$, $s$ and $t$ being rotation matrix,
scale change and translation vector. %, respectively.
The constants $\underline{s}\ge 0$ and $\overline{s}\ge0$ are lower and upper  bounds of $s$.
The matching matrix $P=\{p_{ij}\}$ has   $p_{ij}=1$
if two points $i$, $j$ are matched and $0$  otherwise.
The last term in $\Phi$ is used to regularize the number of correct matches %between the two sets
with $\mu$ being the balancing weight.
$\|\cdot\|$ is  the $l_2$  norm of a vector
and tr() denotes the trace of a square matrix.
$1_n$ represents the $n$-dimensional vector of all ones.
% In this work,
% we choose the regularization on transformation as
% $
% g(s,R)=\|sR-s_0R_0\|_F^2 -ds_0^2 =  ds^2 - 2ss_0 \text{tr}(R^\top R_0)
% $, i.e.,
% rotation and scale change should be close to the predefined constant matrix $R_0$ and scalar $s_0$,
% where $\|\|_F$ denotes the Frobenius norm of a matrix
% and $\text{tr}$ denotes the trace of a square matrix.
% Taking into account the form of $g$ and by derivation,
The matrices
$X\triangleq\begin{bmatrix}
    x_{1}, \dots,  x_{m}
  \end{bmatrix}^\top$,
$Y\triangleq\begin{bmatrix}
    y_{1}, \dots,  y_{n}
  \end{bmatrix}^\top$
and vectors    $ {\widetilde x}\triangleq \begin{bmatrix}
   \| x_1\|^2, \dots, \| x_{m}\|^2
  \end{bmatrix}^\top$,
$ {\widetilde y}\triangleq \begin{bmatrix}
   \| y_1\|^2, \dots, \| y_{n}\|^2
  \end{bmatrix}^\top$.
% $ 1_n$ denotes an $n$-dimensional vector of all $1$s.
% $I_d$ denotes the $d$-dimensional identity matrix and $\otimes$ denotes the Kronecker product.
% $\text{tr}(\cdot)$ denotes the trace of a matrix.


% From Eq. \eqref{E_lin_tr},
It's easily seen  that given the values of $P$, $s$ and $R$,
$\Phi$ is a convex quadratic function of $t$.
% (regardless of the  values of other variables). 
Hence,
the optimal   $t$  minimizing $\Phi$ can be obtained via  $\frac{\partial \Phi}{\partial { t}}=0$ to be
\scalebox{1.1}{
$
\widehat { t}
%  \frac{1}{s}(\sum p_{ij} { y}_j - \sum p_{ij} J_i {\theta})\\
 =
  \frac{1}{1_m^\top P1_n }( Y^\top P^\top  1_m  -  s R X^\top P  1_n)
$}.
Substituting  $\widehat { t}$  into $\Phi$ to eliminate $ t$ yields
an energy function with reduced number of variables: % $P$, $s$ and $R$:
\begin{align}
&\Phi(P,s,R)=
 1_m^\top P  {\widetilde y} -\mu 1_m^\top P 1_n - \frac{1}{1_m^\top P1_n} \|Y^\top P^\top  1_m\|^2  \notag\\
&+ s^2 ( {\widetilde x}^\top P  1_n   - \frac{1}{1_m^\top P1_n}    \| X^\top P  1_n\|^2 )  \notag\\
&- 2s\cdot\text{tr}(R ( X^\top P Y - \frac{1}{1_m^\top P1_n} X^\top P 1_n 1_m^\top PY ))  \label{E_P_s_R}
\end{align}

\section{Optimal $s,R$ minimizing $\Phi(P,s,R)$ \label{optimal_s_R}}
Let matrix
\[
 A\triangleq   
  X^\top P Y - \frac{1}{1_m^\top P1_n} X^\top P 1_n 1_m^\top PY 
\]
and let $USV^\top$ be the singular value decomposition of $A^\top$,
where $S$ is a diagonal matrix and
the columns of  $U$ and $V$ are orthogonal unity vectors.
Then given $s> 0$, 
the optimal rotation matrix  $R$ minimizing $\Phi$ in   \eqref{E_P_s_R} is
$\widehat R=U\text{diag}(\begin{bmatrix}
                     1,\ldots,1,\det(UV^\top)
                    \end{bmatrix})V^\top$ \cite{CPD},
where $\text{diag}(\cdot)$ denotes converting a vector into a diagonal matrix
and $\det(\cdot)$ is the determinant of a square matrix.
Substituting $\widehat R$  into \eqref{E_P_s_R} to eliminate $R$ 
% is eliminated and
% With $R$ solved, 
% \eqref{value_E_v} becomes
yields  a (possibly concave) quadratic program in single variable $s$.
Given the range of $s$ as $\underline{s}\le s \le \overline{s}$,
one can easily solve  this  quadratic program 
by comparing the function values at the boundary points $\underline{s}$, $\overline{s}$ and 
the extreme  point.
% to obtain  the optimal $s$.

\section{An objective function in one variable $P$
% Concave form of the RPM objective function 
\label{sec:regularize}}


We aim to obtain an objective function only in one variable $P$,
which can be achieved by minimizing $\Phi$ with respect to $s$ and $R$, i.e.:
% The result is 
\begin{align}
& \Phi(P)\triangleq\min_{s,R}  \Phi(P,s,R) 
% = 1_m^\top P { \widetilde y} -\mu 1^\topP 1_n - \frac{1}{1^\topP1} \|Y^\top P^\top  1\|^2  \notag\\
% & + \min_{s,R} \{s^2 ( {\widetilde x}^\top P  1   - \frac{1}{1^\topP1}    \| X^\top P  1\|^2 + \gamma d)  \notag\\
% & - 2s\cdot\text{tr}(R ( X^\top P Y - \frac{1}{1^\topP1} X^\topP 1_n 1^\topPY + \gamma s_0 R_0^\top)) \}
\label{E_P}
\end{align}

% By substituting $\widehat\theta$ back into the objective function $\Phi(P,\theta)$, 
% $\theta$ is eliminated and we get our regularization term as:
% \begin{gather}
%  \Phi(P) = 
% %  \text{trace}(C^\topP)+ 
%   1_m^\top P z     \notag\\
%  -   y^\top (P\otimes I_d)^\top J   
%  [J^\top (\text{diag}(P   1_n) \otimes I_d) J]^{-1} 
%  J^\top (P\otimes I_d) y  %\notag\\
% \end{gather}
% Here vector $ z\triangleq \begin{bmatrix}
%    \| y_1\|^2, \dots, \| y_n\|^2
%   \end{bmatrix}^\top$.
  
For $\Phi(P)$, 
the following results can be established:

\begin{proposition} \label{Prop_one}
$\Phi(P)$ is  concave under constraints \eqref{s_range}. 
% \eqref{inequal_assign_const} and
\end{proposition}

{\proof
Based on the aforementioned derivation, % of the energy function,
we have $\Phi(P,s,R )=\min_{{ t}} \Phi (P,s,R,{ t})$.
Consequently, we have  
\[\Phi(P)=\min_{s,R} \Phi(P,s,R)=
\min_{s,R,{ t}} \Phi(P,s,R,{ t})\]
For each $s$, $R$ and ${ t}$, 
$\Phi(P,s,R,{ t})$ is apparently  a linear function of $P$.
We see that $\Phi(P)$ is the point-wise minimum of a family
of linear functions,
% (with ${\theta},{ t}$ as the family parameters),
and thus is concave, as illustrated in Fig. \ref{linear_min}.
}



\begin{figure}[h]
\centering
 \includegraphics[width=0.5\linewidth]{piecewise_concave3-1.mps}  %piecewise_concave-0.mps
 \caption{ 
Point-wise minimization of a family of linear functions $\Phi(P,s,R,t)$ (dashed  straight lines)
with respect to parameters $s$, $R$ and $t$ results in a concave function (solid piecewise straight line).
\label{linear_min}
}
\end{figure}

The fact that $\Phi(P)$ is concave makes it easier for 
the PF algorithm to be applied to the minimization of our objective function
as it requires two terms, a concave and a convex term, to be provided.


\begin{proposition}
There exists an integer solution for any local minima (including the global minimum) of function
$\Phi(P)$ under constraints \eqref{inequal_assign_const} and \eqref{s_range}.
\end{proposition}

{\proof
The polytope formed by  constraint \eqref{inequal_assign_const}
satisfies the total unimodularity property \cite{book_comb_optimize},
which means that the coordinates of the vertices of this polytope are integer valued.
We already proved that $\Phi(P)$ is concave under constraints 
% \eqref{inequal_assign_const} and 
\eqref{s_range}. 
It is well known that any local minima 
(including the global minimum)
of a concave function over a polytope can be obtained at one of its vertices.
Thus, the proposition follows.


% We already proved that $\Phi(P)$ is concave. % under constraint \eqref{k_card_P_const}.
%  It's well known that the minimum solution of a concave
% function over a polytope can be taken at one of its vertices.
% The proposition follows by combining this result with the
% total unimodularity of  constraint \eqref{inequal_assign_const} as stated previously.
}


This result implies that minimization of $\Phi(P)$ 
by simplex-like algorithms results in integer valued solution.
This is important  as it avoids the need of discretizing solutions
which can cause error
and poor performance 
\cite{LP_edge}. %,LP_similarity,LP_embedding}.


% This proposition shows that any simplex-like local optimization algorithm for
% $\Phi(P)$ will yield integer valued solutions.
% In contrast, 
% the regularization terms in 
% don't satisfy  this property 
% and need  complicated successive convexification procedure  to
% gradually recover a binary solution.

To facilitate optimization of $\Phi$, %the objective function, % in the PF algorithm,
we needs to convert  $P$  into a vector.
We define the vectorization of a matrix as the concatenation of its rows
\footnote{This is different from the conventional definition.},
denoted by $\text{vec}()$.
Let $p\triangleq\text{vec}(P)$.
To get the form of $\Phi$ in terms of vector $p$,
new denotations are needed.
Let
\begin{gather}
 \text{vec}(X^\top PY)\triangleq B  p,\
 X^\top P 1_n\triangleq C  p, \
 Y^\top P^\top  1_m\triangleq D p,    \notag\\ 
  {\widetilde x}^\top P  1_n\triangleq   a^\top  p, \quad
 1_m^\top P \widetilde Y \triangleq b^\top p  \notag
\end{gather}
Based on the fact $\text{vec}(M_1 M_2 M_3)= (M_1\otimes M_3^\top)\text{vec}(M_2)$ for any matrices  $M_1$, $M_2$ and $M_3$,
we have matrices
% \begin{gather}
$
B=X^\top\otimes Y^\top,\ C=X^\top\otimes  1_n^\top,\ D= 1_m^\top\otimes Y^\top  \notag
$
% \end{gather}
 and vectors
% \begin{gather}
\scalebox{1.1}{
$
  a= {\widetilde x} \otimes  1_n,\
b=1_m \otimes \widetilde y  \notag
$}.
% \end{gather}
Here $\otimes$ denotes the Kronecker product.
With the above preparation, 
$\Phi(P)$  can be written in terms of vector $ p$ as
\begin{align}
\Phi( p)=&  
(b-\mu 1_{mn})^\top   p  - \frac{1}{1_{mn}^\top p} \|D  p \|^2  %\notag\\
 + \min_{s,R} \{s^2 ( a^\top  p    - \frac{1}{1_{mn}^\top p}    \| C  p \|^2 )  \notag\\
&- 2s\cdot \text{tr}(R [ \text{mat} (B p)  - \frac{1}{1_{mn}^\top p} C p  p^\top D^\top ]) \} \label{phi_p}
\end{align}
where $\text{mat}()$ denotes converting a vector into a matrix,
which can be seen as  inverse of the operator  $\text{vec}()$.

To facilitate  optimization of $\Phi$, %the objective function, % by the PF algorithm,
we need to get  the formula of the gradient of $\Phi$. 
% $\frac{\partial \Phi}{\partial p}$.
% Since $\Phi$ is concave, 
As  $\Phi$ involves minimization operations, %w.r.t. $s$ and $R$,
it's difficult to directly derive the formula of \scalebox{1.}{$\frac{\partial \Phi}{\partial p}$}.
To address this issue,
we appeal to the result of Danskin's theorem \cite{cov_analysis} (page 245 therein), 
which in our case states that if $\Phi(p,s,R)$ is concave in $p$ for each $s$ and $R$
(this can be proved  analogously as the proof of Proposition \ref{Prop_one})
and the feasible regions of $s$ and $R$ are compact,
% (which is apparently satisfied),
then 
\scalebox{1.1}{
$\Phi(p)= \min_{s,R} \Phi(p, s, R)$}
has gradient:
% then the gradient of $\Phi(p)$  is
\begin{align}
&\frac{\partial\Phi(p)}{\partial p}= \frac{\partial\Phi(p,\widehat s,\widehat r)}{\partial p}=         % \notag\\
b -\mu 1_{mn} 
-\frac{2}{1_{mn}^\top p} D^\top D p    \notag\\
&+\frac{\|Dp\|^2 }{(1_{mn}^\top p)^2}1_{mn} 
+  \widehat s^2 ( a    - \frac{2}{1_{mn}^\top p}   C^\top C  p  + \frac{1}{(1_{mn}^\top p)^2}    \| C  p \|^2 1_{mn})  \notag\\
&- 2\widehat s \{ B^\top \widehat r  -  \frac{1}{1_{mn}^\top p}  [D^\top (p^\top C^\top  \otimes I_d) + C^\top(I_d\otimes p^\top D^\top) ] \widehat r \notag\\
&+ \frac{1}{(1_{mn}^\top p)^2} \text{tr}( \widehat R  C p  p^\top D^\top ) 1_{mn} 
\}  \label{gradient_exp}
\end{align}
where  $\widehat s$ and $\widehat R$ 
% minimize $\Phi(p,s,R)$, i.e., 
satisfy
\scalebox{1.1}{
$
\Phi(p,\widehat s,\widehat R)= \min_{s,R} \Phi(p, s, R)
$}.
% $\widehat s$ and $\widehat R$ can be obtained by 
The optimal $\widehat s$ and $\widehat R$ can be obtained by the method described previously. % in Sec. \ref{optimal_s_R}.
Here the vector $\widehat r\triangleq\text{vec}(\widehat R^\top)$ and
$I_{d}$ denotes the $d\times d$ identity matrix.



% 
\section{PF based optimization\label{sec:optimize}}
% Since $\Phi$ is concave,
% minimizing $\Phi$ using local optimization strategies  such as gradient descent 
% % tends to yield   undesirable locally minimum solutions.
% % far from the globally minimum solution.
% is prone to being trapped in local minima.
% To address this issue,
% analogous to the practice of \cite{RPM_PF_aff},
The PF algorithm \cite{GM_PF_quadratic} is used to optimize $\Phi$
 by constructing an interpolation function 
between a convex  function $\|p\|^2$ and the concave function $\Phi$,
% The idea of PF based optimization is to construct a new function
\[
 E_\lambda=(1-\lambda)\|p\|^2 +\lambda \Phi(p)
\]
and gradually increasing $\lambda$ from $0$ to $1$ so that
$E_\lambda$ gradually transitions from the convex function $\|p\|^2$ to the concave function $\Phi$.
With each value of $\lambda$, $E_\lambda$ is locally minimized.
We refer the reader to \cite{RPM_PF_aff} for detail.

% In this way,
% PF largely avoids the pitfall  of being trapped in local minimum.
% 
% Instead of using $\|p\|^2$ as the  convex term as in \cite{RPM_PF_aff},
% better alternative can be explored based on the low-rank nature of $\Phi(p)$:
% Note that if we let
% \[F=\begin{bmatrix} 
% 1_{mn} & a & D^\top & C^\top & B^\top  
% \end{bmatrix},\]
% and let the QR factorization of $F$ be $Q R=F$,
% where the columns of $Q$ are orthogonal unity vectors
% and $R$ is an upper triangular matrix,
% % $Q^\top Q=I$.
% % b-\mu 1_{mn} &
% then the nonlinear part  of  $\Phi(p)$ is completely  determined by the low dimensional variable
% $
% u\triangleq R^{-\top} F^\top p =Q^\top p
% $.
% More specifically,
% the nonlinear part of $\Phi$ can be written as a function of $u$:
% \begin{align}
% &\Phi_\text{nonlinear}(u) =
% % (b-\mu 1_{mn})^\top   p  
% - \frac{1}{(R^\top u)_1} \|(R^\top u)_D \|^2    \notag\\
% & + \min_{s,R} \{s^2 ((R^\top u)_a    - \frac{1}{(R^\top u)_1}    \| (R^\top u)_C \|^2 )  \notag\\
% &- 2s\cdot \text{tr}(R [ \text{mat} ((R^\top u)_B)  - \frac{1}{(R^\top u)_1} (R^\top u)_C  (R^\top u)_D^\top  ]) \} \label{phi_p}
% \end{align}
% where $(R^\top u)_{D}$ denotes the subvector of $R^\top u$
% with  indices  equal to the column indices of the submatrix $D^\top$ in matrix $F$.
% % $\begin{bmatrix}
% % 1_{mn} & a & D^\top & C^\top & B^\top  
% %   \end{bmatrix}^\top$.
% Vectors $(R^\top u)_{1}$,
% $(R^\top u)_{a}$, $(R^\top u)_{C}$ and $(R^\top u)_{B}$ are similarly  defined. 
% % Let the QR factorization of $F$ be $Q R=F$
% % with $Q$ satisfying $Q^\top Q=I$.
% % are mutually  orthogonal unity vectors.
% % Then, in turn,
% % the nonlinear part of $\Phi$ is  determined by $Q^\top p$.
% % Then  instead of using $\|p\|^2$ as the convex term,
% Therefore,
% we can use $\|u\|^2=\|Q^Tp\|^2$ as the convex term of $E_\lambda$
% which guarantees that $E_\lambda$ is convex when $\lambda$ is sufficiently small.
% With this choice,
% function $E_\lambda$ takes the following form:
% \begin{gather}\label{E_lambda}
%  E_\lambda( p)=  (1-\lambda) \|Q^\top p\|^2 + \lambda\Phi( p) 
% \end{gather}
% % Compared with $\|p\|^2$, 
% Since  $\|Q^Tp\|^2\le \|p\|^2$
% (due to low rank of $Q$, $\|Q^Tp\|^2$ is in practice much smaller than $\|p\|^2$),
% % Therefore,
% the interpolation function $E_\lambda$ using $\|Q^Tp\|^2$ as the convex term will be more close to  $\Phi$ 
% than when using $\|p\|^2$ as the convex term.
% This leads to a PF algorithm that  converges faster.
% 
% 
% 
% 
% % Directly minimizing $\Phi$ via simple strategies such as gradient descent is impractical
% % since $\Phi$ is  concave 
% % and such strategies can easily be trapped in local minimum.
% % Following \cite{RPM_PF_aff},
% % % Instead,
% % we adopt the path following (PF) strategy of \cite{GM_PF_quadratic}
% % by constructing a new objective function as the interpolation between 
% % the concave geometric matching cost $\Phi(p)$ as presented previously
% % and
% % a convex quadratic term $\|p\|^2$ used to enforce the fuzziness of point correspondence:
% % 
% % where the parameter $\lambda$ is used to balance the weights of the two terms.
% 
% % The PF strategy then proceeds  by gradually
% % transitioning from the state that there is only weight of the convex term to
% % the state that there is only weight of the concave term.
% % This is accomplished by gradually increasing the value of $\lambda$ from $0$ to $1$.
% % Initially,
% % the objective function is convex.
% % Since a convex function can be easily globally optimized,
% % PF thus largely avoids the %pitfall
% % tendency of being trapped in local minimum.
% % % of naive optimization strategies such as  gradient descent.
% 
% Following \cite{RPM_PF_aff},
% for each $\lambda$,
% $E_\lambda$ is minimized by the Frank-Wolfe (FW) algorithm,
% % As for the sub-problem of minimizing $E_\lambda$ given a $\lambda$,
% % since $E_\lambda$ is generally nonconvex
% % and we know  that finding the global minimum  of a nonconvex function is generally  NP-hard. % problem.
% % Hence, instead of using global optimization algorithms,
% % we use the Frank-Wolfe (FW) algorithm, an efficient local search algorithm,
% % to minimize $E_\lambda$.
% which works by first determining a local search direction and then searching along this direction.
% The local search direction is determined by minimizing the first order Taylor expansion of $E_\lambda$ subject to the constraint \eqref{inequal_assign_const}.
% After removing constant terms which have no effect on optimization,
% we get the following equivalent optimization problem:
% \begin{gather}
% \min_q \quad [\nabla E_\lambda(p)] ^\top q %\notag\\
% ,\quad s.t. \quad \text{constraint}\ \eqref{inequal_assign_const} \label{grad_descent}
% \end{gather}
% This is a linear assignment problem with inequality constraints, % \cite{book_assign},
% which can be solved by  the scheme described in \cite{RPM_PF_aff}.
% % which can be converted into a standard equality constrained version
% % by adding $n$ dummy rows and $m$ dummy columns of zeros to the cost matrix.
% % The resulting problem can then be  efficiently solved by the Jonker and Volgenant algorithm~\cite{LAPJV}.
% 
% 
% Let the optimal solution of problem \eqref{grad_descent} be $q$,
% then the second step of FW involves searching along the search direction $q-p$.
% This problem  can be formulated as
% \begin{gather}
% \min_\alpha \quad E_\lambda(p + \alpha (q-p) ) %\notag\\
% ,\quad s.t. \quad 0\le \alpha \le 1 \label{line_search}
% \end{gather}
% This is a single variable optimization problem
% which can be solved by algorithms such as golden section search.
% In this paper, the Matlab function 'fminbnd' with default setting is used to accomplish this task. 
% % But we empirically found that our algorithm without the line search step performs 
% % similar to our algorithm with the line search step but with  computational speedup.
% % Therefore, this step is omitted in our algorithm.
% 
% 
% 
% The entire algorithm is summarized in Algorithm \ref{alg_PF},
% % where we note that $p=0$ is the globally minimum solution to $E_0$.
% % Therefore $\lambda$ can be initially set as $d\lambda$ instead of $0$.
% where the gradient of $E_\lambda$ can be easily derived as: % having the following form:
% \[\nabla E_\lambda (p)=(1-\lambda)2Q Q^\top p + \lambda \nabla \Phi(p)\]
% where the formula of $\nabla \Phi$  is presented in Eq. \eqref{gradient_exp}.
% \begin{algorithm}
% % $p=0$
% 
% $\lambda= 0$; 
% 
% \textbf{while} $\lambda\le1$  
% 
% $\quad$\textbf{while} $p$ not converged and number of iteration $\le l$, \textbf{do} %$\qquad$ // FW algorithm
% 
% $\qquad$ $q=\arg\min_q [\nabla E_\lambda(p)]^\top q$,\ s.t.\ $q\in$ constraint\ \eqref{inequal_assign_const};
% 
% $\qquad$  obtain $\alpha$ via line search \eqref{line_search};
% 
% $\qquad$ $p\leftarrow p+\alpha  (q-p)$;
% 
% $\quad$\textbf{end while}
% 
% $\quad$ $\lambda\leftarrow\lambda +d\lambda$;
% 
% \textbf{end while}
% 
% \textbf{return} $p$
% 
% \caption{A PF algorithm for point matching \label{alg_PF}}
% \end{algorithm}

% \section{Complexity analysis}
% In each iteration of  Algorithm  \ref{alg_PF},
% the linear assignment problem \eqref{grad_descent} needs to be solved, 
% which has  $O(m^3)$ complexity  \cite{LAPJV}
% (For  sake of simplicity, here we assume $m=n$).
% Assume the inner loop of Algorithm \ref{alg_PF}  iterates $l$ times,
% then the total complexity is $O(\frac{1}{d\lambda}lm^3)$.













\section{Experimental results}
We compare our method with state-of-the-art methods including
RPM-PF~\cite{RPM_PF_aff}, RPM~\cite{RPM_TPS}, 
Go-ICP~\cite{Go_ICP}, CPD~\cite{CPD} and gmmreg~\cite{kernel_Gaussian_journal}.
% These methods represent state-of-the-art and
% one of them (Go-ICP) is also globally optimal,
% making them good candidates for comparison.
To ensure fairness, for RPM-PF,
transformation is not regularized.
% Affine transformation is adopted by RPM-PF, CPD and gmmreg,
% and the thin plate spline transformation is adopted by RPM.
We implement all the  methods in MATLAB on a
PC with a 3.3 GHz CPU and 16 G RAM. For methods only
outputting point correspondence, affine transformation is used
to warp the model point set. For our method, we set parameters
$\underline{s}=0.5$ and $\overline{s}=1.5$.
% $l=30$, $\mu=0.1$
% and $d\lambda=0.1$.
% in Algorithm 1.



% \subsection{Experiments on 3D synthetic dataset}

Following \cite{GM_relax_label,RPM_model_occlude},
we test a method's robustness to non-rigid deformation, positional noise,
outliers, occlusion and coexisting outliers,
as illustrated in the second to fifth column of Fig. \ref{3D_test_exa}.
% by following the experimental setup as described in \cite{}.
% Here non-rigid deformation is generated by using the Gaussian radial basis function 
% and occlusion is generated by 
% removing points within a randomly chosen ball region from the prototype shape.
% For the last 3 types of tests, 
% a moderate amount of deformation is present.
Also, to test a method's ability to handle rotation and scale changes,
random rotation with rotation angle less than 60 degree 
and random uniform scaling with scale factor within range $[0.5 ,1.5]$
are applied to the prototype shape 
when generating the scene point set.
% Two 3D shapes, %\footnote{http://shapes.aimatshape.net/}, 
% a horse and a dinosaur,
% as shown in the left column of Fig. \ref{3D_test_exa},
% are used as the prototype shape, respectively.
% Fig. shows examples of scene point sets in these 4 tests.






% Following \cite{RPM_model_occlude},
% we then test a method's robustness to coexisting outliers.
% The experimental setup is as follows:
% equal number of normally distributed random outliers are added to different sides of the prototype shape to generate the two point sets,
% as illustrated in the right two columns of Fig. \ref{3D_test_exa}.
% Also, 
% moderate deformation, %is applied to the scene point set and
% random rotation and scaling as described previously are applied to the prototype shape when generating the two point sets
% so as to test a method's ability to handle deformation, rotation and scaling.


\begin{figure}[t]
 \includegraphics[width=\linewidth]{horses.png}


% \hfill 
%  \includegraphics[width=0.14\linewidth]{horse200_prototype.pdf}\hfill
% %    \includegraphics[width=0.14\linewidth]{horse_model.pdf}\hfill
%   \includegraphics[width=0.14\linewidth]{horse200_rot_scale_deform_exa.pdf}\hfill
%     \includegraphics[width=0.14\linewidth]{horse201_rot_scale_noise_exa.pdf}\hfill
% %  \includegraphics[width=0.2\linewidth]{horse_rot_scale_outlier_model_exa.pdf}\hfill
%  \includegraphics[width=0.14\linewidth]{horse200_rot_scale_outlier_exa.pdf}\hfill
%   \includegraphics[width=0.14\linewidth]{horse201_rot_scale_occlude_exa.pdf}\hfill
%    \includegraphics[width=0.14\linewidth]{horse201_rot_scale_double_outlier_model_exa.pdf}\hfill
%  \includegraphics[width=0.14\linewidth]{horse201_rot_scale_double_outlier_data_exa.pdf}\hfill
 
\caption{
First 5 columns:
model point set (left column) and 
examples of scene  sets in the deformation, positional noise,  outlier and  occlusion tests, respectively (columns 2 to 5).
Last 2 columns:
examples of model (column 6) and scene (right column) point sets in the coexisting outlier test.
\label{3D_test_exa}}
\end{figure}

% \begin{figure}[h]
% \begin{center}
% \begin{tabular}{c@{}c@{}c@{}c@{}c@{}c}
% \includegraphics[width=0.164\linewidth]{fish_model} &
% \includegraphics[width=0.164\linewidth]{fish_deform_exa} &
% \includegraphics[width=0.164\linewidth]{fish_noise_exa}&
% \includegraphics[width=0.164\linewidth]{fish_outlier_exa} &
% \includegraphics[width=0.164\linewidth]{fish_occlude_model} &
% \includegraphics[width=0.164\linewidth]{fish_occlude_target_rotate} \\
% \includegraphics[width=0.164\linewidth]{fu_model} &
% \includegraphics[width=0.164\linewidth]{fu_deform_exa} &
% \includegraphics[width=0.164\linewidth]{fu_noise_exa}&
% \includegraphics[width=0.164\linewidth]{fu_outlier_exa} &
% \includegraphics[width=0.164\linewidth]{fu_occlude_model}& 
% \includegraphics[width=0.164\linewidth]{fu_occlude_target_rotate}  
% \end{tabular}
% \end{center}
% \caption{
% First 4 columns: 
% model point sets (left column) and examples
% of scene  sets in deformation,  noise and outlier tests,
% respectively
% (column 2 to 4).
% %
% Last 2 columns: 
% examples of model (column 5) 
% and scene (right column) point sets  in the clutter test. 
% \label{experi_setup}
% }
% \end{figure}



% \begin{figure*}[!th]
% \centering
% % \includegraphics[height=0.42\linewidth,width=1\linewidth]{path_follow_occlude_feature/fish_double_sta}
% \subfigure{\includegraphics[width=0.24\linewidth]{fish_rot_deform_err}}
% \subfigure{\includegraphics[width=0.24\linewidth]{fish_rot_noise_err}}
% \subfigure{\includegraphics[width=0.24\linewidth]{fish_rot_outlier_err}}
% \subfigure{\includegraphics[width=0.24\linewidth]{fish_rot_clutter_err}}
% 
% \subfigure{\includegraphics[width=0.24\linewidth]{fu_rot_deform_err}}
% \subfigure{\includegraphics[width=0.24\linewidth]{fu_rot_noise_err}}
% \subfigure{\includegraphics[width=0.24\linewidth]{fu_rot_outlier_err}}
% \subfigure{\includegraphics[width=0.24\linewidth]{fu_rot_clutter_err}}
% 
% 
% \caption{
% Average matching errors  by different methods on the 2-D synthetic dataset
% (error bars 
% indicate 
% standard variances).
% \label{test_statis}
% }
% \end{figure*}




% \begin{figure}[h]
% \centering
% % \subfigure{\includegraphics[width=0.49\linewidth]{horse_rot_double_outlier_err}}
% % \subfigure{\includegraphics[width=0.49\linewidth]{dino_rot_double_outlier_err}}
% \subfigure{\includegraphics[width=0.49\linewidth]{horse_rot_outlier_err}}
% \subfigure{\includegraphics[width=0.49\linewidth]{dino_rot_outlier_err}}
% 
% \caption{
% Successful matching rates  by different methods on the 3-D synthetic dataset
% (error bars indicate standard variances).
% \label{3D_test_statis}
% }
% \end{figure}






% \begin{figure}[t]
% \hfill 
% \includegraphics[width=0.1\linewidth]{fish_model.pdf}\hfill
%  \includegraphics[width=0.2\linewidth]{fish_rot_scale_double_outlier_model_exa.pdf}\hfill
%  \includegraphics[width=0.2\linewidth]{fish_rot_scale_double_outlier_data_exa.pdf}\hfill
%   \includegraphics[width=0.1\linewidth]{fu_model.pdf}\hfill
%  \includegraphics[width=0.2\linewidth]{fu_rot_scale_double_outlier_model_exa.pdf}\hfill
%  \includegraphics[width=0.2\linewidth]{fu_rot_scale_double_outlier_data_exa.pdf}\hfill
% \caption{
% Left column: the prototype shape. 
% For the remaining columns: 
% examples of model and scene point sets in the  outlier (columns 2, 3)
% and  occlusion+outlier (columns 4, 5) tests.
% \label{nonrot_3D_test_data_exa}}
% \end{figure}








% \begin{figure}[t]
% \hfill 
%  \includegraphics[width=0.1\linewidth]{horse_model.pdf}\hfill
% 
%   \includegraphics[width=0.1\linewidth]{dino_model.pdf}\hfill
% 
% %   \includegraphics[width=0.2\linewidth]{horse_double_outlier0d5_occlude_model_exa.pdf}\hfill
% %  \includegraphics[width=0.2\linewidth]{horse_double_outlier0d5_occlude_data_exa.pdf} \hspace{\fill}
% 
% \caption{
% Left column: the prototype shape. 
% For the remaining columns: 
% examples of model and scene point sets in the  outlier (columns 2, 3)
% and  occlusion+outlier (columns 4, 5) tests.
% \label{nonrot_3D_test_data_exa}}
% \end{figure}

% We then test a method over the challenging problem of rotation invariant point matching
% where outliers exist in both point sets.
% The experiment is designed as follows:
% Equal number of normally distributed random outliers
% are added to different sides of the prototype shape to generate the two point sets, respectively.
% Then the model point set is moderately non-rigidly deformed and randomly rotated.
% as illustrated in Fig.

The average matching accuracies (fraction of correct matches)
% successful matching rates 
% over 100 random trials
by
different 
% our method using generic quadratic term,
% our method using low rank quadratic term 
% and other 
methods  are presented in Fig. \ref{3D_test_statis}. 
% where a matching is considered successful if mean
% of the Euclidean distances between the transformed model
% inliers and their corresponding ground truth scene inliers is
% less than 0.1.
% where error is defined as mean of the Euclidean
% distances between the warped ground truth model inliers
% and their corresponding data inliers. 
One can see that our method performs considerably better than  other methods.
% for all categories of tests,
% except for the coexisting outlier test, 
% where our method is closely followed by the gmmreg method. % perform the best.
% for all the tests.
% among all the methods.
% In contrast, failed for all the tests. 
This demonstrates our method's robustness to various types of disturbances.
Examples of matching results by different methods in the 
% outlier and
coexisting outlier test are shown  in Fig. \ref{3D_match_exa}.
The average running times (in second) by different methods are %listed in Table \ref{3D_test_time}.
   3.6054 for our method,
    4.1525 for RPM-PF,
    1.8160 for RPM,
    5.7997 for Go-ICP,
    0.0612 for CPD and
    0.2865 for gmmreg.
It's clear our method is  efficient.
% Overall,
% our method is efficient for all types of tests.
% In comparison,
% RPM-PF is less efficient for the coexisting outlier test and 
% Go-ICP is less efficient for the occlusion test.
% % It's clear our method is as efficient as RPM-PF.
% For different variants of our method,
% % using different quadratic terms,
% our method using low rank quadratic term is more efficient than our method using generic quadratic term,
% particularly for the  challenging tests of outliers, occlusion and coexisting outlers,
% where the speed improvement is quite significant.
    
    
% \begin{table}[h]
% \centering
% \caption{
% Average run time (in seconds).
% }
% \label{3D_test_time}
%  \begin{tabular}{|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|}
% \hline
%           &Deformation&Noise &Outlier & Occlusion & Coexisting outlier\\\hline
% ours & 4.3461   &  4.3250  & 5.7993  &2.4220 &6.4260\\\hline
% ours (low rank) &  3.1800   & 3.1983    & 2.0655  &1.3886 &1.7242\\\hline
% RPM-PF & 2.6418   &  2.2850 & 2.5233  &1.1814 & 12.1312\\\hline
% RPM &  1.9985   & 1.6700 &1.6288  &  1.1587&2.6240\\\hline
% Go-ICP & 2.2487  & 1.5983  &3.2961  & 13.9372&7.9183 \\\hline
% CPD &\textbf{0.0764}&\textbf{0.0591}&  \textbf{0.0693} &\textbf{0.0260}& \textbf{0.0752} \\\hline
% gmmreg &    0.2839   &  0.3029 &  0.2309  & 0.2357&0.3792 \\\hline
%    \end{tabular} 
% \end{table}      
  
          
    
  
    
    
   
      
    
    
   
  
    
   
        
    
    
    
    
   
    
      
   
    
    
    
   
    
    
    
  
  
    
    
    
\begin{figure}[!ht]

% \includegraphics[width=\linewidth]{charts.png}

\centering
{\includegraphics[width=0.325\linewidth]{statis_deform}}
{\includegraphics[width=0.325\linewidth]{statis_noise}}
{\includegraphics[width=0.325\linewidth]{statis_outlier}}


{\includegraphics[width=0.33\linewidth]{statis_occlude}}
{\includegraphics[width=0.46\linewidth]{statis_double_outlier3}}
% {\includegraphics[width=0.32\linewidth]{horse_rot_scale_occlude_succ_rate}}
% {\includegraphics[width=0.32\linewidth]{horse_rot_scale_double_outlier_succ_rate}}
% \subfigure{\includegraphics[width=0.19\linewidth]{dino_rot_scale_deform_succ_rate}}
% \subfigure{\includegraphics[width=0.19\linewidth]{dino_rot_scale_noise_succ_rate}}
% \subfigure{\includegraphics[width=0.19\linewidth]{dino_rot_scale_outlier_succ_rate}}
% \subfigure{\includegraphics[width=0.19\linewidth]{dino_rot_scale_occlude_succ_rate}}
% \subfigure{\includegraphics[width=0.19\linewidth]{dino_rot_scale_double_outlier_succ_rate}}
\caption{
Average matching accuracies  by different methods in the 5 categories of tests.
% deformation, positional noise, outliers, occlusion and coexisting outlier tests
% on the 3D synthetic dataset
The error bars indicate standard deviations of the methods over 100 random trials.
\label{3D_test_statis}
}
\end{figure}    
\begin{figure}[!ht]
\centering

\includegraphics[width=\linewidth]{horses2.png}


% \begin{tabular}{@{}c c c c c c@{}}
% \hfill
% {\includegraphics[width=.14\linewidth]{horse_rot_scale_outlier_RPM_PF_rigid}}\hfill
% {\includegraphics[width=.14\linewidth]{horse_rot_scale_outlier_RPM_PF_rigid_low_rank}}\hfill
% {\includegraphics[width=.14\linewidth]{horse_rot_scale_outlier_RPM_PF_aff}}\hfill
% {\includegraphics[width=.14\linewidth]{horse_rot_scale_outlier_RPM}}\hfill
% {\includegraphics[width=.14\linewidth]{horse_rot_scale_outlier_GO_ICP}}\hfill
% {\includegraphics[width=.14\linewidth]{horse_rot_scale_outlier_CPD_aff}}\hfill
% {\includegraphics[width=.14\linewidth]{horse_rot_scale_outlier_gmmreg_aff}} \hspace{\fill}
% \hfill
% {\includegraphics[width=.14\linewidth]{dino_rot_scale_outlier_RPM_PF_rigid}}\hfill
% {\includegraphics[width=.14\linewidth]{dino_rot_scale_outlier_RPM_PF_rigid_low_rank}}\hfill
% {\includegraphics[width=.14\linewidth]{dino_rot_scale_outlier_RPM_PF_aff}}\hfill
% {\includegraphics[width=.14\linewidth]{dino_rot_scale_outlier_RPM}}\hfill
% {\includegraphics[width=.14\linewidth]{dino_rot_scale_outlier_GO_ICP}}\hfill
% {\includegraphics[width=.14\linewidth]{dino_rot_scale_outlier_CPD_aff}}\hfill
% {\includegraphics[width=.14\linewidth]{dino_rot_scale_outlier_gmmreg_aff}} \hspace{\fill}
% {\includegraphics[width=.16\linewidth]{horse_rot_scale_occlude_RPM_PF_rigid}}
% {\includegraphics[width=.16\linewidth]{horse_rot_scale_occlude_RPM_PF_aff}}
% {\includegraphics[width=.16\linewidth]{horse_rot_scale_occlude_RPM}}
% {\includegraphics[width=.16\linewidth]{horse_rot_scale_occlude_GO_ICP}}
% {\includegraphics[width=.16\linewidth]{horse_rot_scale_occlude_CPD_aff}}
% {\includegraphics[width=.16\linewidth]{horse_rot_scale_occlude_gmmreg_aff}} \\
% \hfill
% {\includegraphics[width=.23\linewidth]{horse_rot_scale_double_outlier_RPM_PF_rigid}}
% % {\includegraphics[width=.14\linewidth]{horse_rot_scale_double_outlier_RPM_PF_rigid_low_rank}}\hfill
% {\includegraphics[width=.23\linewidth]{horse_rot_scale_double_outlier_RPM_PF_aff}}
% % {\includegraphics[width=.14\linewidth]{horse_rot_scale_double_outlier_RPM}}
% {\includegraphics[width=.23\linewidth]{horse_rot_scale_double_outlier_RPM_TPS}}\\
% 
% {\includegraphics[width=.23\linewidth]{horse_rot_scale_double_outlier_GO_ICP}}
% {\includegraphics[width=.23\linewidth]{horse_rot_scale_double_outlier_CPD_aff}}
% {\includegraphics[width=.23\linewidth]{horse_rot_scale_double_outlier_gmmreg_aff}}
% % \hspace{\fill} 

% \hfill
% \subfigure[ours]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_RPM_PF_rigid}}\hfill
% \subfigure[ours (low rank)]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_RPM_PF_rigid_low_rank}}\hfill
% \subfigure[RPM-PF]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_RPM_PF_aff}}\hfill
% % \subfigure[RPM]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_RPM}}
% \subfigure[RPM]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_RPM_TPS}}\hfill
% \subfigure[Go-ICP]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_GO_ICP}}\hfill
% \subfigure[CPD]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_CPD_aff}}\hfill
% \subfigure[gmmreg]{\includegraphics[width=.14\linewidth]{dino_rot_scale_double_outlier_gmmreg_aff}}\hspace{\fill}

% \end{tabular}
\caption{
Examples of matching results by (from left to right and from top to bottom)
our method, RPM-PF, RPM, Go-ICP, CPD and gmmreg
 in the  coexisting outlier  test.
\label{3D_match_exa}
}
\end{figure}
    
% \begin{figure}[h]
% \centering
% 
% \subfigure{\includegraphics[width=0.49\linewidth]{fish_rot_scale_double_outlier_succ_rate}}
% \subfigure{\includegraphics[width=0.49\linewidth]{fu_rot_scale_double_outlier_succ_rate}}
% \caption{
% Successful matching rates  by different methods on the 3-D synthetic dataset
% (error bars indicate standard variances).
% \label{3D_test_statis}
% }
% \end{figure}




\section{Conclusion}
We proposed a PF based point matching method in this letter
by adapting the method of \cite{RPM_PF_aff} to use the similarity transformation.
% we 
% % proposed a PF based point matching method in this paper by 
% adapt the PF method of \cite{RPM_PF_aff} to use similarity transformation.
% % instead of affine transformation as in \cite{RPM_PF_aff}.
% % Due to the nonlinearity of 3D similarity transformation,
% % this is a nontrivial extension of the method of \cite{RPM_PF_aff}.
Due to nonlinearity of 3D similarity transformation,
this is a nontrivial extension of the method of \cite{RPM_PF_aff}.
% The reduced number of transformation parameters 
% % by our method over that of \cite{RPM_PF_aff}
% leads to more constrained and desirable matching results,
% which is verified by 
% in the case of 3D matching 
% where the two point sets can have significant orientation and scale differences.
% We also propose a novel low rank convex quadratic term for use in the PF algorithm
% which leads to better convergence property.
% % and scale changes between two point sets.
Experimental results demonstrate better robustness of the proposed method %to various types of disturbances 
over  state-of-the-art methods.
% and also improved computational efficiency.
% over that of \cite{RPM_PF_aff}.


% Wei Lian and Jianmei Zhang (\textit{Department of Computer Science, Changzhi University,
% Changzhi 046011, Shanxi, People's Republic of China}).
% Email: lianwei3@foxmail.com.
% 
% Junyi Zuo (\textit{School of Aeronautics,
% Northwestern Polytechnical University, 
% Xi'an 710072, People's Republic of China}).

% This work was supported by 
% the National Natural Science Foundation of China under Grant 61473227.
% % scientific and technological innovation programs of higher education institutions in Shanxi (2014150).





% \bibliographystyle{splncs}
% % \bibliographystyle{ieee}%splncs}%{IEEEtran}%{}
% \bibliography{../DP_SC_rotate/DP_SC_CVPR}






\end{document}


Feature point matching where there is only partial overlap between two point sets is a challenging problem in literature. To solve this problem, we made the following contributions:  1) we propose to use the concave form of the robust point matching (RPM) method as a regularization term which is applicable to the case that there is only partial overlap between two point sets; 2) instead of using fixed weights to combine feature matching costs and regularization, we propose a path following strategy which transits from the state that the two terms have the same weight to the state that there is only weight of regularization. In doing so, our approach can better handle the situation that when matching problem becomes difficult, the costs of some wrong correspondences are also low and their presence in the energy function may bias the optimization towards yielding poor matching results. Experimental results verified the better performance of path following strategy over the naive approach of using fixed weights for the two terms.

Feature point matching is a key component in many areas include computer vision, pattern recognition and medical image analysis etc.
Therefore our algorithm have wide applications and can be applied to the specific problems in these areas.
 