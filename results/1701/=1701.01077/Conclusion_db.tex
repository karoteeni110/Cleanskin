\section{Conclusion and Future Work}

% recap of paper contribution
The use of transfer learning to extract features and solve typical AI tasks has been increasing over the past few years. The major consideration while doing transfer learning tasks is that the data in the source domain and the target domain are similar in terms of representation.

This paper explores the concept of transfer learning for the domains which are not directly eligible to apply transfer learning. We introduce the idea of transforming a non-visually interpretable problem domain to a visual domain, to leverage the effectiveness of pre-trained CNNs on visual data. To our knowledge, this kind of modality transformation of data with the intention of applying transfer learning techniques has not been carried out so far.
Additionally, we provide a unified feature extractor for sensor data which generally requires different feature extraction techniques for different applications. However, even though we apply our technique on the sensor data for a only single application, we believe that since the CNN for feature extraction is fixed and there is difference only in the way the input data is transformed, it should work for other sensor data applications as well.


%recap of results
This paper applies the introduced idea to a pilot dataset containing data from pressure sensors to perform a person identification task among 13 people. After evaluating the system with a pre-trained CNN as a feature extractor, we are able to achieve the average identification rate of 71.99\% and 78.41\% with maximum and average frame intensities respectively. We also explored the idea of analyzing the temporal information in the walking sequences, and applied the RNNs to exploit this additional dimension of time and hence achieve an average accuracy of 87.66\%.

This idea of modality transformation from one domain to another can be applied to other areas as well. This will specifically be beneficial in the cases of data for which there are no pre-trained models available. But, with this approach, if the data can be transformed into the target modality, transfer learning can be applied using the pre-trained models.

%future work

To further explore this concept, we would like to explore the effectiveness of this method on other types of sensors such as, accelerometers, gyroscopes, etc. Certain sensors do not present an obvious or intuitive way to be transformed into the visual mode. Therefore, it might be interesting to determine if it is possible to learn a transformation function from the source to the target mode. 