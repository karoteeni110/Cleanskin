<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>Inverting the coupling of the signed Gausssian free field with a loop
soup</title>
    <abstract>Lupu introduced a coupling between a random walk loop-soup and a
Gaussian free field, where the sign of the field is constant on each
cluster of loops. This coupling is a signed version of isomorphism
theorems relating the square of the GFF to the occupation field of
Markovian trajectories. His construction starts with a loop-soup, and by
adding additional randomness samples a GFF out of it. In this article we
provide the inverse construction: starting from a signed free field and
using a self-interacting random walk related to this field, we construct
a random walk loop-soup. Our construction relies on the previous work by
Sabot and Tarrès, which inverts the coupling from the square of the GFF
rather than the signed GFF itself. As a consequence, we also deduce an
inversion of the coupling between the random current and the FK-Ising
random cluster models introduced by Lupu and Werner. </abstract>
  </head>
  <body>
<outline text="Introduction" _note="Let be a connected undirected graph, with at most countable and each&#10;vertex of finite degree. We do not allow self-loops, however the edges&#10;might be multiple. Given an edge, we will denote and its end-vertices,&#10;even though is non-oriented and one can interchange and . Each edge is&#10;endowed with a conductance . There may be a killing measure on vertices.&#10;&#10;We consider the MARKOV JUMP PROCESSES on which being in , jumps along an&#10;adjacent edge with rate . Moreover if , the process is killed at with&#10;rate (the process is not defined after that time). will denote the time&#10;up to which is defined. If , then either the process has been killed by&#10;the killing measure (and ) or it has gone off to infinity in finite time&#10;(and infinite). We will assume that the process is transient, which&#10;means, if is finite, that . will denote the law of started from . Let be&#10;the Green function of : Let be the Dirichlet form defined on functions&#10;on with finite support: will be the law of the centred GAUSSIAN FREE&#10;FIELD (GFF) on with covariance . In case is finite, the density of is&#10;Given a finite subset of , and a function on , will denote the law of&#10;the GFF conditioned to equal on . will denote the family of local times&#10;of : For all , , let Recall the generalized second Ray-Knight theorem on&#10;discrete graphs by Eisenbaum, Kaspi, Marcus, Rosen and Shi (see also ):&#10;&#10;For any and ,&#10;&#10; under&#10;&#10;has the same law as&#10;&#10; under .&#10;&#10;Sabot and Tarrès showed in that the so-called “magnetized” reverse&#10;Vertex-Reinforced Jump Process provides an inversion of the generalized&#10;second Ray-Knight theorem, in the sense that it enables to retrieve the&#10;law of conditioned on . The jump rates of that latter process can be&#10;interpreted as the two-point functions of the Ising model associated to&#10;the time-evolving weights.&#10;&#10;However in the link with the Ising model is only implicit, and a natural&#10;question is whether Ray-Knight inversion can be described in a simpler&#10;form if we enlarge the state space of the dynamics, and in particular&#10;include the “hidden” spin variables.&#10;&#10;The answer is positive, and goes through an extension of the Ray-Knight&#10;isomorphism introduced by Lupu , which couples the sign of the GFF to&#10;the path of the Markov chain. The Ray-Knight inversion will turn out to&#10;take a rather simple form in Theorem \[thm-Poisson\] of the present&#10;paper, where it will be defined not only through the spin variables but&#10;also random currents associated to the field though an extra Poisson&#10;Point Process.&#10;&#10;The paper is organised as follows.&#10;&#10;In Section \[sec:srk\] we recall some background on loop soup&#10;isomorphisms and on related couplings and state and prove a signed&#10;version of generalized second Ray-Knight theorem. We begin in Section&#10;\[sec:lejan\] by a statement of Le Jan’s isomorphism which couples the&#10;square of the Gaussian Free Field to the loop soups, and recall how the&#10;generalized second Ray-Knight theorem can be seen as its Corollary: for&#10;more details see . In Subsection \[sec:lupu\] we state Lupu’s&#10;isomorphism which extends Le Jan’s isomorphism and couples the sign of&#10;the GFF to the loop soups, using a cable graph extension of the GFF and&#10;Markov Chain. Lupu’s isomorphism yields an interesting realisation of&#10;the well-known FK-Ising coupling, and provides as well a&#10;“Current+Bernoulli=FK” coupling lemma , which occur in the relationship&#10;between the discrete and cable graph versions. We briefly recall those&#10;couplings in Sections \[fkising\] and \[randomcurrent\], as they are&#10;implicit in this paper. In Section \[sec:glupu\] we state and prove the&#10;generalized second Ray-Knight “version” of Lupu’s isomorphism, which we&#10;aim to invert.&#10;&#10;Section \[sec:inversion\] is devoted to the statements of inversions of&#10;those isomorphisms. We state in Section \[sec\_Poisson\] a signed&#10;version of the inversion of the generalized second Ray-Knight theorem&#10;through an extra Poisson Point Process, namely Theorem \[thm-Poisson\].&#10;In Section \[sec\_dicr\_time\] we provide a discrete-time description of&#10;the process, whereas in Section \[sec\_jump\] we yield an alternative&#10;version of that process through jump rates, which can be seen as an&#10;annealed version of the first one. We deduce a signed inversion of Le&#10;Jan’s isomorphism for loop soups in Section \[sec:lejaninv\], and an&#10;inversion of the coupling of random current with FK-Ising in Section&#10;\[sec:coupinv\]. Finally Section \[sec:proof\] is devoted to the proof&#10;of Theorem \[thm-Poisson\]: Section \[sec:pfinite\] deals with the case&#10;of a finite graph without killing measure, and Section \[sec:pgen\]&#10;deduces the proof in the general case.">
</outline>
<outline text="Le Jan’s and Lupu’s isomorphisms">
  <outline text="Loop soups and Le Jan’s isomorphism" _note="The LOOP MEASURE associated to the Markov jump process is defined as&#10;follows. Let be the bridge probability measure from to in time&#10;(conditionned on ). Let be the transition probabilities of .&#10;&#10;Let be the measure on time-parametrised nearest-neighbour based loops&#10;(i.e. loops with a starting site) The loops will be considered here up&#10;to a rotation of parametrisation (with the corresponding pushforward&#10;measure induced by ), that is to say a loop will be the same as , where&#10;denotes the concatenation of paths. A LOOP SOUP of intensity , denoted ,&#10;is a Poisson random measure of intensity . We see it as a random&#10;collection of loops in . Observe that a.s. above each vertex , contains&#10;infinitely many trivial “loops” reduced to the vertex . There are also&#10;with positive probability non-trivial loop that visit several vertices.&#10;&#10;Let be the OCCUPATION FIELD of on i.e., for all , In Le Jan shows that&#10;for transient Markov jump processes, for all a.s. For he identifies the&#10;law of :&#10;&#10; has the same law as under .&#10;&#10;Let us briefly recall how Le Jan’s isomorphism enables one to retrieve&#10;the generalized second Ray-Knight theorem stated in Section&#10;\[SecIntro\]: for more details, see for instance . We assume that is&#10;supported by : the general case can be dealt with by an argument similar&#10;to the proof of Proposition \[PropKillingCase\]. Let , and note that the&#10;isomorphism in particular implies that conditionally on has the same law&#10;as conditionally on .&#10;&#10;On the one hand, given the classical energy decomposition, we have ,&#10;with the GFF associated to the restriction of to , where and are&#10;independent. Now conditionally on has the law of , where is the sign of&#10;, which is independent of . But is symmetric, so that the latter also&#10;has the law of .&#10;&#10;On the other hand, the loop soup can be decomposed into the two&#10;independent loop soups contained in and hitting . Now has the law of and&#10;conditionally on has the law of the occupation field of the Markov chain&#10;under , which enables us to conclude.">
  </outline>
  <outline text="Lupu’s isomorphism" _note="As in , we consider the METRIC GRAPH associated to . Each edge is&#10;replaced by a continuous line of length .&#10;&#10;The GFF on with law can be extended to a GFF on as follows. Given , one&#10;considers inside a conditionally independent Brownian bridge, actually a&#10;bridge of a STANDARD BROWNIAN MOTION, of length , with end-values and .&#10;This provides a continuous field on the metric graph which satisfies the&#10;spatial Markov property.&#10;&#10;Similarly one can define a standard Brownian motion on , whose trace on&#10;indexed by the local times at has the same law as the Markov process on&#10;with jump rate to an adjacent edge up to time , as explained in Section&#10;2 of . One can associate a measure on time-parametrized continuous loops&#10;, and let be the Poisson Point Process of loops of intensity : the&#10;discrete-time loops can be obtained from by taking the print of the&#10;latter on .&#10;&#10;Lupu introduced in an isomorphism linking the GFF and the loop soup on .&#10;&#10;\[thm:Lupu\] There is a coupling between the Poisson ensemble of loops&#10;and defined above, such that the two following constraints hold:&#10;&#10;For all ,&#10;&#10;The clusters of loops of are exactly the sign clusters of .&#10;&#10;Conditionally on , the sign of on each of its connected components is&#10;distributed independently and uniformly in .&#10;&#10;Lupu’s isomorphism and the idea of using metric graphs were applied in&#10;to show that on the discrete half-plane , the scaling limits of&#10;outermost boundaries of clusters of loops in loop soups are the&#10;Conformal Loop Ensembles .&#10;&#10;Let (resp. ) be the set of edges such that (resp. ) does not touch on ,&#10;in other words such that all the edge remains in the same sign cluster&#10;of (resp. ). Let be the set of edges that are crossed (i.e. visited&#10;consecutively) by the trace of the loops on .&#10;&#10;In order to translate Lupu’s isomorphism back onto the initial graph ,&#10;one needs to describe on one hand the distribution of conditionally on&#10;the values of , and on the other hand the distribution of conditionally&#10;on and the cluster of loops on the discrete graph . These two&#10;distributions are described respectively in Subsections \[fkising\] and&#10;\[randomcurrent\], and provide realisations of the FK-Ising coupling and&#10;the “Current+Bernoulli=FK” coupling lemma .">
  </outline>
  <outline text="The FK-Ising distribution of  conditionally on" _note="\[lem:fki\] Conditionally on , is a family of independent random&#10;variables and&#10;&#10;Conditionally on , are constructed as independent Brownian bridges on&#10;each edge, so that are independent random variables, and it follows from&#10;the reflection principle that, if , then&#10;&#10;Let us now recall how the conditional probability in Lemma \[lem:fki\]&#10;yields a realisation of the FK-Ising coupling.&#10;&#10;Assume is finite. Let be a family of positive weights. An ISING MODEL on&#10;with interaction constants is a probability on configuration of spins&#10;such that An FK-ISING RANDOM CLUSTER MODEL with weights is a random&#10;configuration of open (value ) and closed edges (value ) such that where&#10;“” denotes the number of clusters created by open edges.&#10;&#10;The well-known FK-Ising and Ising coupling reads as follows.&#10;&#10;\[FK-Ising\] Given an FK-Ising model, sample on each cluster an&#10;independent uniformly distributed spin. The spins are then distributed&#10;according to the Ising model. Conversely, given a spins configuration&#10;following the Ising distribution, consider each edge , such that ,&#10;closed, and each edge , such that open with probability . Then the open&#10;edges are distributed according to the FK-Ising model. The two couplings&#10;between FK-Ising and Ising are the same.&#10;&#10;Consider the GFF on distributed according to . Let be the random&#10;interaction constants&#10;&#10;Conditionally on , follows an Ising distribution with interaction&#10;constants : indeed, the Dirichlet form (\[Dirichlet-form\]) can be&#10;written as Similarly, when has boundary condition on , then has an Ising&#10;distribution with interaction and conditioned on .&#10;&#10;Now, conditionally on , has FK-Ising distribution with weights . Indeed,&#10;the probability for conditionally on is , by Lemma \[lem:fki\], as in&#10;Proposition \[FK-Ising\].&#10;&#10;Note that, given that has FK-Ising distribution, the fact that the sign&#10;of on its connected components is distributed independently and&#10;uniformly in can be seen either as a consequence of Proposition&#10;\[FK-Ising\], or from Theorem \[thm:Lupu\].&#10;&#10;Given on the discrete graph , we introduce in Definition&#10;\[def\_FK-Ising\] as the random set of edges which has the distribution&#10;of conditionally on .&#10;&#10;\[def\_FK-Ising\] We let be a random set of edges which has the&#10;distribution of conditionally on given by Lemma \[lem:fki\].">
  </outline>
  <outline text="Distribution of  conditionally on" _note="The distribution of conditionally on can be retrieved by Corollary 3.6&#10;in , which reads as follows.&#10;&#10;\[36\] Conditionally on , the events , , are independent and have&#10;probability&#10;&#10;This result gives rise, together with Theorem \[thm:Lupu\], to the&#10;following discrete version of Lupu’s isomorphism, which is stated&#10;without any recourse to the cable graph induced by .&#10;&#10;\[def:out\] Let be a percolation defined as follows: conditionally on ,&#10;the random variables are independent, and equals with conditional&#10;probability given by .&#10;&#10;Let the set of edges:&#10;&#10;\[PropIsoLupuLoops\] Given a loop soup , let be as in Definition&#10;\[def:out\]. Let be random spins taking constant values on clusters&#10;induced by ( if ) and such that the values on each cluster, conditional&#10;on and , are independent and uniformly distributed. Then is a Gaussian&#10;free field distributed according to .&#10;&#10;Proposition \[PropIsoLupuLoops\] induces the following coupling between&#10;FK-Ising and random currents.&#10;&#10;If is finite, a RANDOM CURRENT MODEL on with weights is a random&#10;assignment to each edge of a non-negative integer such that for all , is&#10;even, which is called the PARITY CONDITION. The probability of a&#10;configuration satisfying the parity condition is where actually . Let&#10;The open edges in induce clusters on the graph .&#10;&#10;Given a loop soup , we denote by the number of times the loops in cross&#10;the nonoriented edge . The transience of the Markov jump process implies&#10;that is a.s. finite for all . If , we have the following identity (see&#10;for instance ):&#10;&#10;Assume is finite and consider the loop soup . Conditionally on the&#10;occupation field , is distributed as a random current model with weights&#10;. If is the GFF on given by Le Jan’s or Lupu’s isomorphism, then these&#10;weights are .&#10;&#10;Conditionally on the occupation field , are the edges occupied by a&#10;random current and the edges occupied by FK-Ising. Lemma \[lem:fki\] and&#10;Proposition \[PropIsoLupuLoops\] imply the following coupling, as noted&#10;by Lupu and Werner in .&#10;&#10;\[RCFKIsing\] Assume is finite. Let be a random current on with weights&#10;. Let be an independent percolation, each edge being opened (value )&#10;independently with probability . Then is distributed like the open edges&#10;in an FK-Ising with weights .">
  </outline>
  <outline text="Generalized second Ray-Knight “version” of Lupu’s isomorphism" _note="We are now in a position to state the coupled version of the second&#10;Ray-Knight theorem.&#10;&#10;\[Lupu\] Let . Let with distribution , and define as in Definition&#10;\[def\_FK-Ising\]. Let be an independent Markov jump process started&#10;from .&#10;&#10;Fix . If , we let be the random subset of which contains , the edges&#10;used by the path , and additional edges opened conditionally&#10;independently with probability We let be random spins sampled uniformly&#10;independently on each cluster induced by , pinned at , i.e. , and define&#10;&#10;Then, conditionally on , has distribution , and has distribution&#10;conditionally on .&#10;&#10;One consequence of that coupling is that the path stays in the positive&#10;connected component of for . This yields a coupling between the range of&#10;the Markov chain and the sign component of inside a GFF .&#10;&#10;[PROOF OF THEOREM \[LUPU\]: ]{} The proof is based on . Let , and let be&#10;the loop soup of intensity on the cable graph , which we decompose into&#10;(resp. ) the loop soup hitting (resp. not hitting) , which are&#10;independent. We let and (resp. ) be the prints of these loop soups on&#10;(resp. on ). We condition on .&#10;&#10;Theorem \[thm:Lupu\] implies (recall also Definition \[def\_FK-Ising\])&#10;that we can couple with so that for all , and .&#10;&#10;Define from by, for all , and , where are random spins sampled uniformly&#10;independently on each cluster induced by , pinned at , i.e. . Then, by&#10;Theorem \[thm:Lupu\], has distribution .&#10;&#10;For all , we have&#10;&#10;On the other hand, conditionally on , where we use in the third equality&#10;that the event is measurable with respect to the -field generated by ,&#10;which is independent of , and where we use Lemma \[36\] in the fourth&#10;equality, for and for .&#10;&#10;We conclude the proof by observing that conditionally on has the law of&#10;the occupation field of the Markov chain under . []{}">
  </outline>
</outline>
<outline text="Inversion of the signed isomorphism" _note="In , Sabot and Tarrès give a new proof of the generalized second&#10;Ray-Knight theorem together with a construction that inverts the&#10;coupling between the square of a GFF conditioned by its value at a&#10;vertex and the excursions of the jump process from and to . In this&#10;paper we are interested in inverting the coupling of Theorem \[Lupu\]&#10;with the signed GFF : more precisely, we want to describe the law of&#10;conditionally on .&#10;&#10;We present in section \[sec\_Poisson\] an inversion involving an extra&#10;Poisson process. We provide in Section \[sec\_dicr\_time\] a&#10;discrete-time description of the process and in Section \[sec\_jump\] an&#10;alternative description via jump rates. Sections \[sec:lejaninv\] and&#10;\[sec:coupinv\] are respectively dedicated to a signed inversion of Le&#10;Jan’s isomorphism for loop soups, and to an inversion of the coupling of&#10;random current with FK-Ising.">
  <outline text="A description via an extra Poisson point process" _note="Let be a real function on such that for some . Set We define a&#10;self-interacting process living on as follows. The process starts at .&#10;For , we set where is the local time of the process up to time . Let be&#10;an independent Poisson Point Processes on with intensity 1, for each&#10;edge . We set We also denote by the configuration of edges such that .&#10;As time increases, the interaction parameters decreases for the edges&#10;neighboring , and at some random times may drop by 1. The process is&#10;defined as the process that jumps only at the times when one of the&#10;drops by 1, as follows:&#10;&#10;if decreases by 1 at time , but does not create a new cluster in , then&#10;crosses the edge with probability or does not move with probability ,&#10;&#10;if decreases by 1 at time , and does create a new cluster in , then&#10;moves/or stays with probability 1 on the unique extremity of which is in&#10;the cluster of the origin in the new configuration.&#10;&#10;We set clearly, the process is well-defined up to time .&#10;&#10;For all , is in the connected component of of the configuration . If is&#10;finite, the process ends at , i.e. .&#10;&#10;\[thm-Poisson\] Assume that is finite. With the notation of Theorem&#10;\[Lupu\], conditioned on , has the law of .&#10;&#10;Moreover, conditioned on , has the law of where are random spins sampled&#10;uniformly independently on each cluster induced by , with the condition&#10;that . If is infinite, then -a.s., (with the initial condition ) ends at&#10;, i.e. and . All previous conclusions for the finite case still hold.">
  </outline>
  <outline text="Discrete time description of the process" _note="We give a discrete time description of the process that appears in the&#10;previous section. Let and be the stopping times when one of the stacks&#10;decreases by , where is the time when one of the stacks is completely&#10;depleted. It is elementary to check the following:&#10;&#10;\[PropDiscrTime\] The discrete time process is a stopped Markov process.&#10;The transition from time to is the following:&#10;&#10;first chose an edge adjacent to the vertex according to a probability&#10;proportional to ,&#10;&#10;decrease the stack by 1,&#10;&#10;if decreasing by 1 does not create a new cluster in , then crosses the&#10;edge with probability or does not move with probability ,&#10;&#10;if decreasing by 1 does create a new cluster in , then moves/or stays&#10;with probability 1 on the unique extremity of which is in the cluster of&#10;the origin in the new configuration.">
  </outline>
  <outline text="An alternative description via jump rates" _note="We provide an alternative description of the process that appears in&#10;Section \[sec\_Poisson\].&#10;&#10;\[prop-jump\] The process defined in section \[sec\_Poisson\] can be&#10;alternatively described by its jump rates : conditionally on its past at&#10;time , if , and , then&#10;&#10; jumps to without modification of at rate&#10;&#10;the edge is closed in at rate and, conditionally on that last event:&#10;&#10;- if is connected to in the configuration , then simultaneously jumps to&#10;with probability and stays at with probability&#10;&#10;- otherwise moves/or stays with probability 1 on the unique extremity of&#10;which is in the cluster of the origin in the new configuration.&#10;&#10;It is clear from this description that the joint process is Markov&#10;process, and well defined up to the time&#10;&#10;One can also retrieve the process in Section \[sec\_Poisson\] from the&#10;representation in Proposition \[prop-jump\] as follows. Consider the&#10;representation of Proposition \[prop-jump\] on the graph where each edge&#10;is replaced by a large number of parallel edges with conductance .&#10;Consider now the number of parallel edges that are open in the&#10;configuration between and . Then, when , , converges in law to , defined&#10;in section \[sec\_Poisson\].&#10;&#10;[PROOF OF PROPOSITION \[PROP-JUMP\]: ]{} Assume , fix and let . Recall&#10;that iff .&#10;&#10;Let us first prove (1): Similarly, (2) follows from the following&#10;computation: []{}&#10;&#10;We easily deduce from the Proposition \[prop-jump\] and Theorem&#10;\[thm-Poisson2\] the following alternative inversion of the coupling in&#10;Theorem \[Lupu\].&#10;&#10;\[thm-jump-rates\] With the notation of Theorem \[Lupu\], conditionally&#10;on , has the law of self-interacting process defined by jump rates of&#10;Proposition \[prop-jump\] starting with Moreover has the same law as&#10;where is a configuration of signs obtained by picking a sign at random&#10;independently on each connected component of , with the condition that&#10;the component of has a + sign.">
  </outline>
  <outline text="A signed version of Le Jan’s isomorphism for loop soup" _note="Let us first recall how the loops in are connected to the excursions of&#10;the jump process .&#10;&#10;\[PropPD\] Let and . is distributed according to a Gamma law, where is&#10;the Green’s function. Let , and consider the path conditioned on . Let&#10;be an independent Poisson-Dirichlet partition of . Let and Let Consider&#10;the family of paths It is a countable family of loops rooted in . It has&#10;the same law as the family of all the loops in that visit , conditioned&#10;on .&#10;&#10;Next we describe how to invert the discrete version fo Lupu’s&#10;isomorphism Proposition \[PropIsoLupuLoops\] for the loop-soup in the&#10;same way as in Theorem \[thm-Poisson\].&#10;&#10;Let be a real function on such that for some . Set&#10;&#10;Let be an enumeration of (which may be infinite). We define by induction&#10;the self interacting processes . will denote the end-time for , and . By&#10;definition, . will denote where are the occupation times for . For , we&#10;set The end-times are defined by inductions as Let be independent&#10;Poisson Point Processes on with intensity 1, for each edge . We set We&#10;also denote by the configuration of edges such that . starts at . For ,&#10;&#10;if decreases by 1 at time , but does not create a new cluster in , then&#10;crosses the edge with probability or does not move with probability ,&#10;&#10;if decreases by 1 at time , and does create a new cluster in , then&#10;moves/or stays with probability 1 on the unique extremity of which is in&#10;the cluster of the origin in the new configuration.&#10;&#10;By induction, using Theorem \[thm-Poisson\], we deduce the following:&#10;&#10;\[ThmPoissonLoopSoup\] Let be a GFF on with the law . If one sets in the&#10;preceding construction, then for all , , and the path has the same law&#10;as a concatenation in of all the loops in a loop-soup that visit , but&#10;none of the . To retrieve the loops out of each path , on has to&#10;partition it according to a Poisson-Dirichlet partition as in&#10;Proposition \[PropPD\]. The coupling between the GFF and the loop-soup&#10;obtained from is the same as in Proposition \[PropIsoLupuLoops\].">
  </outline>
  <outline text="Inverting the coupling of random current with FK-Ising" _note="By combining Theorem \[ThmPoissonLoopSoup\] and the discrete time&#10;description of Section \[sec\_dicr\_time\], and by conditionning on the&#10;occupation field of the loop-soup, one deduces an inversion of the&#10;coupling of Proposition \[RCFKIsing\] between the random current and&#10;FK-Ising.&#10;&#10;We consider that the graph and that the edges are endowed with weights .&#10;Let be an enumeration of . Let be a subset of open edges of . Let be a&#10;family of random integers such that if , and are independent Poisson&#10;random variables, where .&#10;&#10;We will consider a family of discrete time self-interacting processes .&#10;starts at at and is defined up to a integer time . Let , with . The&#10;end-times are defined by induction as For , will denote which is&#10;consistent with the notation .&#10;&#10;The evolution is the following. For , the transition from time to time&#10;is the following:&#10;&#10;first chose an edge adjacent to the vertex with probability proportional&#10;to ,&#10;&#10;decrease the stack by 1,&#10;&#10;if decreasing by 1 does not create a new cluster in , then crosses with&#10;probability and does not move with probability .&#10;&#10;if decreasing by 1 does create a new cluster in , then moves/or stays&#10;with probability 1 on the unique extremity of which is in the cluster of&#10;the origin in the new configuration.&#10;&#10;Denote the number of times the edge has been crossed, in both&#10;directions, by all the walks .&#10;&#10;A.s., for all , and . If the initial configuration of open edges is&#10;random and follows an FK-Ising distribution with weights , then the&#10;family of integers is distributed like a random current with weights .&#10;Moreover, the coupling between the random current and the FK-Ising&#10;obtained this way is the same as the one given by Proposition&#10;\[RCFKIsing\].">
  </outline>
</outline>
<outline text="Proof of theorem [thm-Poisson]">
  <outline text="Case of finite graph without killing measure" _note="Here we will assume that is finite and that the killing measure .&#10;&#10;In order to prove Theorem \[thm-Poisson\], we first enlarge the state&#10;space of the process . We define a process living on the space as&#10;follows. Let be a GFF pinned at . Let be the signs of the GFF with the&#10;convention that . The process is as usual the Markov Jump process&#10;starting at with jump rates . We set The initial values are choosen&#10;independently on each edge with distribution where is a Poisson random&#10;variable with parameter . Let be independent Poisson point processes on&#10;with intensity 1. We define the process by where is the number of&#10;crossings of the edge by the Markov jump process before time .&#10;&#10;Note that compared to the process defined in Section \[sec\_Poisson\],&#10;the speed of the Poisson process is related to and not .&#10;&#10;We will use the following notation Recall that for . To simplify&#10;notation, we will write for in the sequel. We define by where are random&#10;spins sampled uniformly independently on each cluster induced by with&#10;the condition that .&#10;&#10;\[end-distrib\] The random vector thus defined has the same distribution&#10;as defined in Theorem \[Lupu\].&#10;&#10;It is clear from construction, that has the same law as (cf Definition&#10;\[def\_FK-Ising\]), the FK-Ising configuration coupled with the signs of&#10;as in Proposition \[FK-Ising\]. Indeed, for each edge such that , the&#10;probability that is . Moreover, conditionally on , has the same law as&#10;defined in Theorem \[Lupu\]. Indeed, is the union of the set , the set&#10;of edges crossed by the process , and the additional edges such that .&#10;Clearly independently with probability which coincides with the&#10;probability given in Theorem \[Lupu\].&#10;&#10;We will prove the following theorem that, together with Lemma&#10;\[end-distrib\], contains the statements of both Theorem \[Lupu\] and&#10;\[thm-Poisson\].&#10;&#10;\[thm-Poisson2\] The random vector is a GFF distributed according to .&#10;Moreover, conditionally on , the process has the law of the process&#10;described in section \[sec\_Poisson\].&#10;&#10;[**Step 1 :**]{} We start by a simple lemma.&#10;&#10;\[distrib-phi-n\] The distribution of is given by the following formula&#10;for any bounded measurable test function where the integral is on the&#10;set and and is the number of clusters induced by the edges such that .&#10;&#10;Indeed, by construction, summing on possible signs of , we have where&#10;the first sum is on the set and the second sum is on the set of (we&#10;write to mean that vanishes on the edges such that ). Since we deduce&#10;that the integrand in (\[int-eee\]) is equal to where we used in the&#10;first equality that on the edges such that . Thus, Inverting the sum on&#10;and and summing on the number of possible signs which are constant on&#10;clusters induced by the configuration of edges , we deduce Lemma&#10;\[distrib-phi-n\].&#10;&#10;[**Step 2 :**]{} We denote by the process defined previously and by its&#10;law with initial condition .&#10;&#10;We now introduce a process , which is a “time reversal” of the process .&#10;This process will be related to the process defined in section&#10;\[sec\_Poisson\] in Step 4, Lemma \[RN\].&#10;&#10;For and such that we define the process with values in as follows. The&#10;process is a Markov jump process with jump rates (so that ), and , are&#10;defined by where is the local time of the process up to time , where are&#10;independent Poisson point process on with intensity 1 for each edge ,&#10;and is the number of crossings of the edge by the process before time .&#10;We set This process is well-defined up to time We denote by its law.&#10;Clearly is a Markov process, we will later on make explicit its&#10;generator.&#10;&#10;We have the following change of variable lemma.&#10;&#10;\[change-var\] For all bounded measurable test functions where the&#10;integral on the l.h.s. is on the set with and the integral on the r.h.s.&#10;is on the set with&#10;&#10;We start from the left-hand side, i.e. the process, . We define and (The&#10;law of the processes such defined will later be identified with the law&#10;of the processes ( defined at the beginning of step 2, cf (\[tildePhi\])&#10;and (\[tilden\])). We also set which is also the number of crossings of&#10;the edge by the process , between time 0 and . With these notations we&#10;clearly have where is the local time of at time , and By time reversal,&#10;the law of is the same as the law of the Markov Jump process , where .&#10;Hence, we see that up to the time , the process has the same law as the&#10;process defined at the beginning of step 2.&#10;&#10;Then, following , we make the following change of variables&#10;conditionally on the processes which is bijective onto the set (Note&#10;that we always have .) The last conditions on and are equivalent to the&#10;conditions and . The Jacobian of the change of variable is given by&#10;&#10;[**Step 3:**]{} With the notations of Theorem \[thm-Poisson2\], we&#10;consider the following expectation for and bounded measurable test&#10;functions By definition, we have where are random signs sampled&#10;uniformly independently on clusters induced by and conditioned on the&#10;fact that . Hence, we define for and where means that the signs are&#10;constant on clusters of and such that . Hence, setting using lemma&#10;\[distrib-phi-n\] in the first equality and lemma \[change-var\] in the&#10;second equality, we deduce that (\[test-functions\]) is equal to with&#10;notations of Lemma \[change-var\]. Let be the filtration generated by .&#10;We define the -adapted process , defined up to time by where denotes the&#10;cluster of the origin induced by the configuration . Note that at time ,&#10;we also have since vanishes on the event where , with . Indeed, if ,&#10;then and for such that . It means that is equal to 0 if for some edge&#10;neighboring . Thus, is null unless is a cluster in . Hence, if since&#10;contains the indicator of the event that and are in the same cluster.&#10;&#10;Hence, using identities (\[eq-3.3\]) and (\[M-T\]) we deduce that&#10;(\[test-functions\]) is equal to&#10;&#10;[**Step 4 :**]{} We denote by the process defined in section&#10;\[sec\_Poisson\], which is well defined up to stopping time , and . We&#10;denote by the law of the process conditionnally on the initial value ,&#10;i.e. conditionally on . The last step of the proof goes through the&#10;following lemma.&#10;&#10;\[RN\] i) Under , ends at a.s. and for all .&#10;&#10;ii\) Let and be the law of the process and , then &#10;&#10;Using this lemma we obtain that in the right-hand side of (\[equ-M\])&#10;Hence, we deduce, using formula (\[h\]) and proceeding as in lemma&#10;\[distrib-phi-n\], that (\[test-functions\]) is equal to where the last&#10;integral is on the set , , and where means that and if . Finally, we&#10;conclude that where in the right-hand side is a GFF and is the process&#10;defined in section \[sec\_Poisson\] from the GFF . This exactly means&#10;that and that This concludes the proof of Theorem \[thm-Poisson2\].&#10;&#10;The generator of the process defined in (\[tildeZ\]) is given, for any&#10;bounded and for the second component test function , by where is the&#10;value obtained by removing 1 from at edge . Indeed, since , we have&#10;which is explains the first term in the expression. The second term is&#10;obvious from the definition of , and corresponding to the term induced&#10;by jumps of the Markov process . The last term corresponds to the&#10;decrease of due to the increase in the process . Indeed, on the interval&#10;, the probability that is equal to 1 is of order using identity&#10;(\[deriv-Phi\]).&#10;&#10;Let be the generator of the Markov jump process . We have that the&#10;generator is equal, for any smooth test function , to where correspond&#10;to the following disjoint events&#10;&#10; if the numbers of connected clusters induced by is the same as that of&#10;.&#10;&#10; if a new cluster is created in compared with and if is in the connected&#10;component of in the cluster induced by .&#10;&#10; if a new cluster is created in compared with and if is in the connected&#10;component of in the cluster induced by .&#10;&#10;Indeed, conditionally on the value of at time , the point process on the&#10;interval has the law of independent points with uniform distribution on&#10;. Hence, the probability that a point lies in the interval is of order&#10;We define the function so that To prove the lemma it is sufficient to&#10;prove (, Chapter 11) that for any bounded smooth test function Let us&#10;first consider the first term in (\[tildeL2\]). Direct computation gives&#10;For the second part, remark that the indicators and imply that vanishes&#10;if or if . By inspection of the expression of , we obtain for ,&#10;Similarly, for , Combining these three identities with the expression&#10;(\[tildeL2\]) we deduce It exactly coincides with the expression for&#10;since .">
  </outline>
  <outline text="General case" _note="\[PropKillingCase\] The conclusion of Theorem \[thm-Poisson\] still&#10;holds if the graph is finite and the killing measure is non-zero ().&#10;&#10;Let be the function on defined as By definition . Moreover, for all ,&#10;Define the conductances , and the corresponding jump process , and the&#10;GFF and with conditions respectively at . The Theorem \[thm-Poisson\]&#10;holds for the graph with conductances and with zero killing measure. But&#10;the process has the same law as the process , conditioned on , after the&#10;change of time This means in particular that for the occupation times,&#10;Moreover, we have the equalities in law Indeed, at the level of energy&#10;functions, we have: where means that this term does not depend of once&#10;the value of the function at fixed.&#10;&#10;Let be the inverse process for the conductances and the initial&#10;condition for the field , given by Theorem \[thm-Poisson\]. By applying&#10;the time change \[EqTimeChange\] to the process , we obtain an inverse&#10;process for the conductances and the field .&#10;&#10;\[PropInfiniteCase\] Assume that the graph is infinite. The killing&#10;measure may be non-zero. Then the conclusion of Theorem \[thm-Poisson\]&#10;holds.&#10;&#10;Consider an increasing sequence of connected sub-graphs of which&#10;converges to the whole graph. We assume that contains . Let be the graph&#10;obtained by adding to an abstract vertex , and for every edge , where&#10;and , adding an edge , with the equality of conductances . will denote&#10;the Markov jump process on , started from . Let be the first hitting&#10;time of or the first killing time by the measure . Let , will denote the&#10;GFFs on with condition respectively at , with condition at , and taking&#10;in account the possible killing measure . The limits in law of&#10;respectively are respectively .&#10;&#10;We consider the process be the inverse process on , with initial field .&#10;, conditional on , has the same law as . Taking the limit in law as&#10;tends to infinity, we conclude that , conditional on , has the same law&#10;as on the infinite graph . The same for the clusters. In particular,&#10;where in the first two probabilities we also average by the values of&#10;the free fields. Hence">
  </outline>
</outline>
<outline text="Acknowledgements" _note="TL acknowledges the support of Dr. Max Rössler, the Walter Haefner&#10;Foundation and the ETH Zurich Foundation.">
</outline>
  </body>
</opml>