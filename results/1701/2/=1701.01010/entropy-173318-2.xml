<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>Divergence and Sufficiency for Convex Optimization</title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Introduction" _note="One of the main purposes of information theory is to compress data so&#10;that data can be recovered exactly or approximately. One of the most&#10;important quantities was called entropy because it is calculated&#10;according to a formula that mimics the calculation of entropy in&#10;statistical mechanics. Another key concept in information theory is&#10;information divergence (KL-divergence) that is defined for probability&#10;vectors and as It was introduced by Kullback and Leibler in 1951 in a&#10;paper entitled information and sufficiency . The link from information&#10;theory back to statistical physics was developed by E.T. Jaynes via the&#10;maximum entropy principle . The link back to statistics is now well&#10;established .&#10;&#10;Related quantities appear in information theory, statistics, statistical&#10;mechanics, and finance, and we are interested in a theory that describes&#10;when these relations are exact and when they just work by analogy. First&#10;we introduce some general results about optimization on state spaces of&#10;finite dimensional C\*-algebras. This part applies exactly to all the&#10;topics under consideration and lead to Bregman divergences. Secondly, we&#10;introduce several notions of sufficiency and show that this leads to&#10;information divergence. This second step is not always applicable which&#10;explains when the different topics are really different.">
</outline>
<outline text="Structure of the state space" _note="Our knowledge about a system will be represented by a state space. I&#10;many cases the state space is given by a set of probability&#10;distributions on a sample space. In such cases the state space is a&#10;simplex, but it is well-known that the state space is not a simplex in&#10;quantum physics. For applications in quantum physics the state space is&#10;often represented by a set of density matrices, i.e. positive&#10;semidefinite complex matrices with trace 1. In some cases the states are&#10;represented as elements of a finite dimensional -algebra, which is a&#10;direct sum of matrix algebras. A finite dimensional -algebra that is a&#10;sum of matrices has a state space that is a simplex, so the state spaces&#10;of finite dimensional -algebras contain the classical probability&#10;distributions as special cases.&#10;&#10;The extreme points in the set of states are the pure states. The pure&#10;states of a -algebra can be identified with projections of rank 1. Two&#10;density matrices and are said to be orthogonal if Any state has a&#10;decomposition where are orthogonal pure states. Such a decomposition is&#10;not unique, but for a finite dimensional -algebra the coefficients are&#10;unique and are called the spectrum of the state.&#10;&#10;Sometimes more general state spaces are of interest. In generalized&#10;probabilistic theories a state space is a convex set where mixtures are&#10;defined by randomly choosing certain states with certain probabilities .&#10;A convex set where all orthogonal decompositions of a state have the&#10;same spectrum is called a spectral state space. Much of the theory in&#10;this paper can be generalized to spectral sets. The most important&#10;spectral sets are sets of positive elements with trace 1 in Jordan&#10;algebras. For questions related to the foundation of quantum theory the&#10;Jordan algebras and other spectral sets give new insight , but in this&#10;paper we will restrict our attention to states on finite dimensional&#10;-algebras. Nevertheless some of the theorems and proofs are stated in&#10;such a way that they hold for more general state spaces.">
</outline>
<outline text="Optimization" _note="Let denotes a state space of a finite dimensional -algebra and let&#10;denote a set of self-adjoint operators. Each is identified with a real&#10;valued measurement. The elements of may represent feasible ACTIONS&#10;(decisions) that lead to a payoff like the score of a statistical&#10;decision, the energy extracted by a certain interaction with the system,&#10;(minus) the length of a codeword of the next encoded input letter using&#10;a specific code book, or the revenue of using a certain portfolio. For&#10;each the mean value of the measurement is given by In this way the set&#10;of actions may be identified with a subset of the dual space of . Next&#10;we define We note that is convex, but need not be strictly convex. In&#10;principle may be infinite but we will assume that for all states . We&#10;also note that is lower semi-continuous. In this paper we will assume&#10;that the function is continuous. The assumption that real valued&#10;continuous function is fulfilled for all the applications we consider.&#10;&#10;If is a state and is an action then we say that is [OPTIMAL]{} for if .&#10;A sequence of actions is said to be [ASYMPTOTICALLY OPTIMAL]{} for the&#10;state if for&#10;&#10;If are actions and is a probability vector then we we may define the&#10;mixed action as the action where we do the action with probability We&#10;note that We will assume that all such mixtures of feasible actions are&#10;also feasible. If almost surely for all states we say that dominates and&#10;if almost surely for all states we say that strictly dominates All&#10;actions that are dominated may be removed from without changing the&#10;function Let denote the set of self-adjoint operators (observables) such&#10;that Then Therefore we may replace by without changing the optimization&#10;problem.&#10;&#10;In the definition of regret we follow Servage but with different&#10;notation.&#10;&#10;Let denote a convex function on the state space . If is finite THE&#10;REGRET of the action is defined by&#10;&#10;\[prop:actionregret\] The regret of actions has the following&#10;properties:&#10;&#10; with equality if is optimal for .&#10;&#10; is a convex function.&#10;&#10;If is optimal for the state where is a probability vector then&#10;&#10; is minimal if is optimal for .&#10;&#10;(0.,0.) – (1.15,0.); in [0,1]{} (0pt,2pt) – (0pt,-2pt) node\[below\]&#10;[]{}; (0.,0.) – (0.,0.7);&#10;&#10;(0.,0.5)– (1.,0.375);&#10;&#10;(1.,0.)– (1.,0.375); (1.,0.375)– (1.,0.625);&#10;&#10;plot(,[()\^2/4 - ()/8 + 1/2]{});&#10;&#10;(1.02,0.52) node\[anchor=north west\] []{}; (0.04,0.7)&#10;node\[anchor=north west\] []{}; (1.0807407407407414,0.1)&#10;node\[anchor=north west\] []{};&#10;&#10;(0.,0.5) circle (2pt); (1.,0.625) circle (2pt); (1.,0.) circle (2pt);&#10;(1.,0.375) circle (2pt);&#10;&#10;If the state is but one acts as if the state were one may compare what&#10;one achieves and what could have been achieved. If the state has a&#10;unique optimal action we may simply define the regret of by The&#10;following definition leads to a regret function that is essentially&#10;equivalent to the so-called [GENERALIZED BREGMAN DIVERGENCES]{} defined&#10;by Kiwiel .&#10;&#10;\[def:regret\] Let denote a convex function on the state space . If is&#10;finite then we define THE REGRET OF THE STATE as where the infimum is&#10;taken over all sequences of actions that are asymptotically optimal for&#10;&#10;With this definition the regret is always defined with values in . We&#10;note that with this definition the value of the regret only depends on&#10;the restriction of the function to the line segment from to . Let denote&#10;the function where . As illustrated in Figure \[Fig:breg\] we have where&#10;denotes the right derivative of at . Equation (\[eq:rightderiv\]) is&#10;even valid when the regret is infinite if we allow the right derivative&#10;to take the value .&#10;&#10;If the state has the unique optimal action then so the function can be&#10;reconstructed from except for an affine function of The closure of the&#10;convex hull of the set of functions is uniquely determined by the convex&#10;function The following proposition follows from Alexandrov’s theorem.&#10;See for details.&#10;&#10;A convex function on a finite dimensional convex set is differentiable&#10;almost everywhere with respect to the Lebesgue measure.&#10;&#10;A state where is differentiable has a unique optimal action. Therefore&#10;Equation (\[eq:rekonst\]) holds for almost any state . In particular the&#10;function can be reconstructed from except for an affine function.&#10;&#10;\[prop:regretproperties\] The regret of states has the following&#10;properties:&#10;&#10; with equality if there exists an action that is optimal for both and .&#10;&#10; is a convex function.&#10;&#10;Further the following two conditions are equivalent.&#10;&#10; implies .&#10;&#10;The function is strictly convex.&#10;&#10;We say that a regret function is [STRICT]{} if is strictly convex. The&#10;two last properties Proposition \[prop:actionregret\] do not carry over&#10;to regret for states except if the regret is a [BREGMAN DIVERGENCE]{} as&#10;defined below. The regret is called a BREGMAN DIVERGENCE if it can be&#10;written in the following form where denotes the (Hilbert-Smidt) inner&#10;product. In the context of forecasting and statistical scoring rules the&#10;use of Bregman divergences dates back to . A similar but less general&#10;definition of regret was given by Rao and Nayak where the name CROSS&#10;ENTROPY was proposed. Although Bregman divergences have been known for&#10;many years they did not gain popularity before the paper where a&#10;systematic study of Bregman divergences was presented.&#10;&#10;We note that if is a Bregman divergence and minimizes then so that the&#10;formula for the Bregman divergence reduces to Bregman divergences&#10;satisfy the BREGMAN IDENTITY but if is not differentiable this identity&#10;can be violated.&#10;&#10;Let the state space be the interval with two actions and Let and Let&#10;further and Then If then but Clearly the Bregman identity&#10;(\[eq:Bregmanid\]) is violated and will increase if is replaced by .&#10;&#10;The following proposition is easily proved.&#10;&#10;For a convex and continuous function the following conditions are&#10;equivalent.&#10;&#10;The function is differentiable.&#10;&#10;The regret is a Bregman divergence.&#10;&#10;The Bregman identity is always satisfied.&#10;&#10;For any probability vectors the sum is always minimal when .">
</outline>
<outline text="Examples" _note="In this section we shall see how regret functions are defined in some&#10;applications.">
  <outline text="Information theory" _note="We recall that a code is uniquely decodable if any finite sequence of&#10;input symbols give a unique sequence of output symbols. It is well-known&#10;that a uniquely decodable code satisfies Kraft’s inequality where&#10;denotes the length of the codeword corresponding to the input symbol and&#10;denotes the size of the output alphabet . Here the length of a codeword&#10;is an integer. If is a probability vector over the input alphabet, then&#10;the mean code-length is Our goal is to minimize the expected&#10;code-length. Here the state space consist of probability distributions&#10;over the input alphabet and the actions are code-length functions.&#10;&#10;Shannon established the inequality It is a combinatoric problem to find&#10;the optimal code length function. In the simplest case with a binary&#10;output alphabet the optimal code-length function is determined by the&#10;Huffmann algorithm.&#10;&#10;A code-length function dominates another code-length function if all&#10;letters have it has shorter code-length. If a code-length function is&#10;not dominated by another code-length function then for all the length is&#10;bounded by For fixed alphabets and there exists only a finite number of&#10;code-length functions that satisfy Kraft’s inequality and are not&#10;dominated by other code-length functions that satisfying Kraft’s&#10;inequality.">
  </outline>
  <outline text="Scoring rules" _note="The use of scoring rules has a long history in statistics. An early&#10;contribution was the idea of minimizing the sum of square deviations&#10;that dates back to Gauss and works perfectly for Gaussian distributions.&#10;In the 1920s Ramsay and de Finetti proved versions of the Dutch book&#10;theorem where determination of probability distributions were considered&#10;as dual problems of maximizing a payoff function. Later it was proved&#10;that any consistent inference procedure corresponds to optimizing with&#10;respect to some payoff function. A more systematic study of scoring&#10;rules was given by McCarthy .&#10;&#10;Consider an experiment with as sample space. A SCORING RULE is defined&#10;as a function such that the score is when a prediction has been given in&#10;terms of a probability distribution and has been observed. A scoring&#10;rule is PROPER if for any probability measure the score is minimal when&#10;Here the state space consist of probability distributions over and the&#10;actions are predictions over , which are also probability distributions&#10;over .&#10;&#10;There is a correspondence between proper scoring rules and Bregman&#10;divergences as explained in . If is a Bregman divergence and is a&#10;function with domain then given by defines a scoring rule.&#10;&#10;Assume that is a proper scoring function. Then a function can be defined&#10;as This lead to the regret function Since is assumed to be proper . The&#10;Bregman identity (\[eq:Bregmanid\]) follows by straight forward&#10;calculations. With these two results we see that the regret function is&#10;a Bregman divergence and that Hence a proper scoring rule has the form&#10;where . A [STRICTLY PROPER SCORING RULE]{} can be defined as a proper&#10;scoring rule where the corresponding Bregman divergence is strict.&#10;&#10;The Brier score is given by The Brier score is generated by the strictly&#10;convex function">
  </outline>
  <outline text="Statistical mechanics" _note="Thermodynamics is the study of concepts like heat, temperature and&#10;energy. A major objective is to extract as much energy from a system as&#10;possible. The idea in statistical mechanics is to view the macroscopic&#10;behavior of a thermodynamic system as a statistical consequence of the&#10;interaction between a lot of microscopic components where the&#10;interacting between the components are governed by very simple laws.&#10;Here the central limit theorem and large deviation theory play a major&#10;role. One of the main achievements is the formula for entropy as a&#10;logarithm of a probability.&#10;&#10;Here we shall restrict the discussion to the most simple kind of&#10;thermodynamic system from which we want to extract energy. We may think&#10;of a system of non-interacting spin particles in a magnetic field. For&#10;such a system the Hamiltonian is given by where is the spin&#10;configuration, is the magnetic moment, is the strength of an external&#10;magnetic field, and is the spin of the the ’th particle. If the system&#10;is in thermodynamic equilibrium the configuration probability is where&#10;is the partition function Here is the inverse temperature of the spin&#10;system and is Boltzmann’s constant.&#10;&#10;The mean energy is given by which will be identified with the internal&#10;energy defined in thermodynamics. The Shannon entropy can be calculated&#10;as The Shannon entropy times will be identified with the thermodynamic&#10;entropy .&#10;&#10;The amount of energy that can be extracted from the system if a heat&#10;bath is available, is called the EXERGY . We assume that the heat bath&#10;has temperature and the internal energy and entropy of the system are&#10;and if the system has been brought in equilibrium with the heat bath.&#10;The exergy can be calculated by The information divergence between the&#10;actual state and the corresponding state that is in equilibrium with the&#10;environment is Hence This equation appeared already in .">
  </outline>
  <outline text="Portfolio theory" _note="The relation between information theory and gambling was established by&#10;Kelly . Logarithmic terms appear because we are interested in the&#10;exponent in the exponential growth rate of our wealth. Later Kelly’s&#10;approach has been generalized to trading of stocks although the relation&#10;to information theory is weaker .&#10;&#10;Let denote PRICE RELATIVES for a list of assets. For instance means that&#10;asset no. 5 increases its value by 4 %. Such price relatives are mapped&#10;into a price relative vector&#10;&#10;A special asset is the SAFE ASSET where the price relative is 1 for any&#10;possible price relative vector. Investing in this asset corresponds to&#10;placing the money at a safe place with interest rate equal to 0 % .&#10;&#10;A PORTFOLIO is a probability vector where for instance means that 30 %&#10;of the money is invested in asset no. 5. We note that a portfolio may be&#10;traded just like the original assets. The price relative for the&#10;portfolio is The original assets may be considered as extreme points in&#10;the set of portfolios. If an asset has the property that the price&#10;relative is only positive for one of the possible price relative&#10;vectors, then we may call it a GAMBLING ASSET.&#10;&#10;We now consider a situation where the assets are traded once every day.&#10;For a sequence of price relative vectors and A CONSTANT RE-BALANCING&#10;PORTFOLIO the wealth after days is where the expectation is taken with&#10;respect to the empirical distribution of the price relative vectors.&#10;Here is proportional to the DOUBLING RATE and is denoted where indicates&#10;the probability distribution of . Our goal is to maximize by choosing an&#10;appropriate portfolio&#10;&#10;Let and denote two portfolios. We say that DOMINATES if for any possible&#10;price relative vector We say that STRICTLY DOMINATES if for any possible&#10;price relative vector A set of assets is said to dominate the set of&#10;assets if any asset in is dominated by a portfolio of assets in&#10;&#10;The maximal doubling rate does not change if dominated assets are&#10;removed. Sometimes assets that are dominated but not strictly dominated&#10;may lead to non-uniqueness of the optimal portfolio.&#10;&#10;Let denote a portfolio that is optimal for and define The regret of&#10;choosing a portfolio that is optimal for when the distribution is is&#10;given by the regret function If is not uniquely determined we take a&#10;minimum over all that are optimal for&#10;&#10;\[ex:port\] Assume that the price relative vector is with probability&#10;and with probability . Then the portfolio concentrated on the first&#10;asset is optimal for and the portfolio concentrated on the second asset&#10;is optimal for . For values of between and the optimal portfolio invests&#10;money on both assets as illustrated in Figure \[fig:port\].&#10;&#10;(0.,0.) – (1.1177000323939097,0.); in [,0.2,0.4,0.6,0.8,1,0]{} (0pt,2pt)&#10;– (0pt,-2pt);&#10;&#10;(0.,0.) – (0.,0.9124392614188542); in [0.2,0.4,0.6,0.8]{} (2pt,0pt) –&#10;(-2pt,0pt);&#10;&#10;plot \[smooth\] coordinates [ (0.2,0.4182935787194957)&#10;(0.24350034788969488,0.36120950042115774)&#10;(0.2870003018694437,0.3168468268696912)&#10;(0.3305002558491924,0.2817583882332283)&#10;(0.36050022411108806,0.26258526897379575)&#10;(0.4010001812646472,0.242875609771641)&#10;(0.4475001320705855,0.2286661976310767)&#10;(0.4880000892241446,0.22343157468501623)&#10;(0.540500033682462,0.22642765345704483)&#10;(0.6079999622717273,0.24665640576588088)&#10;(0.6469999210121916,0.26700668167457386)&#10;(0.6844998813395612,0.29285980246773613)&#10;(0.7279998353193099,0.33105261588381335)&#10;(0.7519998099288264,0.35616328670391684)&#10;(0.7999997591478595,0.4158879744441841)]{};&#10;&#10;(0.2,0.4182935787194957)– (0.2,0.);&#10;(0.8000000094532285,0.41588832144092486)– (0.8,0.);&#10;&#10;(0.02926465824424991,0.8875607385811478) node\[anchor=north west\] []{};&#10;(1.05,0.09) node\[anchor=north west\] []{}; (-0.02,-0.01)&#10;node\[anchor=north west\] []{}; (0.16,-0.01) node\[anchor=north west\]&#10;[]{}; (0.76,-0.01) node\[anchor=north west\] []{}; (0.98,-0.01)&#10;node\[anchor=north west\] []{};&#10;&#10;(0.,0.6931471805599453)– (0.19827171206890273,0.4182935787194957);&#10;(1.,0.6931471805599453)– (0.8000000094532285,0.41588832144092486);&#10;&#10;(0.8000000094532285,0.41588832144092486) circle (2.0pt);&#10;(0.19827171206890273,0.4182935787194957) circle (2.0pt);&#10;(0.,0.6931471805599453) circle (2.0pt); (1.,0.6931471805599453) circle&#10;(2.0pt);&#10;&#10;If there are only two price relative vectors and the regret function is&#10;strict then either one of the assets dominates all other assets or two&#10;of the assets are orthogonal gambling assets that dominate all other&#10;assets.&#10;&#10;We will assume that no assets are dominated by other assets. Let denote&#10;the two price relative vectors. Without loss of generality we may assume&#10;that If then so that if then and the asset is dominated by the asset&#10;Since we have assumed that no assets are dominated we may assume that If&#10;is a probability vector over the two price relative vectors then&#10;according to the portfolio is optimal if and only if for all with&#10;equality if Assume that the portfolio is optimal. Now is equivalent to&#10;Similarly is equivalent to We have to check that which is equivalent&#10;with The right hand side equals the determinant which is positive&#10;because asset is not dominated by a portfolio based on asset and asset&#10;&#10;We see that the portfolio concentrated in asset is optimal for in an&#10;interval of positive length and the regret between distributions in such&#10;an interval will be zero. In particular the regret will not be strict.&#10;&#10;Strictness of the regret function is only possible if there are only two&#10;assets and if a portfolio concentrated on one of these assets is only&#10;optimal for a singular probability measure. According to the formulas&#10;for the end points of intervals (\[eq:hoejreendepunkt\]) and&#10;(\[eq:venstreendepunkt\]) this is only possible if the assets are&#10;gambling assets.&#10;&#10;\[strict\] If the regret function is strict it equals information&#10;divergence, i.e.&#10;&#10;If the regret function is strict then it is also strict when we restrict&#10;to two price relative vectors. Therefore any two price relative vectors&#10;are orthogonal gambling assets. If the assets are orthogonal gambling&#10;assets we get the type of gambling described by Kelly . For gambling&#10;equation can easily be derived .">
  </outline>
</outline>
<outline text="Sufficiency Conditions" _note="In this section we will introduce some conditions on a regret function.&#10;Under some mild conditions they turn out to be equivalent.&#10;&#10;Let denote a regret function based on a continuous and convex function&#10;defined on the state space of a finite dimensional -algebra. If the&#10;state space has at least three orthogonal states then the following&#10;conditions are equivalent.&#10;&#10;The function equals entropy times a negative constant plus an affine&#10;function.&#10;&#10;The regret is proportional to information divergence.&#10;&#10;The regret is monotone.&#10;&#10;The regret is satisfies sufficiency.&#10;&#10;The regret is local.&#10;&#10;In the rest of this section we will describe each of these equivalent&#10;conditions and prove that they are actually equivalent. The theorems and&#10;proofs will be stated so that they hold even for more general state&#10;spaces than the ones considered in this paper.">
  <outline text="Entropy and Information Divergence" _note="Let denote an element in a state space. The ENTROPY of is be defined as&#10;where the infimum is taken over all decompositions of into pure states .&#10;&#10;This definition of the entropy of a state was first given by Uhlmann .&#10;Using that entropy is decreasing under majorization we see that the&#10;entropy of is attained at an orthogonal decomposition and we obtain the&#10;familiar equation&#10;&#10;In general this definition of entropy does not provide a concave&#10;function on a convex set. For instance the entropy of points in the&#10;square has local maximum in the four different points. A&#10;characterization of the convex sets with concave entropy functions is&#10;lacking.&#10;&#10;If the entropy is a concave function then the Bregman divergence is&#10;called INFORMATION DIVERGENCE.&#10;&#10;The information divergence is also called KULLBACK-LEIBLER DIVERGENCE,&#10;RELATIVE ENTROPY or QUANTUM RELATIVE ENTROPY. In a C\*-algebra we get&#10;where Now so that Hence For states it reduces to the well-known formula">
  </outline>
  <outline text="Monotonicity" _note="We consider a set of maps of the state space into itself. The set will&#10;be used to represent those transformations that we are able to perform&#10;on the state space before we choose a feasible action . Let denote a&#10;map. Then the dual map maps actions into actions and is given by&#10;&#10;\[prop:lostoppotunities\] If maps the set of feasible actions into&#10;itself then&#10;&#10;If then because . Inequality (\[eq:aftagende\]) follows because&#10;&#10;Let denote a map of the state space into itself such that maps the set&#10;of feasible actions into itself and let denote a state that minimizes&#10;the function . If is a Bregman divergence then&#10;&#10;Since minimizes and is differentiable we have . Since minimizes and we&#10;also have that minimizes and that . Therefore which proves the&#10;inequality.&#10;&#10;Next we introduce the stronger notion of monotonicity.&#10;&#10;Let denote a regret function on the state space of a finite dimensional&#10;C\*-algebra. Then is said to be MONOTONE if for any affine map&#10;&#10;\[prop:monoBreg\] If a regret function based on a convex and continuous&#10;function is monotone then it is a Bregman divergence.&#10;&#10;Assume that is monotone. We have to prove that is differentiable. Since&#10;is convex it is sufficient to prove that any restriction of to a line&#10;segment is differentiable. Let and denote states that are the end points&#10;of a line segment. The restriction of to the line segment is given by&#10;the convex and continuous function so we have to prove that is&#10;differentiable.&#10;&#10;If then according to Equation (\[eq:rightderiv\]) we have where denotes&#10;the denote the derivative from the right. A dilation by a factor around&#10;decreases the regret so that is increasing. Since is convex the function&#10;is increasing. Assume that is not differentiable so that has a positive&#10;jump as illustrated on Figure \[Fig:monobreg\]. This contradicts that&#10;the function (\[eq:hoejreafledt\]) is increasing. Therefore is&#10;continuous and is differentiable.&#10;&#10;(0.,0.) – (1.15,0.); (0.,0.) – (0.,1);&#10;&#10;(0,0.45) – (0.4499987575911538,0.45);&#10;(0.4500007324771293,0.4500007324771293) –&#10;(0.998624824324231,0.998624824324231);&#10;&#10;(1.,1.)– (1.,0.); (0.50,0.)– (0.50,0.50); (0.8,0.)– (0.80,0.80);&#10;(0.4,0.)– (0.4,0.45);&#10;&#10;(0.78,-0.04) node\[anchor=north west\] []{}; (0.96,-0.04)&#10;node\[anchor=north west\] []{}; (0.32,-0.04) node\[anchor=north west\]&#10;[]{}; (0.47,-0.04) node\[anchor=north west\] []{}; (1.07,0.1)&#10;node\[anchor=north west\] []{}; (0.04164903189233505,1)&#10;node\[anchor=north west\] []{}; (0.4,0.45)– (0.8,0.45);&#10;&#10;(1.,0.) circle (2pt); (0.50,0.) circle (2pt); (0.8,0.) circle (2pt);&#10;(0.4,0.45) circle (2pt); (0.4,0.) circle (2pt); (0.50,0.50) circle&#10;(2pt); (0.80,0.80) circle (2pt); (1.,1.) circle (2pt); (0.8,0.45) circle&#10;(2pt);&#10;&#10;Recently it has been proved that information divergence on a complex&#10;Hilbert space is decreasing under positive trace preserving maps .&#10;Previously this was only known to hold if some extra condition like&#10;complete positivity or 2-positivity was assumed .&#10;&#10;Information divergence is monotone under any positive trace preserving&#10;map on the states of a finite dimensional -algebra.&#10;&#10;Any finite dimensional -algebra can be embedded in and there exist a&#10;conditional expectation If is a positive trace preserving map of the&#10;density matrices of into it self then is positive and trace preserving&#10;on According to M[ü]{}ller-Hermes and Reeb we have for density matrices&#10;in In particular this inequality holds for density matrices in and for&#10;such matrices we have .">
  </outline>
  <outline text="Sufficiency" _note="The notion of sufficiency plays an important role in statistics and&#10;related fields. We shall present a definition of sufficiency that is&#10;based on , but there are a number of other equivalent ways of defining&#10;this concept. We refer to where the notion of sufficiency is discussed&#10;in great detail.&#10;&#10;Let denote a family of states and let denote an affine map where and&#10;denote state spaces. A RECOVERY MAP is an affine map such that The map&#10;is said to be SUFFICIENT for if has a recovery map.&#10;&#10;Assume is a regret function based on a convex and continuous function&#10;and assume that is sufficient for and with recovery map . Assume that&#10;both and map the set of feasible actions into itself. Then&#10;&#10;According to the principle of lest opportunities (Proposition&#10;\[prop:lostoppotunities\]) we have Therefore Let denote an action that&#10;is optimal for Then and we see that is optimal for Now where the infimum&#10;is taken over actions that are optimal for Then so we have The reverse&#10;inequality is proved in the same way.&#10;&#10;The notion of sufficiency as a property of divergences was introduced in&#10;. The crucial idea of restricting the attention to maps of the state&#10;space into itself was introduced in . It was shown in that a Bregman&#10;divergence on the simplex of distributions on an alphabet that is not&#10;binary and satisfies sufficiency equals information divergence up a&#10;multiplicative factor. Here we extend the notion of sufficiency from&#10;Bregman divergences to regret functions.&#10;&#10;Let denote a regret function based on a convex and continuous function&#10;on a state space . We say satisfies SUFFICIENCY if for any affine map&#10;that is sufficient for&#10;&#10;\[prop:sufficiency\]Let denote a regret function based on a convex and&#10;continuous function on a state space . If the regret function is&#10;monotone then it satisfies sufficiency.&#10;&#10;Assume that the regret function is monotone. Let and denote two states&#10;and let and denote maps on the state space such that  . Then Hence&#10;&#10;Combining the previous results we get that information divergence&#10;satisfies sufficiency. Under some conditions there exists an inverse&#10;version of Proposition \[prop:sufficiency\] stating that if monotonicity&#10;holds with equality then the map is sufficient. In statistics where the&#10;state space is a simplex, this result is well established. For density&#10;matrices over the complex numbers it has been proved for completely&#10;positive maps in . Some new results on this topic can be found in .">
  </outline>
  <outline text="Locallity" _note="Often it is relevant to use the following weak version of the&#10;sufficiency property.&#10;&#10;Let denote a regret function based on a convex and continuous function&#10;on a state space . The regret function is said to be local if when the&#10;states and are orthogonal to and&#10;&#10;On a 1-dimensional simplex (an interval) or on the Block sphere any&#10;regret function is local. The reason is that if and are states that are&#10;orthogonal to then&#10;&#10;Let denote a regret function based on a convex and continuous function&#10;on a state space . If the regret function satisfies sufficiency then is&#10;local.&#10;&#10;Let and be states that are orthogonal to Let denote the projection&#10;supporting the state . Let the maps and be defined by Then and and&#10;Therefore and&#10;&#10;Let be the state space of a -algebra with at least three orthogonal&#10;states, and let denote a regret function based on a convex and&#10;continuous function on the state space . If the regret function is local&#10;then it is the Bregman divergence generated by the entropy times a&#10;negative constant.&#10;&#10;In the following proof we will assume that the regret function is based&#10;on the convex function First we will prove that the regret function is a&#10;Bregman divergence.&#10;&#10;Let denote the convex hull of a set of orthogonal states. For let denote&#10;the function . Note that is decreasing and continuous from the left. Let&#10;and where for all . If is differentiable in then locality implies that&#10;Note that is a convex function and thereby it is continuous. Assume that&#10;is an arbitrary element in and let denote a sequence such that for The&#10;sequence can be choosen so that regret is differentiable in for all&#10;Further the sequence can be chosen such that is increasing for all Then&#10;Similarly, if the sequence can be chosen such that is increasing for all&#10;then which implies that and that for all . Therefore for all in the&#10;interior of . In the following calculations we will assume that the&#10;distributions lie in the interior of . The validity of the Bregman&#10;identity (\[eq:Bregmanid\]) follows directly from Equation \[eq:local\]&#10;implying that is a Bregman divergence.&#10;&#10;As a function of the regret is minimal when In the following&#10;calculations we write , , , and . If for then non-negativity of regret&#10;can be written as and we note that this inequality should hold as long&#10;as Permutation of and leads to the inequality that implies where&#10;&#10;Assume that in Inequality (\[eq:sym\]). Then so that is mid-point&#10;convex, which for a measurable function implies convexity. Therefore is&#10;differentiable from left and right.&#10;&#10;If and and then we have with equality when We differentiate with respect&#10;to from right. which is positive for so that Since is convex we have&#10;which in combination Inequality (\[eq:f\_ij\]) implies that so that is&#10;differentiable. Since the function is also differentiable.&#10;&#10;As a function of the Bregman divergence has a minimum at under the&#10;condition . Since the functions are differentiable we can characterize&#10;this minimum using Lagrange multipliers. We have and Further so there&#10;exist a constant such that Hence so that for some constant&#10;&#10;Now we get Therefore there exists an affine function defined on such&#10;that for all in the interior of . Since is continuous on Equation&#10;(\[eq:affinentropi\]) holds for any . If each of the sets and is a&#10;simplex and then so that If has dimension greater than zero then the&#10;right hand side is affine so the left hand side is affine, which is only&#10;possible when Therefore we also have for all Therefore the functions can&#10;be extended to a single affine function on the whole of">
  </outline>
</outline>
<outline text="Applications">
  <outline text="Information theory" _note="If only integer values of a code-length function are allowed then there&#10;are only finitely many actions that are not dominated. Therefore the&#10;function given by is piece-wise linear. In particular is not&#10;differentiable so that the regret is not a Bregman divergence and cannot&#10;be monotone according to Proposition \[prop:monoBreg\]. In information&#10;theory monotonicity of a divergence function is closely related to the&#10;DATA PROCESSING INEQUALITY and since the data processing inequality is&#10;one of the most important tools for deriving inequalities in information&#10;theory we need to modify our notion of code-length function in order to&#10;achieve a data processing inequality.&#10;&#10;We now formulate a version of Kraft’s inequality that allow the code&#10;length function to be non-integer valued.&#10;&#10;\[Theorem:Kraft\]Let be a function. Then the function satisfies Kraft’s&#10;inequality (\[eq:Kraft\]) if and only if for all there exists an integer&#10;and a uniquely decodable fixed-to-variable length block code such that&#10;where denotes the length divided by The uniquely decodable block code&#10;can be chosen to be prefix free.&#10;&#10;Assume that satisfies Kraft’s inequality. Then Therefore the function&#10;given by is integer valued and satisfies Kraft’s inequality&#10;(\[eq:Kraft\]) and there exists a prefix-free code such that Therefore&#10;so for any choose such that&#10;&#10;Assume that for all there exists a uniquely decodable fixed-to-variable&#10;length code such that for all strings Then satisfies Kraft’s&#10;Inequality(\[eq:Kraft\]) and Therefore for all and the result is&#10;obtained.&#10;&#10;Like in Bayesian statistics we focus on finite sequences. Contrary to&#10;Bayesian statistics we should always consider a finite sequence as a&#10;prefix of LONGER FINITE sequences. Contrary to frequential statistics we&#10;do not have to consider a finite sequence as a prefix of an INFINITE&#10;sequence.&#10;&#10;If we minimize the mean code-length over functions that satisfy Kraft’s&#10;inequality (\[eq:Kraft\]), but without an integer constraint the&#10;code-length should be and the function is given by The function is&#10;proportional to the Shannon entropy and the (negative) proportionality&#10;factor is determined by the size of the output alphabet.&#10;&#10;In lossy source coding and rate distortion theory it is important to&#10;choose a distortion function with tractable properties. The notion of&#10;sufficiency for divergence functions was introduced in in order to&#10;characterize such tractable distortions functions. In this paper the&#10;main result was that sufficiency together with properties related to&#10;Bregman divergence lead directly to the information bottleneck method&#10;introduced by N. Tishby . Logarithmic loss has also been studied for&#10;lossy compression in .">
  </outline>
  <outline text="Statistics" _note="In statistics one is often interested in scoring rules that are local,&#10;which means a scoring rule where the payoff only depends on the&#10;probability of the observed value and not on the predicted distribution&#10;over unobserved values. The notion of locality has recently been&#10;extended by Dawid, Lauritzen and Parry , but here we shall focus on the&#10;original definition. The basic result is that the only local strictly&#10;proper scoring rule is logarithmic score that was proved by Bernardo&#10;under the assumption that scoring rule is given by a smooth function .&#10;&#10;A LOCAL STRICTLY PROPER SCORING RULE is a scoring rule of the form&#10;&#10;On a finite space a local strictly proper scoring rule is given by a&#10;local regret function.&#10;&#10;The regret function of a local strictly proper scoring rule is given by&#10;If and and are mutually singular then and we see that the regret does&#10;not depend on because vanish on the support of Therefore the regret&#10;function is local.&#10;&#10;On a finite space with at least three elements a local strictly proper&#10;scoring rule is given by a function of the form for some constants and&#10;&#10;Also the notion of sufficiency plays an important role in statistics.&#10;Here we will restrict the discussion to 1-dimensional exponential&#10;families. A natural exponential family is a family of probability&#10;distributions of the form where is a reference measure on the real&#10;numbers and is the moment generating function given by . Then is a&#10;sufficient statistic for the family&#10;&#10;In a Bernoulli model a sequence is predicted with probability The&#10;function induces a sufficient map from probability distributions on to&#10;probability distributions on The reverse map maps a measure concentrated&#10;in into a uniform distributions over sequences that satisfy&#10;&#10;The mean value of is The set of possible mean values is called the mean&#10;value range and is an interval. Let denote the element in the&#10;exponential family with mean value Then a Bregman divergence on the mean&#10;value range is defined by Note that the mapping is not affine so the&#10;Bregman divergence will in general not be given by the formula for&#10;information divergence with the family of binomial distributions as the&#10;only exception. Nevertheless the Bregman divergence encode important&#10;information about the exponential family. In statistics it is common to&#10;use squared Euclidean distance as distortion measure, but often it is&#10;better to use the Bregman divergence as distortion measure. Note that is&#10;only proportional to squared Euclidean distance for the Gaussian&#10;location family.&#10;&#10;An exponential distribution has density This leads to a Bregman&#10;divergence on the interval given by This Bregman divergence is called&#10;the ISAKURA-SAITO DISTANCE. The Isakura-Saito distance is defined on an&#10;unbounded set so our previous results cannot be applied. Affine&#10;bijections on have the form for some constant . The Isakura-Saito&#10;distance obviously satisfy sufficiency for such maps and it is a simple&#10;exercise to check that the Isakura-Saito distance is the only Bregman&#10;divergence on that satisfies sufficiency. Any affine map is composed of&#10;a map where and a right translation where The Itakura-Saito distance&#10;decreases under right translations because Thus the Isakura-Saito&#10;distance is monotone.&#10;&#10;Both sufficiency and the Bregman identity are closely related to&#10;inference rules. In I. Csisz[á]{}r explained why information divergence&#10;is the only divergence function on the cone of positive measures that&#10;lead to tractable inference rules. One should observe that his inference&#10;rules are closely related to sufficiency and the Bregman identity, and&#10;the present paper may be view as a generalization of these results of I.&#10;Csisz[á]{}r.">
  </outline>
  <outline text="Statistical mechanics" _note="Statistical mechanics can be stated based on classical mechanics or&#10;quantum mechanics. For our purpose this makes no difference because our&#10;theorems are valid for both classical systems and quantum systems.&#10;&#10;As we have seen before Our general results for Bregman divergences imply&#10;that the Bregman divergence based on this exergy satisfies Therefore for&#10;any map that is sufficient for The equality holds for any regret&#10;function that is reversible and conserves the state that is in&#10;equilibrium with the environment. Since a different temperature of the&#10;environment leads to a different state that is in equilibrium the&#10;equality holds for any reversible map that leave some equilibrium state&#10;invariant. We see that is uniquely determined as long as there exists a&#10;sufficiently large set of maps that are reversible.&#10;&#10;In this exposition we have made some short-cuts. First of all we did not&#10;derive equation \[eq:Kelvin\]. In particular the notion of temperature&#10;was used without discussion. Secondly we identified the internal energy&#10;with the mean value of the Hamiltonian and identified the thermodynamic&#10;entropy with times the Shannon entropy. Finally, in the argument above&#10;we need to verify in all details that the set of reversible maps is&#10;sufficiently large to determine the regret function. For classical&#10;thermodynamics the most comprehensive exposition was done by Lieb and&#10;Yngvason . In their exposition randomness was not taken into account.&#10;With the present framework it is also possible to handle randomness so&#10;that one can make a bridge between thermodynamics and statistical&#10;mechanics. A detailed exposition will be given in a future paper.&#10;&#10;According to Equation (\[eq:Kelvin\]) any bit of information can be&#10;converted into an amount of energy! One may ask how this is related to&#10;the mixing paradox (a special case of Gibbs’ paradox). Consider a&#10;container divided by a wall with a blue and a yellow gas on each side of&#10;the wall. The question is how much energy can be extracted by mixing the&#10;blue and the yellow gas?&#10;&#10;(8.,5.) – (5.,5.) – (5.,3.) – (8.,3.) – cycle; (2.,5.) – (5.,5.) –&#10;(5.,3.) – (2.,3.) – cycle; (2.,2.) – (8.,2.) – (8.,0.) – (2.,0.) –&#10;cycle; (2.,5.)– (8.,5.); (8.,5.)– (8.,3.); (8.,3.)– (2.,3.); (2.,3.)–&#10;(2.,5.); (5.,5.)– (5.,3.);&#10;&#10;(2.,2.)– (8.,2.); (8.,2.)– (8.,0.); (8.,0.)– (2.,0.); (2.,0.)– (2.,2.);&#10;(5.,2.)– (5.,0.);&#10;&#10;We loose one bit of information about each molecule by mixing the blue&#10;and the green gas, but if the color is the ONLY DIFFERENCE no energy can&#10;be extracted. This seems to be in conflict with Equation&#10;(\[eq:Kelvin\]), but in this case different states cannot be converted&#10;into each other by reversible processes. For instance one cannot convert&#10;the blue gas into the yellow gas. To get around this problem one can&#10;restrict the set of preparations and one can restrict the set of&#10;measurements. For instance one may simply ignore measurements of the&#10;color of the gas. What should be taken into account and what should be&#10;ignored, can only be answered by an experienced physicist. Formally this&#10;solves the mixing paradox, but from a practical point of view nothing&#10;has been solved. If for instance the molecules in one of the gases are&#10;much larger than the molecules in the other gas then a semi-permeable&#10;membrane can be used to create an osmotic pressure that can be used to&#10;extract some energy. It is still an open question which differences in&#10;properties of the two gases that can be used to extract energy.">
  </outline>
  <outline text="Monotone regret for portfolios" _note="We know that in general a local regret function on a state space with at&#10;least three orthogonal states is proportional to information divergence.&#10;In portfolio theory we get the stronger result that monotonicity implies&#10;that we are in the situation of gambling introduced by Kelly .&#10;&#10;\[Theorem:proper\]Assume that none of the assets are dominated by a&#10;portfolio of other assets. If the regret function given by&#10;(\[eq:Bregman\]) is monotone then the regret function equals information&#10;divergence and the measures and are supported by distinct price relative&#10;vectors of the form , until&#10;&#10;If there are more than three price relative vectors then a monotone&#10;regret function is always proportional to information divergence which&#10;is a strict regret function. Therefore we may assume that there are only&#10;two price relative vectors. Assume that the regret function is not&#10;strict. Then the function defined by (\[eq:G\]) is not strictly convex.&#10;Assume that so that is affine between and . Let be a contraction around&#10;one of the end points of intersection between the state space and the&#10;line through and . Then monotonicity implies that so that is affine on&#10;the line between and . This holds for contractions around any point.&#10;Therefore is affine on the whole state space which implies that there is&#10;a single portfolio that dominates all assets. Such a portfolio must be&#10;supported on a single asset. Therefore monotonicity implies that if two&#10;assets are not dominated then the regret function is strict and&#10;according to Theorem \[strict\] we have already proved that a strict&#10;regret function in portfolio theory is proportional to information&#10;divergence.&#10;&#10;If the regret function divergence is monotone and one of the assets is&#10;the safe asset then there exists a portfolio such that for all&#10;Equivalently which is possible if and only if One say that the gamble is&#10;FAIR if . If the gamble is SUPER-FAIR, i.e. , then the portfolio gives a&#10;price relative equal to independently of what happens, which is a DUTCH&#10;BOOK.&#10;&#10;In portfolio theory the regret function given by (\[eq:Bregman\]) is&#10;monotone if and only if it is strict.&#10;&#10;We use that in portfolio theory the regret function is monotone if and&#10;only it is proportional to information.">
  </outline>
</outline>
<outline text="Concluding remarks" _note="In it was proved that if is a function such that the Bregman divergence&#10;based on is monotone on any (simple) C\*-algebra then the Bregman&#10;divergence is jointly convex. As we have seen that monotonicity implies&#10;that the Bregman divergence must be proportional to inform divergence,&#10;which is jointly convex in both arguments. We also see that in general&#10;joint convexity is not a sufficient condition for monotonicity, but in&#10;the case where the state space has only two orthogonal states it is not&#10;known if joint convexity of a Bregman divergence is sufficient to&#10;conclude that the Bregman divergence is monotone.&#10;&#10;One should note that the type of optimization presented in this paper is&#10;closely related to a game theoretic model developed by F. Topsøe . In&#10;his game theoretic model he needed what he called the [PERFECT MATCH&#10;PRINCIPLE]{}. Using the terminology presented in this paper the perfect&#10;match principle states that the regret function is a strict Bregman&#10;divergence. As we have seen the perfect match principle is only&#10;fulfilled in portfolio theory if all the assets are gambling assets.&#10;Therefore the theory of F. Topsøe can only be used to describe gambling&#10;while our optimization model can describe general portfolio theory and&#10;our sufficient conditions can explain exactly when our general model&#10;equals gambling.&#10;&#10;The original paper of Kullback and Leibler was called “On Information&#10;and Sufficiency”. In the present paper we have made the relation between&#10;information divergence and the notion of sufficiency more explicit. The&#10;results presented in this paper are closely related to the result that a&#10;divergence that is both an -divergence and a Bregman divergence is&#10;proportional to information divergence (see or and references therein).&#10;All -divergences satisfy a sufficiency condition, which is the reason&#10;why this class of divergences has played such a prominent role in the&#10;study of the relation between information theory and statistics. One&#10;major question has been to find reasons for choosing between the&#10;different -divergences. For instance -divergences of power type (often&#10;called Tsallis divergences or Cressie-Read divergences) are popular, but&#10;there are surprisingly few papers that can point at a single value of&#10;the power that is optimal for a certain problem except if this value is&#10;1. In this paper we have started with Bregman divergences because each&#10;optimization problem comes with a specific Bregman divergence. Often it&#10;is possible to specify a Bregman divergence for an optimization problem&#10;and only in some of the cases this Bregman divergence is proportional to&#10;information divergence.&#10;&#10;The idea of sufficiency has different relevance in different&#10;applications, but in all cases information divergence prove to be the&#10;quantity that convert the general notion of sufficiency into a number.&#10;In information theory information divergence appear as a consequence of&#10;Kraft’s inequality. For code length functions of integer length we get&#10;functions that are piecewise linear. Only if we are interested in&#10;extend-able sequences we get a regret function that satisfies a data&#10;processing inequality. In this sense information theory is a theory of&#10;extend-able sequences. For scoring functions in statistics the notion of&#10;locality is important. These applications do not refer to sequences.&#10;Similarly the notion of sufficiency that plays a major role in&#10;statistics, does not refer to sequences. Both sufficiency and locality&#10;imply that regret is proportional to information divergence, but these&#10;reasons are different from the reasons why information divergence is&#10;used in information theory. Our description of statistical mechanics&#10;does not go into technical details, but the main point is that the many&#10;symmetries in terms of reversible maps form a set of maps so large that&#10;our result on invariance of regret under sufficient maps applies. In&#10;this sense statistical mechanics and statistics both apply information&#10;divergence for reasons related to sufficiency. For portfolio theory the&#10;story is different. In most cases one has to apply the general theory of&#10;Bregman divergences because we deal with an optimization problem. The&#10;general Bregman divergences only reduce to information divergence when&#10;the assets are gambling assets.&#10;&#10;Often one talk about applications of information theory in statistics,&#10;statistical mechanics and portfolio theory. In this paper we have argued&#10;that information theory is mainly a theory of sequences, while some&#10;problems in statistics and statistical mechanics are also relevant&#10;without reference to sequences. It would be more correct to say that&#10;convex optimization has various application such as information theory,&#10;statistics, statistical mechanics, and portfolio theory and that certain&#10;conditions related to sufficiency lead to the same type of quantities in&#10;all these applications.">
</outline>
<outline text="Acknowledgment" _note="The author want to thank Prasad Santhanam for inviting me to the&#10;Electrical Engineering Department, University of Hawaii at Mānoa, where&#10;many of the ideas presented in this paper were developed. I also want to&#10;thank Alexander M[ü]{}ller-Hermes, Frank Hansen, and Flemming Tops[ø]{}e&#10;for stimulating discussions and correspondence. Finally I want to thank&#10;the reviewers for their valuable comments.&#10;&#10;[——-]{} \[1\][\#1]{}&#10;&#10;Kullback, S.; Leibler, R. On Information and Sufficiency. ,&#10;[22]{}, 79–86.&#10;&#10;Jaynes, E.T. Information Theory and Statistical Mechanics, [I]{} and&#10;[II]{}. , [106 AND 108]{}, 620–630 and 171–190.&#10;&#10;Jaynes, E.T. Clearing up mysteries – The original goal. In [MAXIMUM&#10;ENTROPY AND [B]{}AYESIAN METHODS]{}; Skilling, J., Ed.; Kluwer:&#10;Dordrecht, 1989.&#10;&#10;Liese, F.; Vajda, I. ; Teubner: Leipzig, 1987.&#10;&#10;Barron, A.R.; Rissanen, J.; Yu, B. The Minimum Description Length&#10;Principle in Coding and Modeling. , [44]{}, 2743–2760. Commemorative&#10;issue.&#10;&#10;Csisz[á]{}r, I.; Shields, P. ; Foundations and Trends in Communications&#10;and Information Theory, Now Publishers Inc., 2004.&#10;&#10;Gr[ü]{}nwald, P.D.; Dawid, A.P. Game Theory, Maximum Entropy, Minimum&#10;Discrepancy, and Robust [B]{}ayesian Decision Theory. , [&#10;32]{}, 1367–1433.&#10;&#10;Gr[ü]{}nwald, P. ; MIT Press, 2007.&#10;&#10;Holevo, A.S. ; Vol. 1, [NORTH-HOLLAND SERIES IN STATISTICS AND&#10;PROBABILITY]{}, North-Holland: Amsterdam, 1982.&#10;&#10;Krumm, M.; Barnum, H.; Barrett, J.; M[ü]{}ller, M. Thermodynamics and&#10;the structure of quantum theory. arXiv:1608.04461.&#10;&#10;Barnum, H.; M[ü]{}ller, M.P.; Ududec, C. Higher-order interference and&#10;single-system postulates characterizing quantum theory. ,&#10;[16]{}, 123029.&#10;&#10;Harremo[ë]{}s, P. Maximum Entropy and Sufficiency. Proceedings&#10;MaxEnt2016. American Institute of Physics (AIP), 2016, [[&#10;\[arXiv:1607.02259\]]{}](http://xxx.lanl.gov/abs/arXiv:1607.02259).&#10;&#10;Harremo[ë]{}s, P. Quantum information on Spectral Sets. arXiv:1701.06688&#10;Accepted for presentation at ISIT 2017.&#10;&#10;Servage, L.J. The Theory of Statistical Decision. , [46]{}, 55–67.&#10;&#10;Kiwiel, K.C. Proximal Minimization Methods with Generalized Bregman&#10;Functions. , [ 35]{}, 1142–1168, [[&#10;\[http://dx.doi.org/10.1137/S0363012995281742\]]{}](http://xxx.lanl.gov/abs/http://dx.doi.org/10.1137/S0363012995281742).&#10;&#10;Kiwiel, K.C. Free-steering Relaxation Methods for Problems with Strictly&#10;Convex Costs and Linear Constraints. , [22]{}, 326–349.&#10;&#10;Rockafellar, R.T. ; Princeton Univ. Press: New Jersey, 1970.&#10;&#10;Hendrickson, A.D.; Buehler, R.J. Proper scores for probability&#10;forecasters. , [42]{}, 1916–1921.&#10;&#10;Rao, C.R.; Nayak, T.K. Cross Entropy, Dissimilarity Measures, and&#10;Characterizations of Quadratic Entropy. , [31]{}, 589–593.&#10;&#10;Banerjee, A.; Merugu, S.; Dhillon, I.S.; Ghosh, J. Clustering with&#10;[B]{}regman Divergences. , [ 6]{}, 1705–1749.&#10;&#10;arthy, J. Measures of the value of information. , [42]{}, 654–655.&#10;&#10;Gneiting, T.; Raftery, A.E. Strictly Proper Scoring Rules, Prediction,&#10;and Estimation. , [102]{}, 359–378, [[&#10;\[http://dx.doi.org/10.1198/016214506000001437\]]{}](http://xxx.lanl.gov/abs/http://dx.doi.org/10.1198/016214506000001437).&#10;&#10;Ovcharov, E.Y. Proper Scoring Rules and Bregman Divergences. Sept. 2015.&#10;arXiv:1502.01178.&#10;&#10;Gundersen, T. An Introduction to the Concept of Exergy and Energy&#10;Quality. Technical report, Department of Energy and Process Engineering,&#10;Norwegian University of Science and Technology, Trondheim, Norway, 2011.&#10;http://www.ivt.ntnu.no/ept/fag/tep4120/innhold/Exergy Harremo[ë]{}s, P.&#10;; Vol. 255, [ IMFUFA-TEKST]{}, IMFUFA Roskilde University, 1993.&#10;Original in Danish entitled Tid og Betinget Uafh[æ]{}ngighed. English&#10;translation partially available.&#10;&#10;Kelly, J.L. A New Interpretation of Information Rate. , [35]{}, 917–926.&#10;&#10;Cover, T.; Thomas, J.A. ; Wiley, 1991.&#10;&#10;Uhlmann, A. On the [S]{}hannon Entropy and Related Functionals on Convex&#10;Sets. , [1]{}, 147–159.&#10;&#10;M[ü]{}ller-Hermes, A.; Reeb, D. Monotonicity of the Quantum Relative&#10;Entropy Under Positive Maps. , [[ \[Sept. 2016.&#10;arXiv:1512.06117v2\]]{}](http://xxx.lanl.gov/abs/Sept. 2016. arXiv:1512.06117v2).&#10;&#10;Christandl, M.; M[ü]{}ller-Hermes, A. Relative Entropy Bounds on&#10;Quantum, Private and Repeater Capacities. April, 2016. arXiv:1604.03448.&#10;&#10;Petz, D. Monotonicity of Quantum Relative Entropy Revisited. ,&#10;[15]{}, 79–91, [[&#10;\[http://www.worldscientific.com/doi/pdf/10.1142/S0129055X03001576\]]{}](http://xxx.lanl.gov/abs/http://www.worldscientific.com/doi/pdf/10.1142/S0129055X03001576).&#10;&#10;Petz, D. Sufficiency of Channels over von [N]{}eumann algebras. ,&#10;[39]{}, 97–108,.&#10;&#10;Jen[č]{}ov[á]{}, A.; Petz, D. Sufficiency in quantum statistical&#10;inference. , [ 263]{}, 259–276.&#10;&#10;Harremo[ë]{}s, P.; Tishby, N. The Information Bottleneck Revisited or&#10;How to Choose a Good Distortion Measure. Proceedings ISIT 2007, Nice.&#10;IEEE Information Theory Society, 2007, pp. 566–571.&#10;&#10;Jiao, J.; amd Albert No, T.C.; Venkat, K.; Weissman, T. Information&#10;Measures: the Curious Case of the Binary Alphabet. , [60]{}, 7616–7626.&#10;&#10;Jen[č]{}ov[á]{}, A. Preservation of a quantum [R]{}[é]{}nyi relative&#10;entropy implies existence of a recovery map. , [50]{}, 085303.&#10;&#10;Tishby, N.; Pereira, F.; Bialek, W. The information bottleneck method.&#10;Proceedings of the 37-th Annual Allerton Conference on Communication,&#10;Controland Computing, 1999, pp. 368–377.&#10;&#10;No, A.; Weissman, T. Universality of logarithmic loss in lossy&#10;compression. 2015 IEEE International Symposium on Information Theory&#10;(ISIT), 2015, pp. 2166–2170.&#10;&#10;Dawid, A.P.; Lauritzen, S.; Perry, M. Proper local scoring rules on&#10;discrete sample spaces. , [40]{}, 593–603.&#10;&#10;Bernardo, J.M. Expected Information as Expected Utility. ,&#10;[7]{}, 686–690. Institute of Mathematical Statistics.&#10;&#10;Csisz[á]{}r, I. Why least squares and maximum entropy? An axiomatic&#10;approach to inference for linear inverse problems. , [19]{}, 2032–2066.&#10;&#10;Lieb, E.; Yngvason, J. A Guide to Entropy and the Second Law of&#10;Thermodynamics. , [45]{}, 571–581.&#10;&#10;Lieb, E.; Yngvason, J., The Mathematics of the Second Law of&#10;Thermodynamics. In [VISIONS IN MATHEMATICS]{}; Alon, N.; Bourgain, J.;&#10;Connes, A.; Gromov, M.; Milman, V., Eds.; Birkh[ä]{}user Basel, 2010;&#10;pp. 334–358.&#10;&#10;Pitrik, J.; Virosztek, D. On the Joint Convexity of the Bregman&#10;Divergence of Matrices. , [ 105]{}, 675–692.&#10;&#10;Tops[ø]{}e, F. Game theoretical optimization inspired by information&#10;theory. , [43]{}, 553.&#10;&#10;Tops[ø]{}e, F. Cognition and Inference in an Abstract Setting.&#10;Proceedings WITMSE 2011, 2011.&#10;&#10;Amari, S.I. -Divergence Is Unique, Belonging to Both -Divergence and&#10;Bregman Divergence Classes. , [ 55]{}, 4925–4931.">
</outline>
  </body>
</opml>