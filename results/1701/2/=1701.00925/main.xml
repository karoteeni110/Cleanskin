<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>Warped Gaussian Processes Occupancy Mapping with Uncertain Inputs</title>
    <abstract>In this paper, we study extensions to the Gaussian Processes (GPs)
continuous occupancy mapping problem. There are two classes of occupancy
mapping problems that we particularly investigate. The first problem is
related to mapping under pose uncertainty and how to propagate pose
estimation uncertainty into the map inference. We develop expected
kernel and expected sub-map notions to deal with uncertain inputs. In
the second problem, we account for the complication of the robot’s
perception noise using Warped Gaussian Processes (WGPs). This approach
allows for non-Gaussian noise in the observation space and captures the
possible nonlinearity in that space better than standard GPs. The
developed techniques can be applied separately or concurrently to a
standard GP occupancy mapping problem. According to our experimental
results, although taking into account pose uncertainty leads, as
expected, to more uncertain maps, by modeling the nonlinearities present
in the observation space WGPs improve the map quality. </abstract>
  </head>
  <body>
<outline text="INTRODUCTION" _note="many scenarios such as robotic navigation, the robot pose is partially&#10;observable; and we have access only to an estimate (noise-corrupted&#10;version) of the robot pose, as depicted in&#10;Figure \[fig:intel\_posecov\]. Under these circumstances, the robot&#10;requires to navigate in an uncertain environment , and the probability&#10;distribution of the robot pose will be the input for the mapping&#10;problem. In practice, and based on the application, most of the&#10;occupancy mapping techniques ignore robot pose uncertainty for map&#10;representation; either for efficiency or as the resultant map is not&#10;suitable for navigation. Furthermore, dense representation of the state&#10;often makes uncertainty propagation intractable. This problem is not&#10;unique to GAUSSIAN PROCESSES OCCUPANCY MAPS (GPOMs), but it is also&#10;present in OCCUPANCY GRID MAPS. With this motivation, we study the&#10;problem of GP occupancy mapping under pose uncertainty. The first&#10;solution is uncertainty propagation through KERNEL functions. The second&#10;solution we propose uses the EXPECTED SUB-MAP notion to incorporate pose&#10;uncertainties into the map building process.&#10;&#10;The second problem studied is motivated by the fact that due to the&#10;smoothness common in the resultant regressed maps, inferring a&#10;high-quality map compatible with the actual shape of the environment is&#10;non-trivial . Furthermore, for a complicated task such as robotic&#10;mapping , the additive white Gaussian noise assumption in standard GPs&#10;can be simplistic. To account for these problems, we improve the&#10;incremental GPOM technique using WARPED GAUSSIAN PROCESSES (WGPs) . The&#10;core idea is to map the target values through a warping (transforming)&#10;function to capture the nonlinear behavior of the observations.&#10;&#10;We tackle the mentioned problems to improve map quality and provide&#10;results using incremental WGP Occupancy Maps (WGPOMs) under pose&#10;uncertainty.">
  <outline text="Notation" _note="Probabilities and probability densities are not distinguished in&#10;general. Matrices are capitalized in bold, such as in , and vectors are&#10;in lower case bold type, such as in . Vectors are column-wise and means&#10;integers from to . The Euclidean norm is shown by . and denote the trace&#10;and the determinant of matrix , respectively. Random variables, such as&#10;, and their realizations, , are sometimes denoted interchangeably.&#10;denotes a reference to the -th element of the variable. An alphabet such&#10;as denotes a set. A reference to a test set quantity is shown by . The&#10;-by- identity matrix is denoted by . The sign function, and the absolute&#10;value are denoted by , and , respectively. Finally, and denote the&#10;expected value and variance of a random variable, respectively.">
  </outline>
  <outline text="Outline" _note="A review of related works is given in the following section. We first&#10;discuss the problem of Gaussian processes occupancy mapping under pose&#10;uncertainty in Section \[sec:uncertainpose\]; followed by presenting the&#10;warped Gaussian processes occupancy mapping in Section \[sec:Warped\].&#10;Robotic mapping experiments are presented in Section \[sec:wgpomres\],&#10;and finally, Section \[sec:conclusion\] concludes the paper.">
  </outline>
</outline>
<outline text="Related Work" _note="Current robotic navigation algorithms rely on a dense environment&#10;representation for safe navigation. Occupancy grid maps are the standard&#10;way of environment representation in robotics and are the natural choice&#10;for online implementations . However, they simplify the mapping problem&#10;to a set of independent cells and estimate the probability of occupancy&#10;for each cell by ignoring the correlation between them. The map&#10;posterior is then approximated as the product of its marginals.&#10;&#10;The FastSLAM algorithm  exploits RAO-BLACKWELLIZED PARTICLE FILTERS ,&#10;and relies on the fact that, given the robot trajectory, landmarks are&#10;conditionally independent. In practice, FastSLAM can generate accurate&#10;maps; however, it suffers from degeneracy and depletion problems . Full&#10;SLAM methods estimate the SMOOTHING DISTRIBUTION of the robot trajectory&#10;and the map, given all available data. In robotics, full SLAM using&#10;probabilistic graphical models representation and the MAXIMUM A&#10;POSTERIORI estimate derived by solving a nonlinear least squares&#10;problem  can be considered the state-of-the-art and we thus focus our&#10;attention on using a pose-graph estimation of the robot trajectory as&#10;in .&#10;&#10;Kernel methods in the form of Gaussian processes (GPs) framework  are&#10;non-parametric regression and classification techniques that have been&#10;used to model spatial phenomena . The development of GPOM is discussed&#10;in . The incremental GP map building using the Bayesian Committee&#10;Machine (BCM) technique  is developed in  and for online applications&#10;in . In , the Hilbert maps technique is proposed and is more scalable.&#10;However, it is an approximation for continuous occupancy mapping and&#10;produces maps with less accuracy than GPOM.&#10;&#10;Approximate methods for uncertainty propagation into GPs models through&#10;kernel functions are proposed in , and developed for GPOM in . Generally&#10;speaking, training and query points can both be noisy. In , the problem&#10;of prediction at an uncertain input is discussed while it is assumed the&#10;input in training data is noise free. In , using a similar approach, the&#10;idea is extended to account for noisy training input. Similarly, we&#10;assume the input in training data is uncertain and query points are&#10;deterministic. In this paper, we employ this technique and develop the&#10;expected sub-map technique for approximate uncertainty propagation, then&#10;incorporate both techniques into the WGPOM framework.">
</outline>
<outline text="Mapping under Pose Uncertainty" _note="The main challenge in building occupancy maps under robot pose&#10;uncertainty is the dense representation of map belief which makes&#10;uncertainty propagation computationally expensive. Maximum likelihood&#10;dense map representations are currently the common practice which does&#10;not necessarily produce correct maps, especially if pose estimation&#10;uncertainties are significant. This popularity can be understood from&#10;the fact that employing an environment representation constructed with&#10;significant uncertainties results in vague obstacles and free space and&#10;is not suitable for robotic motion planning and navigation. However,&#10;accounting for pose uncertainties in mapping is not only important for&#10;correct map representations, but also for motion planning (prediction)&#10;tasks.">
  <outline text="Problem Statement and Formulation" _note="Let be the set of possible static occupancy maps. We consider the map of&#10;the environment as an -tuple random variable whose elements are&#10;described by a normal distribution . Let be the set of spatial&#10;coordinates to build a map on. Let be a noisy measurement (class label;&#10;and for unoccupied and occupied, respectively) at a noisy sample , where&#10;and . Define a training set which consists of noisy measurements at&#10;noisy locations. Let function , i.e. , be the real underlying process&#10;that we model as a Gaussian process , where is the COVARIANCE FUNCTION&#10;or KERNEL; and and are either in the training or the test (query) sets.&#10;Estimate , i.e. the map posterior probability given a noisy training&#10;set. For a given query point in the map, , GP predicts a mean, , and an&#10;associated variance, . We can write . To show a valid probabilistic&#10;representation of the map , the classification step squashes data into&#10;the range .&#10;&#10;We propose two methods to solve the defined problem. The first approach&#10;is based on the EXPECTED KERNEL. The alternative approach, EXPECTED&#10;SUB-MAP, treats all inputs deterministically and propagates pose&#10;uncertainties through uncertain map fusion. The following assumptions&#10;are made in the present work:&#10;&#10;In the problem of Gaussian processes occupancy mapping under robot pose&#10;uncertainty, query points are deterministic.&#10;&#10;\[assump:statcov\] The covariance function in the expected sub-map&#10;method is stationary, .&#10;&#10;Using Assumption \[assump:statcov\], map inference in the local&#10;coordinates of the robot (local map) can be done using deterministic&#10;inputs.">
  </outline>
  <outline text="System Dynamics" _note="The equation of motion of the robot is governed by the nonlinear&#10;partially observable equation as follows. moreover, with appropriate&#10;linearization at the current state estimate, we can predict the state&#10;covariance matrix as where and are the Jacobian matrices calculated with&#10;respect to and , respectively.">
  </outline>
  <outline text="Expected Kernel" _note="The core idea in the expected kernel approach is taking an expectation&#10;of the covariance function over uncertain inputs. Let be distributed&#10;according to a probability distribution . The expected covariance&#10;function can be computed as In general, this integral is analytically&#10;intractable; therefore we employ two numerical approximations to solve .&#10;However, for the case of the squared exponential (SE) kernel, a&#10;closed-form solution exists . Hence, once the expected covariance matrix&#10;is calculated, we can compute the predictive conditional distribution&#10;for a single query point similar to standard GPs.">
    <outline text="Monte Carlo Integration" _note="Since we assume the distribution of the uncertain input is known, by&#10;drawing independent samples, , from and using a Monte-Carlo technique,&#10;we can approximate Equation  by where is the covariance function&#10;computed at .&#10;&#10;In Equation , the covariance and cross-covariance are both denoted as .&#10;Depending on the input, the integration is only performed on training&#10;points as it is assumed query points are deterministic.">
    </outline>
    <outline text="Gauss-Hermite Quadrature" _note="Gauss-Hermite quadrature  of integrals of the kind are given by . The&#10;multi-variate normal distribution of noisy input is given by . Through a&#10;change of variable such that and , where is a lower triangular matrix&#10;that can be calculated using a Cholesky factorization, the Equation  can&#10;be approximated as where , are the roots of the Hermite polynomial , ,&#10;and is the covariance function computed at . When , we can simplify&#10;Equation  and write .&#10;&#10;We assumed points from the map spatial support, , are global&#10;coordinates. In practice, to transform local points, an unscented&#10;transform  is used to reduce linearization errors .&#10;&#10;An illustrative example of GP regression where inputs are uncertain is&#10;shown in Figure \[fig:ek\_toy\_eg\]. By propagating the input&#10;uncertainty using the expected kernel, the output does not follow the&#10;observations exactly yet remains consistent as the underlying function&#10;is within the estimated uncertainty bounds.">
    </outline>
  </outline>
  <outline text="Expected Sub-map" _note="We exploit the fact that a stationary covariance function does not&#10;depend on the selected coordinates, i.e. the global or a local sub-map&#10;frame. Therefore, we treat all training inputs as noise free and conduct&#10;map inference using deterministic inputs in the local (sensor/robot)&#10;frame. To fuse the inferred sub-map into the global map, we draw&#10;independent samples from . In other words, by taking the expectation&#10;over the location of the sub-map, we propagate uncertainty of each map&#10;point to its neighborhood. Thus, we have , and by drawing independent&#10;samples from and using a Monte-Carlo approximation it follows that .&#10;Note that any sub-map can be fused into the global map using the&#10;algorithms in . However, as a result of sampling, the expected map, , is&#10;similar to a mixture distribution; therefore, the mean and variance&#10;calculations need to be addressed accordingly. We present the following&#10;proposition to calculate the first two moments of .&#10;&#10;\[lem:meanvarmix\] Let be random variables that are distributed&#10;according to probability densities , with constant weights , where . The&#10;probability density function of the mixture is . Given and , the mean&#10;and variance of the mixture density is given by and .&#10;&#10;The proof follows from the fact that for the -th moment of the mixture,&#10;we can write and define the variance accordingly.&#10;&#10;In incremental map building, to compute , sampled sub-maps can be fused&#10;into the global map using the following equations where is the updated&#10;global map built using the -th independently drawn robot pose sample,&#10;and and can be computed point-wise for every map point .&#10;&#10;The proof directly follows from Lemma \[lem:meanvarmix\].&#10;&#10;Therefore, we can perform incremental map fusion by considering the&#10;robot pose uncertainty without modifying the GP framework.">
  </outline>
</outline>
<outline text="Warped GP Occupancy Mapping" _note="The primary challenge in modeling the environment “accurately” is the&#10;different nature of free and occupied classes. Free space tends to span&#10;vast areas while occupied space often represents the structural shape of&#10;the environment. In addition, the assumption of additive Gaussian noise&#10;in the observations in standard GPs is unable to capture complexity in&#10;observations appropriately. We propose to employ Warped Gaussian&#10;Processes to account for the nonlinear behavior of observations. This&#10;method is appealing as it allows for non-Gaussian noise in the&#10;observation space. However, exact inference is not possible anymore, and&#10;approximate inference algorithms such as EXPECTATION PROPAGATION  or&#10;VARIATIONAL BAYES  are required.&#10;&#10;The idea to accommodate non-Gaussian distributions and noise is to use a&#10;nonlinear monotonic function for warping (transforming) the observation&#10;space . Let be a transformation from the observation space to a latent&#10;space as where denotes the vector of warping function hyperparameters&#10;and is the vector of latent targets. Now we can re-write the GP&#10;formulation for the latent target and by accounting for the&#10;transformation between a true observation and the latent target, the&#10;negative log of the marginal likelihood (NLML) can be written as in&#10;which the last term is the Jacobian of the defined transformation. To&#10;compute the mean at a new test point, it is possible to calculate the&#10;expectation of the inverse warping function over the latent target&#10;predictive density, therefore This integral can be computed numerically&#10;using Gauss-Hermite quadrature with a weighted sum of the inverse&#10;warping function .&#10;&#10;Inspired by the neural network transfer functions, a sum of hyperbolic&#10;tangent functions satisfies the requirements for the transformation to&#10;be monotonic and at the same time allowing for complicated mappings.&#10;With hyperparameters vector , the function can be defined as where the&#10;parameter is the number of steps and has to be set depending on the&#10;complexity of observations, , , and . Alternative warping functions can&#10;be polynomials ():&#10;&#10;Figure \[fig:toy\_eg\] shows a simple yet challenging example for&#10;regression using standard and Warped GPs. The measurements are corrupted&#10;by an additive Gaussian noise. Even though the noise is still Gaussian,&#10;the complicated structure of the underlying function makes modeling it&#10;non-trivial. Note that the inputs are deterministic.&#10;&#10;By increasing the number of training points, it is possible to generate&#10;more accurate results using standard GPs. However, given the cubic time&#10;complexity of GPs, dense training datasets reduce the scalability of the&#10;algorithms significantly.">
</outline>
<outline text="Results and Discussion" _note="We now present results from experiments using a synthetic dataset and a&#10;real publicly available pose-graph dataset. The synthetic dataset,&#10;Figure \[fig:synmap\_setup\], is built in such a way as to highlight the&#10;strength of WGPOM to model complicated structural shapes and to better&#10;appreciate the mapping performance of the incremental GPOM and WGPOM&#10;under the expected kernel (EK) and expected sub-map (ESM) uncertainty&#10;propagation techniques. On the other hand, the Intel dataset , as shown&#10;in Figure \[fig:intel\_posecov\], exposes an extreme real-world example&#10;of the problem at hand where highly uncertain robot poses along the&#10;estimated trajectory are present.&#10;&#10;We compare the overall taken time to build the entire map (using all the&#10;available data) as well as the map accuracy using the Area Under the&#10;receiving operating characteristic Curve (AUC) . For each model, we&#10;learn the hyperparameters at the first increment of map building by&#10;minimization of the NLML using the first set of training data with&#10;manual supervision to ensure the best possible outcome for all models.&#10;The data processing and computations for the incremental map building&#10;are implemented using MATLAB.&#10;&#10;\&#10;&#10;\&#10;">
  <outline text="First Experiment: Motion Uncertainty Effect" _note="The map of the environment, the robot trajectory, the observations&#10;collected at each pose using a simulated rangefinder sensor, together&#10;with the evolution of the robot pose uncertainty due to its motion&#10;noise, are illustrated in Figure \[fig:synmap\_setup\]. The uncertainty&#10;ellipsoids show the worst-case covariance of the robot position, and&#10;there is no uncertainty reduction along the path by closing loops.&#10;&#10;Details from the model selection, compared techniques, and conducted&#10;experiments are collected in Table \[tab:starexpsetup\]. We use Matérn&#10;() covariance function for GPOM as its performance has been shown&#10;fitting in earlier works . For WGPOM, we use SE covariance function with&#10;Automatic Relevance Determination (ARD) . Since the observations do not&#10;cover the entire map, we use with as the warping function to improve the&#10;extrapolation ability of GPs (Figure \[fig:toy\_eg\]). The experiment&#10;for each mapping technique using EK and ESM uncertainty propagation is&#10;repeated by increasing the robot motion noise covariance in five steps.&#10;In Figure \[fig:synmap\_qplot\], the map accuracy and runtime&#10;comparisons of all methods using AUC are shown. In the bottom plot, the&#10;runtime for the ESM is higher than the EK for both mapping techniques.&#10;From the top plot, we can see that applying WGPs improves the map&#10;quality regardless of the uncertainty propagation choice. The expected&#10;kernel is computed using Gauss-Hermite quadrature with sample points,&#10;and the expected sub-map computations are performed using Monte-Carlo&#10;approximations with samples. When increasing the number of samples from&#10;to we did not observe any improvement in the map accuracy.&#10;&#10;Figure \[fig:startest\] illustrates the results of all combinations of&#10;the proposed techniques. GPOM and WGPOM by ignoring the robot pose&#10;uncertainty are shown in Figures \[fig:gpom\_startest\] and&#10;\[fig:wgpom\_startest\], respectively. WGPOM demonstrates a better&#10;discrimination performance between class labels in the absence of&#10;measurements. This effect can be seen in the middle of the smaller star&#10;in both maps. Note that further optimization of hyperparameters can lead&#10;to over-fitting instead of solving the discussed problem.&#10;&#10;Even though ESM and EK try to achieve the same goal, they demonstrate&#10;different behaviors. Generally speaking, integration over the covariance&#10;function (EK) has a smoothing effect that sometimes can be desirable.&#10;For example, in all the presented maps the central part of the map due&#10;to the lack of observation is partially complete. As a result of this&#10;smoothing effect of the EK, this part is correctly classified to be&#10;closer to the free space class. However, the probabilities are closer to&#10;, and the robot cannot be completely confident about the status of the&#10;area. Alternatively, ESM leads to relatively more confident maps with&#10;smaller smoothing effects. The resultant maps are safer for navigation&#10;as the gap between occupied and unoccupied areas is classified as an&#10;unknown region. While this behavior can be an appealing property from a&#10;motion planning point of view, the occupied areas are faded; and we&#10;cannot see the structural shape of the environment accurately. Overall,&#10;by propagating more uncertainty into the map inference process, we&#10;expect less accuracy in the outcome and more realistic estimation of the&#10;belief. However, WGPs by modeling nonlinearity in the observation space&#10;improve the map quality.">
  </outline>
  <outline text="Experimental Results" _note="The experimental results of occupancy mapping using the Intel dataset&#10;are shown in Table \[tab:intelaucroc\] and Figure \[fig:Intel\_warp\].&#10;In the absence of a complete groundtruth map, the groundtruth map for&#10;this dataset is generated using the estimated robot trajectory and&#10;rangefinder measurements. In this way, the groundtruth map has the same&#10;orientation which makes the comparison convenient. The covariance&#10;function used is an intrinsically sparse kernel . The logic behind this&#10;choice is that the structural shape of the environment is complex, and&#10;it is cluttered with random people and typical office furniture;&#10;therefore, using a covariance function that correlates map points over a&#10;long range is not suitable. We use the Sparse covariance function for&#10;both GPOM and WGPOM and their corresponding uncertainty propagation&#10;experiments.&#10;&#10;\[tab:intelaucroc\]&#10;&#10;Table \[tab:intelaucroc\] shows the runtime and accuracy comparison of&#10;the mapping techniques. In this scenario, where the pose uncertainties&#10;are ignored, GPOM performs marginally better than WGPOM. This result,&#10;shown in Figures \[fig:intel\_gpom\] and \[fig:intel\_wgpom\], can be&#10;understood from the fact that WGPOM has covered more partially observed&#10;areas in the map. While this is desirable, in the absence of a complete&#10;groundtruth map, it leads to a lower AUC. However, WGPOM maintains more&#10;accurate maps by incorporating the pose uncertainties which is the&#10;actual problem to be solved.&#10;&#10;\&#10;&#10;In this experiment, the uncertainty propagation using the ESM method&#10;leads to poor map qualities and the maps, shown in&#10;Figures \[fig:intel\_esm\] and \[fig:intel\_wesm\], are almost entirely&#10;faded due to the significant pose uncertainties resulting from the robot&#10;repeatedly traveling through the same areas. This fading effect could be&#10;partially mitigated by increasing the number of samples, but based on&#10;the runtimes in Table \[tab:intelaucroc\], it is not justifiable.&#10;Nevertheless, WGPOM using the EK demonstrates a better performance in&#10;comparison to all methods that incorporated pose uncertainties;&#10;moreover, it produces a map that is also usable for navigation tasks,&#10;i.e. obstacle avoidance, and path planning.">
  </outline>
  <outline text="Discussion and Limitations" _note="Uncertainty propagation through the developed methods can provide safer&#10;maps for robotic navigation. However, long-term uncertainty propagation&#10;leads to highly faded maps. If the uncertainty at each step is large and&#10;the robot cannot improve the localization confidence through&#10;loop-closures, this fading effect is more severe. Also, the uncertainty&#10;of the robot orientation has a large impact on the map quality. As we&#10;have seen in the presented results, in the expected sub-map approach, if&#10;the orientation uncertainty is significant, integration using a small&#10;number of samples leads to poor map accuracies. The expected kernel&#10;technique has an advantage from this perspective, as the unscented&#10;transform maps the measurement into the map space, and samples are&#10;related to the map spatial dimensions.&#10;&#10;It is also demonstrated that the concept of accounting for possible&#10;nonlinearities in the observation space, here through the warping&#10;function, has desirable effects on the map quality. Our results showed&#10;that regardless of the uncertainty propagation technique, applying WGPs&#10;provide better maps than standard GPs. We reiterate that by ignoring the&#10;robot pose uncertainty, the map is a potentially incorrect&#10;representation of the environment.&#10;&#10;Finding an appropriate warping function that is compatible with&#10;non-Gaussianity in the observation space can be time-consuming unless&#10;the model selection is performed in a more systematic way. In this work,&#10;we tried several functions and chose the best one. Moreover, since the&#10;exact inference is not possible, approximate methods may not always&#10;converge. Although the upper-bound time complexity of WGPOM is similar&#10;to that of GPOM, in practice for larger datasets the inference takes&#10;longer. Improving the computational efficiency of the proposed methods&#10;is an interesting direction to follow.">
  </outline>
  <outline text="Computational Complexity" _note="For both GPOM and WGPOM, the worst-case time complexity is cubic in the&#10;number of training data, . For ESM, the number of sub-map fusion into&#10;the global map scales linearly with the number of samples, , and the&#10;sub-map fusion involves a nearest neighbor query for each test point&#10;resulting in . In the case of two-dimensional mapping, using&#10;Gauss-Hermite quadrature, the time complexity of EK computation is&#10;quadratic in the number of sample points and together with sub-map&#10;fusion leads to . In EK, applying the unscented transform to all&#10;training points involves a Cholesky factorization of the input&#10;covariance matrix which is ignored for the two-dimensional case.">
  </outline>
</outline>
<outline text="CONCLUSION" _note="In this paper, we studied incremental GP occupancy mapping extensions&#10;through warped GPs. Since occupancy maps have dense belief&#10;representations, the robot pose uncertainty is often ignored. We&#10;proposed two methods to incorporate robot pose uncertainty into the map&#10;inference, the expected kernel and the expected sub-map. While the&#10;expected kernel handles the input uncertainty within the GPs framework,&#10;the expected sub-map exploits the inherent property of stationary&#10;covariance functions for map inference in the local frame with&#10;deterministic inputs. The proposed methods can also be useful if the&#10;belief representation is not dense (as opposed to occupancy mapping).&#10;Furthermore, the WGPOM technique can deal with the nonlinear behavior of&#10;measurements through a nonlinear transformation which improves the&#10;ability of GPs to learn complex structural shapes more accurately,&#10;especially, under uncertain inputs.&#10;&#10;Future work includes further examinations of the proposed methods in&#10;practical robotic exploration and obstacle avoidance scenarios, for&#10;example, using currently popular visual-inertial odometry systems.">
</outline>
  </body>
</opml>