<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract>We present the Overlapping Domain Cover (ODC) notion for kernel
machines, as a set of overlapping subsets of the data that covers the
entire training set and optimized to be spatially cohesive as possible.
We show how this notion benefit the speed of local kernel machines for
regression in terms of both speed while achieving while minimizing the
prediction error. We propose an efficient ODC framework, which is
applicable to various regression models and in particular reduces the
complexity of Twin Gaussian Processes (TGP) regression from cubic to
quadratic. Our notion is also applicable to several kernel methods
(Gaussian Process Regression(GPR) and IWTGP regression, as shown in our
experiments). We also theoretically justified the idea behind our method
to improve local prediction by the overlapping cover. We validated and
analyzed our method on three benchmark human pose estimation datasets
and interesting findings are discussed. </abstract>
  </head>
  <body>

  </body>
</opml>