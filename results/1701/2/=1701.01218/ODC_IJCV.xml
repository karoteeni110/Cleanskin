<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>Overlapping Cover Local Regression Machines</title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Introduction">
</outline>
<outline text="Background on Full GPR and TGP Models">
</outline>
<outline text="Related Work on Approximation Methods">
</outline>
<outline text="ODC Framework">
  <outline text="Training">
  </outline>
  <outline text="Prediction">
  </outline>
</outline>
<outline text="Experimental Results">
</outline>
<outline text="Conclusion">
</outline>
<outline text="IWTGP-ODC Experiments" _note="Tables  \[tab:poserw\] and  \[tab:hevaresw\] details the results of&#10;IWTGP-ODC experiments on Poser and HumanEva datasets in terms of error&#10;and speedup in prediction time.">
</outline>
<outline text="More figures on AB Ekmeans" _note="Figure \[fig:ekmeans\] shows the clustering performance on 300000 random&#10;2D point (K=5). Figure  \[fig:hevaVis3\] shows the clustering output of&#10;our algorithm visualized on using the first three principal components&#10;of Human Eva training hog features. The figures shows that the cluster&#10;are spatially cohesive but not necessarily circular. This makes the&#10;elliptic distribution of the data captured by Mode 3 gives more accuracy&#10;membership measure me to the subdomains.&#10;&#10;[0.5]{}&#10;&#10;">
</outline>
<outline text="Overlapping Domain Cover(ODC) Generation-Algorithm" _note="Algorithm  \[alg:sdgen\] shows how the overlapping sub-domains are&#10;generated form the the equal size clusters from the closest clusters.&#10;&#10;[**Input:** Clusters ]{}">
</outline>
<outline text="Local Kernel Machines hyper-parameters on each dataset" _note="The hyper parameters were learnt using cross validation on the training&#10;set for GPR, TGP and IWTGP that we are interested in. The following&#10;subsection present the learnt hyper-parameters and the error measures on&#10;each dataset in case of TGPs.">
  <outline text="Poser Dataset" _note="The parameters , , , and were assigned to , , , and , respectively.">
  </outline>
  <outline text="HumanEva Dataset" _note="The parameters , , , and were assigned to , , , and , respectively.">
  </outline>
  <outline text="Human 3.6 Dataset" _note="The parameters , , , and were assigned to , , , and , respectively.&#10;&#10;[l]{}[0.2]{}&#10;&#10;**Mohamed Elhoseiny** is a PostDoc Researcher at Facebook Research. His&#10;primary research interest is in computer vision, machine learning,&#10;intersection between natural language and vision, language guided&#10;visual-perception, and visual reasoning, art &amp; AI. He received his PhD&#10;degree from Rutgers University, New Brunswick, in 2016 under Prof. Ahmed&#10;Elgammal. Mohamed received an NSF Fellowship in 2014 for the&#10;Write-a-Classifier project (ICCV13), best intern award at SRI&#10;International 2014, and the Doctoral Consortium award at CVPR 2016.&#10;&#10;[l]{}[0.2]{}&#10;&#10;**Ahmed Elgammal** is a professor at the Department of Computer Science,&#10;Rutgers, the State University of New Jersey Since Fall 2002. Dr.&#10;Elgammal is also a member of the Center for Computational Biomedicine&#10;Imaging and Modeling (CBIM). His primary research interest is computer&#10;vision and machine learning. His research focus includes human activity&#10;recognition, human motion analysis, tracking, human identification, and&#10;statistical methods for computer vision. Dr. Elgammal received the&#10;National Science Foundation CAREER Award in 2006. Dr. Elgammal has been&#10;the Principal Investigator and Co-Principal Investigator of several&#10;research projects in the areas of Human Motion Analysis, Gait Analysis,&#10;Tracking, Facial Expression Analysis and Scene Modeling; funded by NSF&#10;and ONR. Dr. Elgammal is Member of the review committee/board in several&#10;of the top conferences and journals in the computer vision field. Dr.&#10;Elgammal received his Ph.D. in 2002 from the University of Maryland,&#10;College Park. He is a senior IEEE member.">
  </outline>
</outline>
  </body>
</opml>