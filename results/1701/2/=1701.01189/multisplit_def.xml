<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Multsiplit and Common Approaches" _note="In this section, we first formally define the multisplit as a primitive&#10;algorithm. Next, we describe some common approaches for performing the&#10;multisplit algorithm, which form a baseline for the comparison to our&#10;own methods, which we then describe in Section \[sec:algorithm\].">
  <outline text="The multisplit primitive" _note="We informally characterize multisplit as follows:&#10;&#10;Input: An unordered set of keys or key-value pairs. “Values” that are&#10;larger than the size of a pointer use a pointer to the value in place of&#10;the actual value.&#10;&#10;Input: A function, specified by the programmer, that inputs a key and&#10;outputs the bucket corresponding to that key (BUCKET IDENTIFIER). For&#10;example, this function might classify a key into a particular numerical&#10;range, or divide keys into prime or composite buckets.&#10;&#10;Output: Keys or key-value pairs separated into buckets. Items within&#10;each output bucket must be contiguous but are otherwise unordered. Some&#10;applications may prefer output order within a bucket that preserves&#10;input order; we call these multisplit implementations “stable”.&#10;&#10;More formally, let and be vectors of KEY and VALUE elements,&#10;respectively. Altogether buckets partition the entire key domain such&#10;that each key element uniquely belongs to one and only one bucket. Let&#10;be an arbitrary bucket identifier that assigns a bucket ID to each input&#10;key (e.g., if and only if ). Throughout this paper, always refers to the&#10;total number of buckets. For any input key vector, we define MULTISPLIT&#10;as a permutation of that input vector into an output vector. The output&#10;vector is densely packed and has two properties: (1) All output elements&#10;within the same bucket are stored contiguously in the output vector, and&#10;(2) All output elements are stored contiguously in a vector in ascending&#10;order by their bucket IDs. Optionally, the beginning index of each&#10;bucket in the output vector can also be stored in an array of size . Our&#10;main focus in this paper is on 32-bit keys and values (of any data&#10;type).&#10;&#10;This multisplit definition allows for a variety of implementations. It&#10;places no restrictions on the order of elements within each bucket&#10;before and after the multisplit (intra-bucket orders); buckets with&#10;larger indices do not necessarily have larger elements. In fact, key&#10;elements may not even be comparable entities, e.g., keys can be strings&#10;of names with buckets assigned to male names, female names, etc. We do&#10;require that buckets are assigned to consecutive IDs and will produce&#10;buckets ordered in this way. Figure \[fig:multisplit\_example\]&#10;illustrates some multisplit examples. Next, we consider some common&#10;approaches for dealing with non-trivial multisplit problems.">
  </outline>
  <outline text="Iterative and Recursive scan-based splits" _note="The first approach is based on binary split. Suppose we have two&#10;buckets. We identify buckets in a binary flag vector, and then compact&#10;keys (or key-value pairs) based on the flags. We also compact the&#10;complemented binary flags from right to left, and store the results.&#10;Compaction can be efficiently implemented by a scan operation, and in&#10;practice we can concurrently do both left-to-right and right-to-left&#10;compaction with a single scan operation.&#10;&#10;With more buckets, we can take two approaches. One is to iteratively&#10;perform binary splits and reduce our buckets one by one. For example, we&#10;can first split based on and all remaining buckets (). Then we can split&#10;the remaining elements based on and . After rounds the result will be&#10;equivalent to a multisplit operation. Another approach is that we can&#10;recursively perform binary splits; on each round we split key elements&#10;into two groups of buckets. We continue this process for at most rounds&#10;and in each round we perform twice number of multisplits and in the end&#10;we will have a stable multisplit. Both of these scan-based splits&#10;require multiple global operations (e.g., scan) over all elements, and&#10;may also have load-balancing issues if the distribution of keys is&#10;non-uniform. As we will later see in&#10;Section \[subsec:perf\_references\], on modern GPUs and with just two&#10;buckets this approach is not efficient enough.">
  </outline>
  <outline text="Radix sort" _note="It should be clear by now that sorting is not a general solution to a&#10;multisplit problem. However, it is possible to achieve a non-stable&#10;multisplit by directly sorting our input elements under the following&#10;condition: if buckets with larger IDs have larger elements (e.g., all&#10;elements in are less than all elements in , and so on). Even in this&#10;case, this is not a work-efficient solution as it unnecessarily sorts&#10;all elements within each bucket as well. On average, as the number of&#10;buckets () increases, this performance gap should decrease because there&#10;are fewer elements within each bucket and hence less extra effort to&#10;sort them. As a result, at some point we expect the multisplit problem&#10;to converge to a regular sort problem, when there are large enough&#10;number of buckets.&#10;&#10;Among all sorting algorithms, there is a special connection between&#10;radix sort and multisplit. Radix sort iteratively sorts key elements&#10;based on selected groups of bits in keys. The process either starts from&#10;the least significant bits (“LSB sort”) or from the most significant&#10;bits (“MSB sort”). In general MSB sort is more common because, compared&#10;to LSB sort, it requires less intermediate data movement when keys vary&#10;significantly in length (this is more of an issue for string sorting).&#10;MSB sort ensures data movements become increasingly localized for later&#10;iterations, because keys will not move between buckets (“bucket” here&#10;refers to the group of keys with the same set of considered bits from&#10;previous iterations). However, for equal width key types (such as 32-bit&#10;variables, which are our focus in this paper) and with a uniform&#10;distribution of keys in the key domain (i.e., an equivalently uniform&#10;distribution of bits across keys), there will be less difference between&#10;the two methods.">
  </outline>
  <outline text="Reduced-bit sort" _note="Because sorting is an efficient primitive on GPUs, we modify it to be&#10;specific to multisplit: here we introduce our REDUCED-BIT SORT method&#10;(RB-sort), which is based on sorting bucket IDs and permuting the&#10;original key-value pairs afterward. For multisplit, this method is&#10;superior to a full radix sort because we expect the number of&#10;significant bits across all bucket IDs is less than the number of&#10;significant bits across all keys. Current efficient GPU radix sorts&#10;(such as CUB) provide an option of sorting only a subset of bits in&#10;keys. This results in a significant performance improvement for RB-sort,&#10;because we only sort bucket IDs (with bits instead of 32-bit keys as in&#10;a full radix sort).">
    <outline text="Key-only" _note="In this scenario, we first make a LABEL vector containing each key’s&#10;bucket ID. Then we sort (label, key) pairs based on label values. Since&#10;labels are all less than , we can limit the number of bits in the radix&#10;sort to be .">
    </outline>
    <outline text="Key-value" _note="In this scenario, we similarly make a label vector from key elements.&#10;Next, we would like to permute (key, value) pairs by sorting labels. One&#10;approach is to sort (label, (key, value)) pairs all together, based on&#10;label. To do so, we first pack our original key-value pairs into a&#10;single 64-bit variable and then do the sort.[^1] In the end we unpack&#10;these elements to form the final results. Another way is to sort (label,&#10;index) pairs and then manually permute key-value pairs based on the&#10;permuted indices. We tried both approaches and the former seems to be&#10;more efficient. The latter requires non-coalesced global memory accesses&#10;and gets worse as increases, while the former reorders for better&#10;coalescing internally and scales better with .&#10;&#10;The main problem with the reduced-bit sort method is its extra overhead&#10;(generating labels, packing original key-value pairs, unpacking the&#10;results), which makes the whole process less efficient. Another&#10;inefficiency with the reduced-bit sort method is that it requires more&#10;expensive data movements than an ideal solution. For example, to&#10;multisplit on keys only, RB-sort performs a radix sort on (label, key)&#10;pairs.&#10;&#10;Today’s fastest sort primitives do not currently provide APIs for&#10;user-specified computations (e.g., bucket identifications) to be&#10;integrated as functors directly into sort’s kernels; while this is an&#10;intriguing area of future work for the designers of sort primitives, we&#10;believe that our reduced-bit sort appears to be the best solution today&#10;for multisplit using current sort primitives.&#10;&#10;[^1]: For data types that are larger than 32 bits, we need further&#10;    modifications for the RB-sort method to work, because it may no&#10;    longer be possible to pack each key-value pair into a single 64-bit&#10;    variable and use the current already-efficient 64-bit GPU sorts for&#10;    it. For such cases, we first sort the array of indexes, then&#10;    manually permute the arbitrary sized key-value pairs.">
    </outline>
  </outline>
</outline>
  </body>
</opml>