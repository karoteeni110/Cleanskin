<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Introduction" _note="This paper studies the multisplit primitive for GPUs. [^1] Multisplit&#10;divides a set of items (keys or key-value pairs) into contiguous&#10;buckets, where each bucket contains items whose keys satisfy a&#10;programmer-specified criterion (such as falling into a particular&#10;range). Multisplit is broadly useful in a wide range of applications,&#10;some of which we will cite later in this introduction. But we begin our&#10;story by focusing on one particular example, the delta-stepping&#10;formulation of single-source shortest path (SSSP).&#10;&#10;The traditional (and work-efficient) serial approach to SSSP is&#10;Dijkstra’s algorithm , which considers one vertex per iteration—the&#10;vertex with the lowest weight. The traditional parallel approach&#10;(Bellman-Ford-Moore ) considers all vertices on each iteration, but as a&#10;result incurs more work than the serial approach. On the GPU, the recent&#10;SSSP work of Davidson et al.  instead built upon the delta-stepping work&#10;of Meyer and Sanders , which on each iteration classifies candidate&#10;vertices into BUCKETS or BINS by their weights and then processes the&#10;bucket that contains the vertices with the lowest weights. Items within&#10;a bucket are unordered and can be processed in any order.&#10;&#10;Delta-stepping is a good fit for GPUs. It avoids the inherent&#10;serialization of Dijkstra’s approach and the extra work of the fully&#10;parallel Bellman-Ford-Moore approach. At a high level, delta-stepping&#10;divides up a large amount of work into multiple buckets and then&#10;processes all items within one bucket in parallel at the same time. How&#10;many buckets? Meyer and Sanders describe how to choose a bucket size&#10;that is “large enough to allow for sufficient parallelism and small&#10;enough to keep the algorithm work-efficient” . Davidson et al. found&#10;that 10 buckets was an appropriate bucket count across their range of&#10;datasets. More broadly, for modern parallel architectures, this design&#10;pattern is a powerful one: expose just enough parallelism to fill the&#10;machine with work, then choose the most efficient algorithm to process&#10;that work. (For instance, Hou et al. use this strategy in efficient&#10;GPU-based tree traversal .)&#10;&#10;Once we’ve decided the bucket count, how do we efficiently classify&#10;vertices into buckets? Davidson et al. called the necessary primitive&#10;MULTISPLIT. Beyond SSSP, multisplit has significant utility across a&#10;range of GPU applications. Bucketing is a key primitive in one&#10;implementation of radix sort on GPUs , where elements are reordered&#10;iteratively based on a group of their bits in their binary&#10;representation; as the first step in building a GPU hash table ; in&#10;hash-join for relational databases to group low-bit keys ; in string&#10;sort for singleton compaction and elimination ; in suffix array&#10;construction to organize the lexicographical rank of characters ; in a&#10;graphics voxelization pipeline for splitting tiles based on their&#10;descriptor (dominant axis) ; in the shallow stages of -d tree&#10;construction ; in Ashari et al.’s sparse-matrix dense-vector&#10;multiplication work, which bins rows by length ; and in probabilistic&#10;top- selection, whose core multisplit operation is three bins around two&#10;pivots . And while multisplit is a crucial part of each of these and&#10;many other GPU applications, it has received little attention to date in&#10;the literature. The work we present here addresses this topic with a&#10;comprehensive look at efficiently implementing multisplit as a&#10;general-purpose parallel primitive.&#10;&#10;The approach of Davidson et al. to implementing multisplit reveals the&#10;need for this focus. If the number of buckets is 2, then a scan-based&#10;“split” primitive  is highly efficient on GPUs. Davidson et al. built&#10;both a 2-bucket (“Near-Far”) and 10-bucket implementation. Because they&#10;lacked an efficient multisplit, they were forced to recommend their&#10;theoretically-less-efficient 2-bucket implementation:&#10;&#10;&gt; The missing primitive on GPUs is a high-performance MULTISPLIT that&#10;&gt; separates primitives based on key value (bucket id); in our&#10;&gt; implementation, we instead use a sort; in the absence of a more&#10;&gt; efficient multisplit, we recommend utilizing our Near-Far work-saving&#10;&gt; strategy for most graphs. &#10;&#10;Like Davidson et al., we could implement multisplit on GPUs with a sort.&#10;Recent GPU sorting implementations  deliver high throughput, but are&#10;overkill for the multisplit problem: unlike sort, multisplit has no need&#10;to order items within a bucket. In short, sort does more work than&#10;necessary. For Davidson et al., reorganizing items into buckets after&#10;each iteration with a sort is too expensive: “the overhead of this&#10;reorganization is significant: on average, with our bucketing&#10;implementation, the reorganizational overhead takes 82% of the&#10;runtime.”  &#10;&#10;In this paper we design, implement, and analyze numerous approaches to&#10;multisplit, and make the following contributions:&#10;&#10;On modern GPUs, “global” operations (that require global communication&#10;across the whole GPU) are more expensive than “local” operations that&#10;can exploit faster, local GPU communication mechanisms. Straightforward&#10;implementations of multisplit primarily use global operations. Instead,&#10;we propose a parallel model under which the multisplit problem can be&#10;factored into a sequence of local, global, and local operations better&#10;suited for the GPU’s memory and computational hierarchies.&#10;&#10;We show that reducing the cost of global operations, even by&#10;significantly increasing the cost of local operations, is critical for&#10;achieving the best performance. We base our model on a hierarchical&#10;divide and conquer, where at the highest level each subproblem is small&#10;enough to be easily solved locally in parallel, and at the lowest level&#10;we have only a small number of operations to be performed globally.&#10;&#10;We locally reorder input elements before global operations, trading more&#10;work (the reordering) for better memory performance (greater coalescing)&#10;for an overall improvement in performance.&#10;&#10;We promote the warp-level privatization of local resources as opposed to&#10;the more traditional thread-level privatization. This decision can&#10;contribute to an efficient implementation of our local computations by&#10;using warp-synchronous schemes to avoid branch divergence, reduce shared&#10;memory usage, leverage warp-wide instructions, and minimize intra-warp&#10;communication.&#10;&#10;We design a novel voting scheme using only binary ballots. We use this&#10;scheme to efficiently implement our warp-wide local computations (e.g.,&#10;histogram computations).&#10;&#10;We use these contributions to implement a high-performance multisplit&#10;targeted to modern GPUs. We then use our multisplit as an effective&#10;building block to achieve the following:&#10;&#10;-   We build an alternate radix sort competitive with CUB (the current&#10;    fastest GPU sort library). Our implementation is particularly&#10;    effective with key-value sorts&#10;    (Section \[subsec:multisplit\_sort\]).&#10;&#10;-   We demonstrate a significant performance improvement in the&#10;    delta-stepping formulation of the SSSP algorithm&#10;    (Section \[sec:app\_sssp\]).&#10;&#10;-   We build an alternate device-wide histogram procedure competitive&#10;    with CUB. Our implementation is particularly suitable for a small&#10;    number of bins (Section \[subsec:multisplit\_histogram\]).&#10;&#10;[^1]: This paper is an extended version of initial results published at&#10;    PPoPP 2016 . The source code is available at&#10;    &lt;https://github.com/owensgroup/GpuMultisplit&gt;.">
</outline>
  </body>
</opml>