<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Experimental Results" _note="In this section, we present the experiments on text outlier analysis&#10;using matrix factorization. We used both real and synthetic data sets to&#10;test our algorithm. The real data sets correspond to the well known&#10;[RCV20]{}, [REUTERS]{} and [WIKI PEOPLE]{} data, whereas the synthetic&#10;data set was created using a well known market basket generator&#10;described later. It should be pointed out that these data sets were not&#10;originally designed for outlier analysis, and they have no ground truth&#10;information available. Therefore, some additional pre-processing needed&#10;to be applied to the real data sets, in order to isolate ground truth&#10;classes, and use them effectively for the outlier analysis problem. In&#10;this section, we will describe the data sets, their preparation, the&#10;performance criteria and the results obtained by our algorithm. At the&#10;end of this section, we will also present a discussion that provides&#10;interesting insights about the effectiveness of algorithm  .">
  <outline text="Data Sets" _note="The experiments were conducted with both labelled real and synthetic&#10;data sets. These are described below:\&#10;[**RCV20 DATA SET:**]{} The [RCV20 DATA SET]{} [^1] is a collection of&#10;approximately 20,000 newsgroup documents, partitioned (nearly) evenly&#10;across 20 different newsgroups. We took all data points from two&#10;randomly chosen classes, which in this case corresponded to the [IBM]{}&#10;and [MAC HARDWARE]{} classes. In addition, 50 data points were chosen&#10;from one randomly chosen class, which corresponds to the [WINDOWS&#10;OPERATING SYSTEM (OS)]{} class. As it turns out, this is a rather hard&#10;problem for our algorithm because of some level of relationship between&#10;one of the rare classes and the base data. Specifically, [WINDOWS&#10;OPERATING SYSTEM]{} and [IBM HARDWARE]{} are both computer related&#10;subjects, and the former is often used with the latter. Therefore, some&#10;vocabulary is shared between the regular class and the rare class, and&#10;this makes the detection of outlier harder. We randomly permuted the&#10;position of the outliers and regular data points.\&#10;[**REUTERS-21578 DATA SET:**]{} The documents in the [REUTERS-21578]{}&#10;collection [^2] appeared on the [REUTERS]{} newswire in 1987. It&#10;contains 21578 documents in 135 categories. Every document belongs to&#10;one or more categories. We selected those documents that belong to only&#10;one category. We chose totally 5768 documents that belong to the&#10;category [EARN]{} and [ACQ]{}. The outliers were 100 documents from&#10;category [INTEREST]{}. The vocabulary size of all the documents from&#10;these categories put together were 18933. We randomly permuted the&#10;position of the outliers and regular data points.\&#10;\&#10;[**MARKET BASKET DATA GENERATOR:**]{} We also wanted to understand the&#10;performance of our algorithm in some large sparse matrices that is&#10;similar to the bag of words matrix. Towards this end, we used the&#10;standard [IBM SYNTHETIC DATA GENERATION CODE FOR ASSOCIATIONS AND&#10;SEQUENTIAL PATTERNS]{} – market-basket data generator, that is packaged&#10;as part of [ILLIMINE]{}[^3] software. We set the average length of the&#10;transaction to be 300 and number of different items to be 50,000. Note&#10;that this generator uses a random seed, and by changing the seed, it is&#10;possible to completely change the transaction distribution, even if all&#10;other parameters remain the same. We generated 10,000 data points as a&#10;group of four different sets of 2500 data points with randomly chosen&#10;seed values. In addition, the rare class contained 250 data points from&#10;a single seed value. In addition, we randomly permuted the positions of&#10;the outliers and regular data points in the matrix representation, to&#10;avoid any unforeseen bias in the algorithm.&#10;&#10;[^1]: &lt;http://qwone.com/~jason/20Newsgroups/&gt;&#10;&#10;[^2]: &lt;http://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection&gt;&#10;&#10;[^3]: &lt;http://illimine.cs.uiuc.edu/&gt;">
  </outline>
  <outline text="Performance Metrics" _note="The effectiveness was measured in terms of the ROC curve drawn on the&#10;outlier scores. We use the area under the Receiver Operating&#10;Characteristics(ROC) curve – the defacto metric for evaluation in&#10;outlier analysis. The idea of this curve is to evaluate a [RANKING]{} of&#10;outlier scores, by examining the tradeoff between the true positives and&#10;false positives, as the threshold on the outlier score is varied in a&#10;range. By using different thresholds, it is possible to obtain a&#10;relatively larger or smaller number of true positives with respect to&#10;the false positives.&#10;&#10;Let be the set of outliers determined by using a threshold on the&#10;outlier scores. In this case, the [TRUE POSITIVE RATE]{} is graphed&#10;against the [FALSE POSITIVE RATE]{}. The true positive rate is defined&#10;in the same way as the metric of recall is defined in the IR literature.&#10;The false positive rate is the percentage of the falsely reported&#10;positives out of the ground-truth negatives. Therefore, for a data set&#10;with ground truth positives , these definitions are as follows: Note&#10;that the end points of the ROC curve are always at and , and a random&#10;method is expected to exhibit performance along the diagonal line&#10;connecting these points. The [LIFT]{} obtained above this diagonal line&#10;provides an idea of the accuracy of the approach. The area under the ROC&#10;curve provides a measure of the accuracy. A random algorithm would have&#10;an area of 0.5 under the ROC curve. The ROC curve was used to provide&#10;detailed insights into the tradeoffs associated with the method, whereas&#10;the area under the ROC curve was used in order to provide a summary of&#10;the performance of the method.">
  </outline>
  <outline text="Baseline Algorithms" _note="The baselines used by our approach were as follows:\&#10;[**DISTANCE-BASED ALGORITHM:**]{} The first algorithm which was used was&#10;the -nearest neighbour algorithm, which is a classical distance-based&#10;algorithm frequently used for outlier detection . The outliers were&#10;ranked based on distances in order to create an ROC curve, rather than&#10;using a specific threshold as in . In addition, we gave the -nearest&#10;neighbour algorithm an advantage by picking a value of optimally based&#10;on area under ROC curve by sweeping from 1 to 50. Note that such an&#10;advantage would not be available to the baseline under real scenarios,&#10;since the ground-truth outliers in the data are unknown, and therefore&#10;the ROC curve cannot be optimized.\&#10;[**SIMPLIFIED LOW RANK APPROXIMATION:**]{} We used a low rank&#10;approximation based on Singular Value Decomposition (). For a given&#10;matrix , a best -rank approximation is given by , where . That is, the&#10;trailing in the descending ordered singular values are set to . It is&#10;natural to understand that the outlier documents require linear&#10;combination of many basis vectors. Thus the norm on the can be used a&#10;score to determine the outliers. In the graphs, we use as the legend to&#10;represent this baseline. For the approach, we used the same low rank as&#10;our algorithm.">
  </outline>
  <outline text="Effectiveness Results" _note="We first present the ROC curves for the different data sets. The ROC&#10;curve for the [REUTERS]{} dataset is illustrated in Figure&#10;\[fig:rocreuters\]. In this case, our algorithm shows a drastic&#10;improvement over both the baseline algorithms. This is evident from the&#10;rather large lift in the chart. Our algorithm had an area of 0.9340&#10;under ROC. The -NN approach performed quite poorly, and had an area&#10;under the ROC curve of 0.5370. This is slightly better than random&#10;performance. The area under ROC for the method was 0.5816 and , which is&#10;better than the -NN method, but still significantly less than the&#10;proposed algorithm.&#10;&#10;The comparison of our algorithm with baselines for the [RCV20]{} data&#10;set is shown in Figure \[fig:rocrcv\]. As discussed in the data&#10;generation section, this is a particularly challenging data set, because&#10;of the similarity in the vocabulary distribution between the rare class,&#10;and the regular class. It is evident that our algorithm   performed&#10;better than the , and the -NN method. However, the lift in the ROC curve&#10;for all the methods is not particularly significant, because of the&#10;inherently challenging nature of the data set. The -NN method performed&#10;particularly poorly in this case. In a later section, we will provide&#10;some insights about the fact that some of this “poor” performance is&#10;because of the noise in the data set itself, where some of the points in&#10;the regular class should really be considered outliers. We generated a&#10;datasets in RCV20 where we just changed the outlier class to [CHRISTIAN&#10;RELIGION]{}. We received a best ROC of 0.9732 and it is not shown in&#10;Figure \[fig:rocrcv\].&#10;&#10;The ROC comparison for the synthetic market basket data is illustrated&#10;in Figure \[fig:rocmb\]. In this case, the improvement of the algorithm&#10;  over the baseline methods was quite significant. Specifically, the&#10;algorithm  had an area under the ROC curve of 0.7598, which is a&#10;significant lift. This significantly outperformed the and . As in the&#10;case of the other data sets, the -NN algorithm performed very poorly&#10;with an area under the ROC curve of 0.5431. The consistently poor&#10;performance of the -NN approach over all algorithms is quite striking,&#10;and suggests that straightforward generalizations of outlier analysis&#10;techniques from other data domains are often not well suited to the text&#10;domain.&#10;&#10;Clearly, conventional distance-based methods do not seem to work very&#10;well for text data.">
  </outline>
  <outline text="Parameter Sensitivity" _note="From (\[outlier\]) in Section \[sec:model\], we can see that the&#10;parameters for our algorithm are and the low rank . We tested the&#10;algorithm for different variations in the parameters, and found that our&#10;algorithm was insensitive to changes in . In other words, for a given&#10;low rank and , the changes in the value of did not result in significant&#10;change in the area under ROC. Hence, in this paper, we provide the&#10;charts of the ROC area variation with the parameters and on the data&#10;sets.&#10;&#10;The sensitivity results for the [REUTERS]{} data set are illustrated in&#10;Figure \[fig:alphakreuters\]. The value of is illustrated on the -axis,&#10;and different values of the low rank are graphed by different curves in&#10;the plot. It is evident in this case, that the area under the ROC&#10;increased with increase in low rank and . However the improvement&#10;started diminishing and changed very marginally at higher ranks .&#10;&#10;The results for the [RCV20]{} and datasets are illustrated in Figure&#10;\[fig:alphakrcv\] . As in the previous case, the value of is illustrated&#10;on the -axis, and different values of the low rank are represented by&#10;different curves. In this case, the area under the ROC curve was&#10;relatively insensitive to the parameters. This implies that the&#10;algorithm can be used over a wide range of parameters, without affecting&#10;the performance too much. Finally, the results for the market basket&#10;data set are illustrated in Figure \[fig:alphakmb\]. In this case, the&#10;area under the ROC curve decreases with increase in low rank and . This&#10;is because the market-basket data has inherently very low (implicit)&#10;dimensionality, and therefore, it is best to use a relatively low rank&#10;in order to mine the outliers.">
  </outline>
  <outline text="Further Insights" _note="In order to illustrate the inner workings of the matrix factorization&#10;approach, we provide some further insights about the statistics buried&#10;deep in the algorithm. We also present some interesting observations&#10;when outliers share the same vocabulary distribution as regular data&#10;points, as is the case for the [RCV20]{} data set. One observation is&#10;that the method of data generation implicitly assumes that all the&#10;documents within a “regular” class in a real data set are not outliers.&#10;This is of course not true in practice, since some of the documents&#10;within these classes will also be outliers, for reasons other than&#10;topical affinity. Our algorithm  was also able to detect such distinct&#10;documents, much better than the other baseline algorithms. We isolated&#10;those false positives of our algorithm  that were not detected in the&#10;baselines in the case of the [RCV20]{} data set. It was observed that&#10;while these outliers officially belonged to one of the regular classes,&#10;they did show different [KINDS]{} of distinctive characteristics. For&#10;example, while the average number of words in regular documents was 195,&#10;the “false positive” outliers chosen by our algorithm were typically&#10;either very lengthy with over 400 words, or were unusually short will&#10;less than 150 words. This behaviour was also generally reflected in the&#10;number of distinct words per document. Another observation is that these&#10;outlier documents typically had a significant vocabulary repetition over&#10;a small number of distinct words. Thus, the algorithm was also able to&#10;identify those natural outliers, which [OUGHT TO]{} have been considered&#10;outliers for reasons of statistical word distribution, as opposed to&#10;their topical behaviour.">
  </outline>
</outline>
  </body>
</opml>