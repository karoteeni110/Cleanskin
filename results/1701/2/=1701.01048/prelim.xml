<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Preliminaries" _note="This section provides a formal description of the representation&#10;language, the relational planning problem, and the description of the&#10;running example in this context.">
  <outline text="Relational Expressions and their Calculus of Operations" _note="The computation of SDP algorithms is facilitated by a representation&#10;that enables compact specification of functions over world states.&#10;Several such representations have been devised and used. In this chapter&#10;we chose to abstract away some of those details and focus on a simple&#10;language of relational expressions. This is closest to the GFODD&#10;representation of , but it resembles the case notation of .&#10;&#10;We assume familiarity with basic concepts and notation in first order&#10;logic (FOL) . Relational expressions are similar to expressions in FOL.&#10;They are defined relative to a relational signature, with a finite set&#10;of predicates each with an associated arity (number of arguments), a&#10;countable set of variables , and a set of constants . We do not allow&#10;function symbols other than constants (that is, functions with arity ).&#10;A term is a variable (often denoted in uppercase) or constant (often&#10;denoted in lowercase) and an atom is either an equality between two&#10;terms or a predicate with an appropriate list of terms as arguments.&#10;Intuitively, a term refers to an object in the world of interest and an&#10;atom is a property which is either true or false.&#10;&#10;We illustrate relational expressions informally by some examples. In FOL&#10;we can consider open formulas that have unbound variables. For example,&#10;the atom is such a formula and its truth value depends on the assignment&#10;of and to objects in the world. To simplify the discussion, we assume&#10;for this example that arguments are typed (or sorted) and ranges over&#10;“objects” and over “colors”. We can then quantify over these variables&#10;to get a sentence which will be evaluated to a truth value in any&#10;concrete possible world. For example, we can write expressing the&#10;statement that there is a color associated with all objects. Generalized&#10;expressions allow for more general open formulas that evaluate to&#10;numerical values. For example, is similar to the previous logical&#10;expression but returns non-binary values.&#10;&#10;Quantifiers from logic are replaced with aggregation operators that&#10;combine numerical values and provide a generalization of the logical&#10;constructs. In particular, when the open formula is restricted to values&#10;0 and 1, the operators and simulate existential and universal&#10;quantification. Thus, is equivalent to the logical sentence given above.&#10;But we can allow for other types of aggregations. For example, evaluates&#10;to the largest number of objects associated with one color, and the&#10;expression evaluates to the number of objects that have no color&#10;association. In this manner, a generalized expression represents a&#10;function from possible worlds to numerical values and, as illustrated,&#10;can capture interesting properties of the state.&#10;&#10;Relational expressions are also related to work in statistical&#10;relational learning . For example, if the open expression given above&#10;captures probability of ground facts for the predicate and the ground&#10;facts are mutually independent then captures the joint probability for&#10;all facts for . Of course, the open formulas in logic can include more&#10;than one atom and similarly expressions can be more involved.&#10;&#10;In the following we will drop the cumbersome if-then-else notation and&#10;instead will assume a simpler notation with a set of mutually exclusive&#10;conditions which we refer to as [CASES]{}. In particular, an expression&#10;includes a set of mutually exclusive open formulas in FOL (without any&#10;quantifiers or aggregators) denoted associated with corresponding&#10;numerical values . The list of cases refers to a finite set of variables&#10;. A generalized expression is given by a list of aggregation operators&#10;and their variables and the list of cases so that the last expression is&#10;canonically represented as .&#10;&#10;The semantics of expressions is defined inductively exactly as in first&#10;order logic and we skip the formal definition. As usual, an expression&#10;is evaluated in an INTERPRETATION also known as a possible world. In our&#10;context, an interpretation specifies (1) a finite set of domain elements&#10;also known as objects, (2) a mapping of constants to domain elements,&#10;and (3) the truth values of all the predicates over tuples of domain&#10;elements of appropriate size to match the arity of the predicate. Now,&#10;given an expression , an interpretation , and a substitution of&#10;variables in to objects in , one can identify the case which is true for&#10;this substitution. Exactly one such case exists since the cases are&#10;mutually exclusive and exhaustive. Therefore, the value associated with&#10;is . These values are then aggregated using the aggregation operators.&#10;For example, consider again the expression and an interpretation with&#10;objects and where is associated with colors black and white and is&#10;associated with color black. In this case we have exactly 4&#10;substitutions evaluating to 0.3, 0.3, 0.5, 0.3. Then the final value is&#10;.&#10;&#10;Any binary operation over real values can be generalized to open and&#10;closed expressions in a natural way. If and are two closed expressions,&#10;represents the function which maps each interpretation to . This&#10;provides a definition but not an implementation of binary operations&#10;over expressions. For implementation, the work in showed that if the&#10;binary operation is [SAFE]{}, i.e., it distributes with respect to all&#10;aggregation operators, then there is a simple algorithm (the Apply&#10;procedure) implementing the binary operation over expressions. For&#10;example, is safe w.r.t.  aggregation, and it is easy to see that = , and&#10;the open formula portion of the result can be calculated directly from&#10;the open expressions and . Note that we need to standardize the&#10;expressions apart, as in the renaming of to for such operations. When&#10;and are open relational expressions the result can be computed through a&#10;cross product of the cases. For example, When the binary operation is&#10;not safe then this procedure fails, but in some cases,&#10;operation-specific algorithms can be used for such combinations.[^1]&#10;&#10;As will become clear later, to implement SDP we need the binary&#10;operations , , and the aggregation includes in addition to aggregation&#10;in the reward function. Since , , are safe with respect to aggregation&#10;one can provide a complete solution when the reward is restricted to&#10;have aggregation. When this is not the case, for example when using sum&#10;aggregation in the reward function, one requires a special algorithm for&#10;the combination. Further details are provided in .&#10;&#10;Relational expressions are closest to the GFODD representation of .&#10;Every case in a relational expression corresponds to a path or set of&#10;paths in the GFODD, all of which reach the same leaf in the graphical&#10;representation of the GFODD. GFODDs are potentially more compact than&#10;relational expressions since paths share common subexpressions, which&#10;can lead to an exponential reduction in size. On the other hand, GFODDs&#10;require special algorithms for their manipulation. Relational&#10;expressions are also similar to the case notation of . However, in&#10;contrast with that representation, cases are not allowed to include any&#10;quantifiers and instead quantifiers and general aggregators are globally&#10;applied over the cases, as in standard quantified normal form in logic.&#10;&#10;[^1]: For example, a product of expressions that include only product&#10;    aggregations, which is not safe, can be obtained by scaling the&#10;    result with a number that depends on domain size, and is euqal to&#10;    when the domain has objects.">
  </outline>
  <outline text="Relational MDPs" _note="In this section we define MDPs, starting with the basic case with&#10;enumerated state and action spaces, and then providing the relational&#10;representation.&#10;&#10;We assume familiarity with basic notions of Markov Decision Processes&#10;(MDPs) . Briefly, a MDP is a tuple given by a set of states , set of&#10;actions , transition probability , immediate reward function and&#10;discount factor . The solution of a MDP is a policy that maximizes the&#10;expected discounted total reward obtained by following that policy&#10;starting from any state. The Value Iteration algorithm (VI) informally&#10;introduced in Eq \[eq:VI\], calculates the optimal value function by&#10;iteratively performing Bellman backups, , defined for each state as,&#10;Unlike Eq \[eq:VI\], which was goal-oriented and had only a single&#10;reward at the terminal horizon, here we allow the reward R(S) to&#10;accumulate at all time steps as typically allowed in MDPs. If we iterate&#10;the update until convergence, we get the optimal infinite horizon value&#10;function typically denoted by and optimal stationary policy . For finite&#10;horizon problems, which is the topic of this chapter, we simply stop the&#10;iterations at a specific . In general, the optimal policy for the finite&#10;horizon case is not stationary, that is, we might make different choice&#10;in the same state depending on how close we are to the horizon.&#10;&#10;RMDPs are simply MDPs where the states and actions are described in a&#10;function-free first order logical language. A state corresponds to an&#10;interpretation over the corresponding logical signature, and actions are&#10;transitions between such interpretations. A relational planning problem&#10;is specified by providing the logical signature, the start state, the&#10;transitions as controlled by actions, and the reward function. As&#10;mentioned above, one of the advantages of relational SDP algorithms is&#10;that they are intended to produce an abstracted form of the value&#10;function and policy that does not require specifying the start state or&#10;even the number of objects in the interpretation at planning time. This&#10;yields policies that generalize across domain sizes. We therefore need&#10;to explain how one can use logical notation to represent the transition&#10;model and reward function in a manner that does not depend on domain&#10;size.&#10;&#10;Two types of transition models have been considered in the literature:&#10;&#10;[**Endogenous Branching Transitions:**]{} In the basic form, state&#10;transitions have limited stochastic branching due to a finite number of&#10;action outcomes. The agent has a set of action types each parametrized&#10;with a tuple of objects to yield an action template and a concrete&#10;ground action (e.g. template and concrete action ). Each agent action&#10;has a finite number of action variants (e.g., action success vs. action&#10;failure), and when the user performs in state one of the variants is&#10;chosen randomly using the state-dependent action choice distribution .&#10;To simplify the presentation we follow and require that are given by&#10;open expressions, i.e., they have no aggregations and cannot introduce&#10;new variables. For example, in &lt;span&#10;style=&quot;font-variant:small-caps;&quot;&gt;BoxWorld&lt;/span&gt;, the agent action has&#10;success outcome and failure outcome with action outcome distribution as&#10;follows: where, to simplify the notation, the last case is shortened as&#10;to denote that it complements previous cases. This provides the&#10;distribution over deterministic outcomes of actions.&#10;&#10;The deterministic action dynamics are specified by providing an open&#10;expression, capturing successor state axioms , for each variant and&#10;predicate template . Following we call these expressions TVDs, standing&#10;for truth value diagrams. The corresponding TVD, , is an open expression&#10;that specifies the truth value of [IN THE NEXT STATE]{} (following&#10;standard practice we use prime to denote that the predicate refers to&#10;the next state) when has been executed [ IN THE CURRENT STATE]{}. The&#10;arguments and are intentionally different logical variables as this&#10;allows us to specify the truth value of all instances of simultaneously.&#10;Similar to the choice probabilities we follow and assume that TVDs have&#10;no aggregations and cannot introduce new variables. This implies that&#10;the regression and product terms in the SDP algorithm of the next&#10;section do not change the aggregation function, thereby enabling&#10;analysis of the algorithm. Continuing our &lt;span&#10;style=&quot;font-variant:small-caps;&quot;&gt;BoxWorld&lt;/span&gt; example, we define the&#10;TVD for for and as follows: Note that each TVD has exactly two cases,&#10;one leading to the outcome 1 and the other leading to the outcome 0. Our&#10;algorithm below will use these cases individually. Here we remark that&#10;since the next state (primed) only depends on the previous state&#10;(unprimed), we are effectively logically encoding the Markov assumption&#10;of MDPs.&#10;&#10;[**Exogenous Branching Transitions:**]{} The more complex form combines&#10;the endogenous model with an exogenous stochastic process that affects&#10;ground atoms independently. As a simple example in our &lt;span&#10;style=&quot;font-variant:small-caps;&quot;&gt;BoxWorld&lt;/span&gt; domain, we might&#10;imagine that with some small probability, each box in a city () may&#10;independently randomly disappear (falsify ) owing to issues with theft&#10;or improper routing — such an outcome is independent of the agent’s own&#10;action. Another more complicated example could be an inventory control&#10;problem where customer arrival at shops (and corresponding consumption&#10;of goods) follows an independent stochastic model. Such exogenous&#10;transitions can be formalized in a number of ways ; we do not aim to&#10;commit to a particular representation in this chapter, but rather to&#10;mention its possibility and the computational consequences of such&#10;general representations.&#10;&#10;Having completed our discussion of RMDP transitions, we now proceed to&#10;define the reward , which can be any function of the state and action,&#10;specified by a relational expression. Our running example with&#10;existentially quantified reward is given by but we will also consider&#10;additive reward as in">
  </outline>
</outline>
  </body>
</opml>