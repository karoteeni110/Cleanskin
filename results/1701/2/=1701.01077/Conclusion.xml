<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Conclusion and Future Work" _note="The use of transfer learning to extract features and solve typical AI&#10;tasks has been increasing over the past few years. The major&#10;consideration while doing transfer learning tasks is that the data in&#10;the source domain and the target domain are similar in terms of&#10;representation.&#10;&#10;This paper explores the concept of transfer learning for the domains&#10;which are not directly eligible to apply transfer learning. We introduce&#10;the idea of transforming a non-visually interpretable problem domain to&#10;a visual domain, to leverage the effectiveness of pre-trained CNNs on&#10;visual data. To our knowledge, this kind of modality transformation of&#10;data with the intention of applying transfer learning techniques has not&#10;been carried out so far. Additionally, we provide a unified feature&#10;extractor for sensor data which generally requires different feature&#10;extraction techniques for different applications. However, even though&#10;we apply our technique on the sensor data for a only single application,&#10;we believe that since the CNN for feature extraction is fixed and there&#10;is difference only in the way the input data is transformed, it should&#10;work for other sensor data applications as well.&#10;&#10;This paper applies the introduced idea to a pilot dataset containing&#10;data from pressure sensors to perform a person identification task among&#10;13 people. After evaluating the system with a pre-trained CNN as a&#10;feature extractor, we are able to achieve the average identification&#10;rate of 71.99% and 78.41% with maximum and average frame intensities&#10;respectively. We also explored the idea of analyzing the temporal&#10;information in the walking sequences, and applied the RNNs to exploit&#10;this additional dimension of time and hence achieve an average accuracy&#10;of 87.66%.&#10;&#10;This idea of modality transformation from one domain to another can be&#10;applied to other areas as well. This will specifically be beneficial in&#10;the cases of data for which there are no pre-trained models available.&#10;But, with this approach, if the data can be transformed into the target&#10;modality, transfer learning can be applied using the pre-trained models.&#10;&#10;To further explore this concept, we would like to explore the&#10;effectiveness of this method on other types of sensors such as,&#10;accelerometers, gyroscopes, etc. Certain sensors do not present an&#10;obvious or intuitive way to be transformed into the visual mode.&#10;Therefore, it might be interesting to determine if it is possible to&#10;learn a transformation function from the source to the target mode.">
</outline>
  </body>
</opml>