<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Preference Radius" _note="Let denote the estimation associated with action on episode and let denote the estimated Pareto front given these options. By definition, the optimal options are . Let denote a ball of center and radius . In order to characterize the difficulty of a multi-objective bandits setting, we introduce the following quantity.  For each action , we define the preference radius as any radius such that if for all actions, then  The radii correspond to the ROBUSTNESS of the preference function, that is to which extent can actions be poorly estimated simultaneously before the set of optimal options changes. The radius is directly linked to the gap . For a suboptimal action, a large radius indicates that this action is far from being optimal. Also, the preference radii of suboptimal actions depend on the preference radius of the optimal action(s). Larger optimal action radii imply smaller radii for suboptimal actions. Note that if all actions estimates stand in their preference balls, being greedy is optimal.  Let denote WEIGHTS such that . The weighted metric with is often used to represent decision functions. This function is known as the linear scalarization when and as the Chebyshev scalarization when . The following examples show the link between the preference radii and the gap for these two common functions.  [0.35]{}  [0.35]{}    The linear scalarization function is given by Consider the optimal action and the suboptimal action . By definition of the preference radii, we have that Fig.   shows examples of preference radii with a linear preference function.    The Chebyshev scalarization  function is given by Consider the optimal and suboptimal actions and , and let By definition of the preference radii, we have that The difficulty here is that and respectively depend on and . Consider a 2-objective setting, we can define as thresholds such that Fig.   shows examples of preference radii with a Chebyshev preference function.  [0.35]{}  [0.35]{}  Outside metrics, other scalarization functions are often based on constraints. For example, using the -constraint scalarization technique, a user assigns a constraint to every objective except a target objective . All options that fail to respect one of the contraints receive a value of 0, while the options that respect all constraints get a value of . The following example shows the relation between the preference radius and the gap given a preference function that is articulated as an -constraint scalarization technique.    The -constraint function is given by Consider the optimal and suboptimal actions and . By definition of the preference radii, we have that We decompose such that denotes the radius required in order for action a to respect the constraints, that is to obtain , and denotes the leftover leading to a gap reduction. Finally, we have that Fig.   shows examples of preference radii with -constraint preference functions.  [0.35]{}  [0.35]{}">
</outline>
  </body>
</opml>