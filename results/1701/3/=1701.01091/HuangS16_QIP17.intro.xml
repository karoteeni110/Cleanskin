<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Introduction">
  <outline text="The problem and the motivation" _note="Cryptographic hash functions are a fundamental primitive used widely in today’s cryptographic systems. They are considered “workhorses of modern cryptography”[^1] For simplicity, we focus our discussions on [KEYLESS]{} (cryptographic) hash functions, each of which is an efficiently computable function from some message space to some [DIGEST SPACE]{}  . Ideally, we want the hash function to have the following properties. First, the digest should be much shorter than the message. Depending on applications, the following security properties are desirable . (1) [COLLISION RESISTANT]{}: It is computationally infeasible to find a “collision”, i.e., two distinct messages and , such that . (2) [PREIMAGE RESISTANCE]{}: It is computationally infeasible to invert . (3) [SECOND PREIMAGE RESISTANCE]{}: Given a message , it should be computational infeasible to with .  Prominent examples of widely used cryptographic hash functions include SHA-256 and SHA-512, part of the SHA-2 algorithms that were designed by NSA and are US Federal Standards. These algorithms are used in UNIX and LINUX for secure password hashing, in Bitcoin for proof-of-work. As a motivating example, we consider how proof-of-work can be carried out through hash. Suppose that Alice receives a trove of valuable documents , and Bob claims that he was the person producing and sending it. To prove his claim, he sends Alice a tag , which supposedly is the result of applying a cryptographic hash function on . Alice simply checks if . Accept if yes, reject otherwise. By the collision resistance property, it is nearly impossible that Bob can produce without knowing .  In practice, there may be information leakage of the message over time due to information transmission, adversarial attacks, etc. Therefore, it is rather desirable if the hash function is resilient against information leakage. We ask: how many bits about the message can be leaked before the adversary is able to forge the tag easily?  Cleary, , since if the tag itself is known to the adversary, he does not need to know more about to pass the verification. This is rather disappointing, since is typically much smaller than . We then ask: what if a quantum tag is used instead? If the leakage is quantum, by the same reasoning, remains a trivial and rather lower upper-bound on . This leads us to our central question: [CAN A QUANTUM HASH FUNCTION BE MUCH MORE RESILIENT TO [CLASSICAL]{} LEAKAGE?]{}  [^1]: Bob Schneier,     &lt;https://www.schneier.com/essays/archives/2004/08/cryptanalysis_of_md5.html&gt;.">
  </outline>
  <outline text="Quantum cryptographic hash functions" _note="By a “quantum hash function,” we simply mean a classical-to-quantum encoding that maps to a pure -qubit state . In a seminal paper, Buhrman et al.  introduced the notion of [QUANTUM FINGERPRINTING]{}. In their most general form, a quantum fingerprinting is the following.    A function is a (generalized) quantum fingerprinting where .  We use the convention that represent the projector for the pure state . If one replaces the predicate by the fidelity , one sees that precisely quantify the extent of collision resistance. For concreteness, we define what we mean by quantum cryptographic hash function as follows. For a function , we say is negligible in if for all and all sufficiently large .    A quantum fingerprinting is a [QUANTUM CRYPTOGRAPHIC HASH FUNCTION]{} if .  We note that while classical cryptographic hash functions necessarily rely on computational assumptions for security, their quantum counterparts can achieve the three security properties (1-3) information-theoretically. We now proceed to formulate our leakage problem precisely. We consider average case security and model classical side-channel information using a classical-classical (c-c) state, called the [SIDE INFORMATION STATE]{}, on . Here is uniformly distributed and represents the side information. The largest probability of correctly guessing conditioned on is . The [CONDITIONAL MIN-ENTROPY]{} is . We quantify the amount of leakage by .  The adversary is given the sub-system and creates a classical-quantum (cq) state , called the [FORGERY STATE]{}, through local quantum operations on . The [VERIFICATION SCHEME]{} for is the following measurement on : . The probability of the forgery state to pass the verification scheme is . Given the leakage , the optimal passing probability of a forgery state is denoted by . We can now define security precisely.  A quantum cryptographic hash function is said to be [-RESILIENT AGAINST BITS OF CLASSICAL LEAKAGE]{} if for all forgery state obtained from bits of side information, the probability of passing the verification scheme . If no is specified, it is assumed that .">
  </outline>
  <outline text="Main Result" _note="We show that quantum cryptographic hash functions can be extremely resilient to classical leakage. Our main theorem is informally stated below.    For all and , all quantum cryptographic hash functions are resilient against bits of classical leakage.  Buhrman et al.  showed that for all and , there exists a quantum fingerprinting for for which explicit constructions can be derived from . We thus have the following corollary.  For all , , and , there exist efficient quantum cryptographic hash functions resilient to leaking bits of information.  One drawback of the verification scheme is that the verifier has to get access to full information about the original message in order to perform the verification. In some cases this would be a heavy burden on the verifier. One natural question to ask is that if it is possible to develop a lightweighted verification scheme where the verifier does not need to read the whole message. More formally, let the verifier now receive qubits of [ADVICE STATE]{} and bits of the [ FORGERY STATE]{} provided by the adversary. An verification scheme would then be a joint measurement on the advice state together with the forgery state. This generalizes the original verification where and .  Out next result shows that, by increasing the hash a little bit we can dramatically reduce the size of system needed by the verifier:  For all , fix . There exists a verification scheme acting on qubits, together with an ensemble of -qubit states such that  Arunachalam et al.  showed that copies of a quantum cryptographic hash based on linear codes is necessary to recover the original -bit classical message, regardless of the length of the hash itself. Our result shows the complimentary aspect that only copies are sufficient to ensure that the prover holds the classical message.  Our central technical result is the following. Recall that is the optimal guessing probability of the message conditioned on the -bit side information.    For any quantum fingerprinting and any leakage of classical bits, the probability of the forgery state passing the verification scheme satisfies  This implies that by considering the two cheating strategies of guessing first (then applying ) and using a fixed fingerprint state. Consequently, when , the above inequality means that is negligible if and only if is negligible.  Since is the threshold for to be non-negligible, the bounds ( ) show for quantum cryptographic hash functions, the leakage resilience can approach the [MAXIMUM]{} of bits.  One counterpart of this result is shown in , saying that copies of quantum fingerprints would be necessary for an adversary to recover the original message with non-negligible probability. Thus, the quantum cryptographic hash functions based on fingerprinting have the following property: The hash itself is efficiently computable, but it is information-theoretically resilient to recovery of the message from the hash (which requires copies of the hash) and to recovery of the hash from partial information of the message.">
  </outline>
  <outline text="Implications on quantum-proof randomness extraction" _note="Our result reveals some stark contrast between quantum and classical side information. This difference shows the difficulty for establishing the quantum security of classical-proof extractors. Roughly speaking, a randomness extractor is a randomized algorithm which turns a weakly random source into near uniform . These are fundamental objects with a wide range of applications in computational complexity, cryptography, and other areas . In particular, they accomplish the important tasks of privacy amplication , by decoupling the correlation between the output and the side information.  A major open problem in randomness extraction is whether every classical-proof randomness extractor for min-entropy sources is secure against quantum adversaries with comparable amount but quantum side information. Loss of parameter is already shown to be inevitable in , but possibilities still remain in the case where the ranges of parameters are relavant to most typical applications.  If all quantum side information can be constructed from a comparable amount of classical side information, we would have resolved this major problem positively. Our result shows that this approach would necessarily fail. For details, see Section  .  There exists a family of classical-quantum states with arbitrarily small amount of quantum side information, yet these quantum states cannot be approximately constructed from classical side information that is almost a perfect copy of the classical message.">
  </outline>
  <outline text="Sketch of Proofs" _note="To prove Separation Lemma  , we first answered the following question (see Section  ): [GIVEN A C-Q STATE, HOW MUCH CLASSICAL SIDE INFORMATION IS NEEDED TO APPROXIMATE IT UP TO A GIVEN ERROR ?]{} It turns out that this quantity, denoted by the CONVERSION PARAMETER, can be simplified to a fairly nice expression. An important step is to show (in Lemma  ) that classical information can without loss of generality be identifying a subset of the messages, and conditioned on this information, the messages are uniformly distributed on that subset. At the end, the proof reduces to estimating the operator norm of , where ’s are projections to the fingerprint states, thus pairwise almost orthogonal. Cotlar-Stein Lemma gives us the desired bound.">
  </outline>
  <outline text="Related works." _note="As mentioned above, Buhrman et al.  introduced the notion and provide the constructions of quantum fingerprinting. The application they focused on is for message identification. For our cryptographic applications, we are primarily interested in instances of a negligible fidelity. They did not discuss properties of quantum fingerprinting in an adversarial context like ours. That quantum fingerprinting satisfies the security properties of cryptographic hash functions was observed and explored by .  Side-channel attack is a major paradigm studied in the classical information security and cryptography community due to its high level of threat in practice . Side-channel key recovery attack has in particular drawn much attention . However, these classical works address problems that necessarily require computational assumptions and many other works focus on the hardware aspects. To the best of our knowledge, this work appears to be the first studying information theoretical security of quantum cryptography against classical side-channel attack.">
  </outline>
</outline>
  </body>
</opml>