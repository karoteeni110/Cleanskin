<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>Divergence and Sufficiency for Convex Optimization</title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="Introduction" _note="One of the main purposes of information theory is to compress data so that data can be recovered exactly or approximately. One of the most important quantities was called entropy because it is calculated according to a formula that mimics the calculation of entropy in statistical mechanics. Another key concept in information theory is information divergence (KL-divergence) that is defined for probability vectors and as It was introduced by Kullback and Leibler in 1951 in a paper entitled information and sufficiency . The link from information theory back to statistical physics was developed by E.T. Jaynes via the maximum entropy principle . The link back to statistics is now well established .  Related quantities appear in information theory, statistics, statistical mechanics, and finance, and we are interested in a theory that describes when these relations are exact and when they just work by analogy. First we introduce some general results about optimization on state spaces of finite dimensional C\*-algebras. This part applies exactly to all the topics under consideration and lead to Bregman divergences. Secondly, we introduce several notions of sufficiency and show that this leads to information divergence. This second step is not always applicable which explains when the different topics are really different.">
</outline>
<outline text="Structure of the state space" _note="Our knowledge about a system will be represented by a state space. I many cases the state space is given by a set of probability distributions on a sample space. In such cases the state space is a simplex, but it is well-known that the state space is not a simplex in quantum physics. For applications in quantum physics the state space is often represented by a set of density matrices, i.e. positive semidefinite complex matrices with trace 1. In some cases the states are represented as elements of a finite dimensional -algebra, which is a direct sum of matrix algebras. A finite dimensional -algebra that is a sum of matrices has a state space that is a simplex, so the state spaces of finite dimensional -algebras contain the classical probability distributions as special cases.  The extreme points in the set of states are the pure states. The pure states of a -algebra can be identified with projections of rank 1. Two density matrices and are said to be orthogonal if Any state has a decomposition where are orthogonal pure states. Such a decomposition is not unique, but for a finite dimensional -algebra the coefficients are unique and are called the spectrum of the state.  Sometimes more general state spaces are of interest. In generalized probabilistic theories a state space is a convex set where mixtures are defined by randomly choosing certain states with certain probabilities . A convex set where all orthogonal decompositions of a state have the same spectrum is called a spectral state space. Much of the theory in this paper can be generalized to spectral sets. The most important spectral sets are sets of positive elements with trace 1 in Jordan algebras. For questions related to the foundation of quantum theory the Jordan algebras and other spectral sets give new insight , but in this paper we will restrict our attention to states on finite dimensional -algebras. Nevertheless some of the theorems and proofs are stated in such a way that they hold for more general state spaces.">
</outline>
<outline text="Optimization" _note="Let denotes a state space of a finite dimensional -algebra and let denote a set of self-adjoint operators. Each is identified with a real valued measurement. The elements of may represent feasible ACTIONS (decisions) that lead to a payoff like the score of a statistical decision, the energy extracted by a certain interaction with the system, (minus) the length of a codeword of the next encoded input letter using a specific code book, or the revenue of using a certain portfolio. For each the mean value of the measurement is given by In this way the set of actions may be identified with a subset of the dual space of . Next we define We note that is convex, but need not be strictly convex. In principle may be infinite but we will assume that for all states . We also note that is lower semi-continuous. In this paper we will assume that the function is continuous. The assumption that real valued continuous function is fulfilled for all the applications we consider.  If is a state and is an action then we say that is [OPTIMAL]{} for if . A sequence of actions is said to be [ASYMPTOTICALLY OPTIMAL]{} for the state if for  If are actions and is a probability vector then we we may define the mixed action as the action where we do the action with probability We note that We will assume that all such mixtures of feasible actions are also feasible. If almost surely for all states we say that dominates and if almost surely for all states we say that strictly dominates All actions that are dominated may be removed from without changing the function Let denote the set of self-adjoint operators (observables) such that Then Therefore we may replace by without changing the optimization problem.  In the definition of regret we follow Servage but with different notation.  Let denote a convex function on the state space . If is finite THE REGRET of the action is defined by    The regret of actions has the following properties:   with equality if is optimal for .   is a convex function.  If is optimal for the state where is a probability vector then   is minimal if is optimal for .  (0.,0.) – (1.15,0.); in [0,1]{} (0pt,2pt) – (0pt,-2pt) node  []{}; (0.,0.) – (0.,0.7);  (0.,0.5)– (1.,0.375);  (1.,0.)– (1.,0.375); (1.,0.375)– (1.,0.625);  plot(,[()\^2/4 - ()/8 + 1/2]{});  (1.02,0.52) node  []{}; (0.04,0.7) node  []{}; (1.0807407407407414,0.1) node  []{};  (0.,0.5) circle (2pt); (1.,0.625) circle (2pt); (1.,0.) circle (2pt); (1.,0.375) circle (2pt);  If the state is but one acts as if the state were one may compare what one achieves and what could have been achieved. If the state has a unique optimal action we may simply define the regret of by The following definition leads to a regret function that is essentially equivalent to the so-called [GENERALIZED BREGMAN DIVERGENCES]{} defined by Kiwiel .    Let denote a convex function on the state space . If is finite then we define THE REGRET OF THE STATE as where the infimum is taken over all sequences of actions that are asymptotically optimal for  With this definition the regret is always defined with values in . We note that with this definition the value of the regret only depends on the restriction of the function to the line segment from to . Let denote the function where . As illustrated in Figure   we have where denotes the right derivative of at . Equation ( ) is even valid when the regret is infinite if we allow the right derivative to take the value .  If the state has the unique optimal action then so the function can be reconstructed from except for an affine function of The closure of the convex hull of the set of functions is uniquely determined by the convex function The following proposition follows from Alexandrov’s theorem. See for details.  A convex function on a finite dimensional convex set is differentiable almost everywhere with respect to the Lebesgue measure.  A state where is differentiable has a unique optimal action. Therefore Equation ( ) holds for almost any state . In particular the function can be reconstructed from except for an affine function.    The regret of states has the following properties:   with equality if there exists an action that is optimal for both and .   is a convex function.  Further the following two conditions are equivalent.   implies .  The function is strictly convex.  We say that a regret function is [STRICT]{} if is strictly convex. The two last properties Proposition   do not carry over to regret for states except if the regret is a [BREGMAN DIVERGENCE]{} as defined below. The regret is called a BREGMAN DIVERGENCE if it can be written in the following form where denotes the (Hilbert-Smidt) inner product. In the context of forecasting and statistical scoring rules the use of Bregman divergences dates back to . A similar but less general definition of regret was given by Rao and Nayak where the name CROSS ENTROPY was proposed. Although Bregman divergences have been known for many years they did not gain popularity before the paper where a systematic study of Bregman divergences was presented.  We note that if is a Bregman divergence and minimizes then so that the formula for the Bregman divergence reduces to Bregman divergences satisfy the BREGMAN IDENTITY but if is not differentiable this identity can be violated.  Let the state space be the interval with two actions and Let and Let further and Then If then but Clearly the Bregman identity ( ) is violated and will increase if is replaced by .  The following proposition is easily proved.  For a convex and continuous function the following conditions are equivalent.  The function is differentiable.  The regret is a Bregman divergence.  The Bregman identity is always satisfied.  For any probability vectors the sum is always minimal when .">
</outline>
<outline text="Examples" _note="In this section we shall see how regret functions are defined in some applications.">
  <outline text="Information theory" _note="We recall that a code is uniquely decodable if any finite sequence of input symbols give a unique sequence of output symbols. It is well-known that a uniquely decodable code satisfies Kraft’s inequality where denotes the length of the codeword corresponding to the input symbol and denotes the size of the output alphabet . Here the length of a codeword is an integer. If is a probability vector over the input alphabet, then the mean code-length is Our goal is to minimize the expected code-length. Here the state space consist of probability distributions over the input alphabet and the actions are code-length functions.  Shannon established the inequality It is a combinatoric problem to find the optimal code length function. In the simplest case with a binary output alphabet the optimal code-length function is determined by the Huffmann algorithm.  A code-length function dominates another code-length function if all letters have it has shorter code-length. If a code-length function is not dominated by another code-length function then for all the length is bounded by For fixed alphabets and there exists only a finite number of code-length functions that satisfy Kraft’s inequality and are not dominated by other code-length functions that satisfying Kraft’s inequality.">
  </outline>
  <outline text="Scoring rules" _note="The use of scoring rules has a long history in statistics. An early contribution was the idea of minimizing the sum of square deviations that dates back to Gauss and works perfectly for Gaussian distributions. In the 1920s Ramsay and de Finetti proved versions of the Dutch book theorem where determination of probability distributions were considered as dual problems of maximizing a payoff function. Later it was proved that any consistent inference procedure corresponds to optimizing with respect to some payoff function. A more systematic study of scoring rules was given by McCarthy .  Consider an experiment with as sample space. A SCORING RULE is defined as a function such that the score is when a prediction has been given in terms of a probability distribution and has been observed. A scoring rule is PROPER if for any probability measure the score is minimal when Here the state space consist of probability distributions over and the actions are predictions over , which are also probability distributions over .  There is a correspondence between proper scoring rules and Bregman divergences as explained in . If is a Bregman divergence and is a function with domain then given by defines a scoring rule.  Assume that is a proper scoring function. Then a function can be defined as This lead to the regret function Since is assumed to be proper . The Bregman identity ( ) follows by straight forward calculations. With these two results we see that the regret function is a Bregman divergence and that Hence a proper scoring rule has the form where . A [STRICTLY PROPER SCORING RULE]{} can be defined as a proper scoring rule where the corresponding Bregman divergence is strict.  The Brier score is given by The Brier score is generated by the strictly convex function">
  </outline>
  <outline text="Statistical mechanics" _note="Thermodynamics is the study of concepts like heat, temperature and energy. A major objective is to extract as much energy from a system as possible. The idea in statistical mechanics is to view the macroscopic behavior of a thermodynamic system as a statistical consequence of the interaction between a lot of microscopic components where the interacting between the components are governed by very simple laws. Here the central limit theorem and large deviation theory play a major role. One of the main achievements is the formula for entropy as a logarithm of a probability.  Here we shall restrict the discussion to the most simple kind of thermodynamic system from which we want to extract energy. We may think of a system of non-interacting spin particles in a magnetic field. For such a system the Hamiltonian is given by where is the spin configuration, is the magnetic moment, is the strength of an external magnetic field, and is the spin of the the ’th particle. If the system is in thermodynamic equilibrium the configuration probability is where is the partition function Here is the inverse temperature of the spin system and is Boltzmann’s constant.  The mean energy is given by which will be identified with the internal energy defined in thermodynamics. The Shannon entropy can be calculated as The Shannon entropy times will be identified with the thermodynamic entropy .  The amount of energy that can be extracted from the system if a heat bath is available, is called the EXERGY . We assume that the heat bath has temperature and the internal energy and entropy of the system are and if the system has been brought in equilibrium with the heat bath. The exergy can be calculated by The information divergence between the actual state and the corresponding state that is in equilibrium with the environment is Hence This equation appeared already in .">
  </outline>
  <outline text="Portfolio theory" _note="The relation between information theory and gambling was established by Kelly . Logarithmic terms appear because we are interested in the exponent in the exponential growth rate of our wealth. Later Kelly’s approach has been generalized to trading of stocks although the relation to information theory is weaker .  Let denote PRICE RELATIVES for a list of assets. For instance means that asset no. 5 increases its value by 4 %. Such price relatives are mapped into a price relative vector  A special asset is the SAFE ASSET where the price relative is 1 for any possible price relative vector. Investing in this asset corresponds to placing the money at a safe place with interest rate equal to 0 % .  A PORTFOLIO is a probability vector where for instance means that 30 % of the money is invested in asset no. 5. We note that a portfolio may be traded just like the original assets. The price relative for the portfolio is The original assets may be considered as extreme points in the set of portfolios. If an asset has the property that the price relative is only positive for one of the possible price relative vectors, then we may call it a GAMBLING ASSET.  We now consider a situation where the assets are traded once every day. For a sequence of price relative vectors and A CONSTANT RE-BALANCING PORTFOLIO the wealth after days is where the expectation is taken with respect to the empirical distribution of the price relative vectors. Here is proportional to the DOUBLING RATE and is denoted where indicates the probability distribution of . Our goal is to maximize by choosing an appropriate portfolio  Let and denote two portfolios. We say that DOMINATES if for any possible price relative vector We say that STRICTLY DOMINATES if for any possible price relative vector A set of assets is said to dominate the set of assets if any asset in is dominated by a portfolio of assets in  The maximal doubling rate does not change if dominated assets are removed. Sometimes assets that are dominated but not strictly dominated may lead to non-uniqueness of the optimal portfolio.  Let denote a portfolio that is optimal for and define The regret of choosing a portfolio that is optimal for when the distribution is is given by the regret function If is not uniquely determined we take a minimum over all that are optimal for    Assume that the price relative vector is with probability and with probability . Then the portfolio concentrated on the first asset is optimal for and the portfolio concentrated on the second asset is optimal for . For values of between and the optimal portfolio invests money on both assets as illustrated in Figure  .  (0.,0.) – (1.1177000323939097,0.); in [,0.2,0.4,0.6,0.8,1,0]{} (0pt,2pt) – (0pt,-2pt);  (0.,0.) – (0.,0.9124392614188542); in [0.2,0.4,0.6,0.8]{} (2pt,0pt) – (-2pt,0pt);  plot   coordinates [ (0.2,0.4182935787194957) (0.24350034788969488,0.36120950042115774) (0.2870003018694437,0.3168468268696912) (0.3305002558491924,0.2817583882332283) (0.36050022411108806,0.26258526897379575) (0.4010001812646472,0.242875609771641) (0.4475001320705855,0.2286661976310767) (0.4880000892241446,0.22343157468501623) (0.540500033682462,0.22642765345704483) (0.6079999622717273,0.24665640576588088) (0.6469999210121916,0.26700668167457386) (0.6844998813395612,0.29285980246773613) (0.7279998353193099,0.33105261588381335) (0.7519998099288264,0.35616328670391684) (0.7999997591478595,0.4158879744441841)]{};  (0.2,0.4182935787194957)– (0.2,0.); (0.8000000094532285,0.41588832144092486)– (0.8,0.);  (0.02926465824424991,0.8875607385811478) node  []{}; (1.05,0.09) node  []{}; (-0.02,-0.01) node  []{}; (0.16,-0.01) node  []{}; (0.76,-0.01) node  []{}; (0.98,-0.01) node  []{};  (0.,0.6931471805599453)– (0.19827171206890273,0.4182935787194957); (1.,0.6931471805599453)– (0.8000000094532285,0.41588832144092486);  (0.8000000094532285,0.41588832144092486) circle (2.0pt); (0.19827171206890273,0.4182935787194957) circle (2.0pt); (0.,0.6931471805599453) circle (2.0pt); (1.,0.6931471805599453) circle (2.0pt);  If there are only two price relative vectors and the regret function is strict then either one of the assets dominates all other assets or two of the assets are orthogonal gambling assets that dominate all other assets.  We will assume that no assets are dominated by other assets. Let denote the two price relative vectors. Without loss of generality we may assume that If then so that if then and the asset is dominated by the asset Since we have assumed that no assets are dominated we may assume that If is a probability vector over the two price relative vectors then according to the portfolio is optimal if and only if for all with equality if Assume that the portfolio is optimal. Now is equivalent to Similarly is equivalent to We have to check that which is equivalent with The right hand side equals the determinant which is positive because asset is not dominated by a portfolio based on asset and asset  We see that the portfolio concentrated in asset is optimal for in an interval of positive length and the regret between distributions in such an interval will be zero. In particular the regret will not be strict.  Strictness of the regret function is only possible if there are only two assets and if a portfolio concentrated on one of these assets is only optimal for a singular probability measure. According to the formulas for the end points of intervals ( ) and ( ) this is only possible if the assets are gambling assets.    If the regret function is strict it equals information divergence, i.e.  If the regret function is strict then it is also strict when we restrict to two price relative vectors. Therefore any two price relative vectors are orthogonal gambling assets. If the assets are orthogonal gambling assets we get the type of gambling described by Kelly . For gambling equation can easily be derived .">
  </outline>
</outline>
<outline text="Sufficiency Conditions" _note="In this section we will introduce some conditions on a regret function. Under some mild conditions they turn out to be equivalent.  Let denote a regret function based on a continuous and convex function defined on the state space of a finite dimensional -algebra. If the state space has at least three orthogonal states then the following conditions are equivalent.  The function equals entropy times a negative constant plus an affine function.  The regret is proportional to information divergence.  The regret is monotone.  The regret is satisfies sufficiency.  The regret is local.  In the rest of this section we will describe each of these equivalent conditions and prove that they are actually equivalent. The theorems and proofs will be stated so that they hold even for more general state spaces than the ones considered in this paper.">
  <outline text="Entropy and Information Divergence" _note="Let denote an element in a state space. The ENTROPY of is be defined as where the infimum is taken over all decompositions of into pure states .  This definition of the entropy of a state was first given by Uhlmann . Using that entropy is decreasing under majorization we see that the entropy of is attained at an orthogonal decomposition and we obtain the familiar equation  In general this definition of entropy does not provide a concave function on a convex set. For instance the entropy of points in the square has local maximum in the four different points. A characterization of the convex sets with concave entropy functions is lacking.  If the entropy is a concave function then the Bregman divergence is called INFORMATION DIVERGENCE.  The information divergence is also called KULLBACK-LEIBLER DIVERGENCE, RELATIVE ENTROPY or QUANTUM RELATIVE ENTROPY. In a C\*-algebra we get where Now so that Hence For states it reduces to the well-known formula">
  </outline>
  <outline text="Monotonicity" _note="We consider a set of maps of the state space into itself. The set will be used to represent those transformations that we are able to perform on the state space before we choose a feasible action . Let denote a map. Then the dual map maps actions into actions and is given by    If maps the set of feasible actions into itself then  If then because . Inequality ( ) follows because  Let denote a map of the state space into itself such that maps the set of feasible actions into itself and let denote a state that minimizes the function . If is a Bregman divergence then  Since minimizes and is differentiable we have . Since minimizes and we also have that minimizes and that . Therefore which proves the inequality.  Next we introduce the stronger notion of monotonicity.  Let denote a regret function on the state space of a finite dimensional C\*-algebra. Then is said to be MONOTONE if for any affine map    If a regret function based on a convex and continuous function is monotone then it is a Bregman divergence.  Assume that is monotone. We have to prove that is differentiable. Since is convex it is sufficient to prove that any restriction of to a line segment is differentiable. Let and denote states that are the end points of a line segment. The restriction of to the line segment is given by the convex and continuous function so we have to prove that is differentiable.  If then according to Equation ( ) we have where denotes the denote the derivative from the right. A dilation by a factor around decreases the regret so that is increasing. Since is convex the function is increasing. Assume that is not differentiable so that has a positive jump as illustrated on Figure  . This contradicts that the function ( ) is increasing. Therefore is continuous and is differentiable.  (0.,0.) – (1.15,0.); (0.,0.) – (0.,1);  (0,0.45) – (0.4499987575911538,0.45); (0.4500007324771293,0.4500007324771293) – (0.998624824324231,0.998624824324231);  (1.,1.)– (1.,0.); (0.50,0.)– (0.50,0.50); (0.8,0.)– (0.80,0.80); (0.4,0.)– (0.4,0.45);  (0.78,-0.04) node  []{}; (0.96,-0.04) node  []{}; (0.32,-0.04) node  []{}; (0.47,-0.04) node  []{}; (1.07,0.1) node  []{}; (0.04164903189233505,1) node  []{}; (0.4,0.45)– (0.8,0.45);  (1.,0.) circle (2pt); (0.50,0.) circle (2pt); (0.8,0.) circle (2pt); (0.4,0.45) circle (2pt); (0.4,0.) circle (2pt); (0.50,0.50) circle (2pt); (0.80,0.80) circle (2pt); (1.,1.) circle (2pt); (0.8,0.45) circle (2pt);  Recently it has been proved that information divergence on a complex Hilbert space is decreasing under positive trace preserving maps . Previously this was only known to hold if some extra condition like complete positivity or 2-positivity was assumed .  Information divergence is monotone under any positive trace preserving map on the states of a finite dimensional -algebra.  Any finite dimensional -algebra can be embedded in and there exist a conditional expectation If is a positive trace preserving map of the density matrices of into it self then is positive and trace preserving on According to M[ü]{}ller-Hermes and Reeb we have for density matrices in In particular this inequality holds for density matrices in and for such matrices we have .">
  </outline>
  <outline text="Sufficiency" _note="The notion of sufficiency plays an important role in statistics and related fields. We shall present a definition of sufficiency that is based on , but there are a number of other equivalent ways of defining this concept. We refer to where the notion of sufficiency is discussed in great detail.  Let denote a family of states and let denote an affine map where and denote state spaces. A RECOVERY MAP is an affine map such that The map is said to be SUFFICIENT for if has a recovery map.  Assume is a regret function based on a convex and continuous function and assume that is sufficient for and with recovery map . Assume that both and map the set of feasible actions into itself. Then  According to the principle of lest opportunities (Proposition  ) we have Therefore Let denote an action that is optimal for Then and we see that is optimal for Now where the infimum is taken over actions that are optimal for Then so we have The reverse inequality is proved in the same way.  The notion of sufficiency as a property of divergences was introduced in . The crucial idea of restricting the attention to maps of the state space into itself was introduced in . It was shown in that a Bregman divergence on the simplex of distributions on an alphabet that is not binary and satisfies sufficiency equals information divergence up a multiplicative factor. Here we extend the notion of sufficiency from Bregman divergences to regret functions.  Let denote a regret function based on a convex and continuous function on a state space . We say satisfies SUFFICIENCY if for any affine map that is sufficient for   Let denote a regret function based on a convex and continuous function on a state space . If the regret function is monotone then it satisfies sufficiency.  Assume that the regret function is monotone. Let and denote two states and let and denote maps on the state space such that  . Then Hence  Combining the previous results we get that information divergence satisfies sufficiency. Under some conditions there exists an inverse version of Proposition   stating that if monotonicity holds with equality then the map is sufficient. In statistics where the state space is a simplex, this result is well established. For density matrices over the complex numbers it has been proved for completely positive maps in . Some new results on this topic can be found in .">
  </outline>
  <outline text="Locallity" _note="Often it is relevant to use the following weak version of the sufficiency property.  Let denote a regret function based on a convex and continuous function on a state space . The regret function is said to be local if when the states and are orthogonal to and  On a 1-dimensional simplex (an interval) or on the Block sphere any regret function is local. The reason is that if and are states that are orthogonal to then  Let denote a regret function based on a convex and continuous function on a state space . If the regret function satisfies sufficiency then is local.  Let and be states that are orthogonal to Let denote the projection supporting the state . Let the maps and be defined by Then and and Therefore and  Let be the state space of a -algebra with at least three orthogonal states, and let denote a regret function based on a convex and continuous function on the state space . If the regret function is local then it is the Bregman divergence generated by the entropy times a negative constant.  In the following proof we will assume that the regret function is based on the convex function First we will prove that the regret function is a Bregman divergence.  Let denote the convex hull of a set of orthogonal states. For let denote the function . Note that is decreasing and continuous from the left. Let and where for all . If is differentiable in then locality implies that Note that is a convex function and thereby it is continuous. Assume that is an arbitrary element in and let denote a sequence such that for The sequence can be choosen so that regret is differentiable in for all Further the sequence can be chosen such that is increasing for all Then Similarly, if the sequence can be chosen such that is increasing for all then which implies that and that for all . Therefore for all in the interior of . In the following calculations we will assume that the distributions lie in the interior of . The validity of the Bregman identity ( ) follows directly from Equation   implying that is a Bregman divergence.  As a function of the regret is minimal when In the following calculations we write , , , and . If for then non-negativity of regret can be written as and we note that this inequality should hold as long as Permutation of and leads to the inequality that implies where  Assume that in Inequality ( ). Then so that is mid-point convex, which for a measurable function implies convexity. Therefore is differentiable from left and right.  If and and then we have with equality when We differentiate with respect to from right. which is positive for so that Since is convex we have which in combination Inequality ( ) implies that so that is differentiable. Since the function is also differentiable.  As a function of the Bregman divergence has a minimum at under the condition . Since the functions are differentiable we can characterize this minimum using Lagrange multipliers. We have and Further so there exist a constant such that Hence so that for some constant  Now we get Therefore there exists an affine function defined on such that for all in the interior of . Since is continuous on Equation ( ) holds for any . If each of the sets and is a simplex and then so that If has dimension greater than zero then the right hand side is affine so the left hand side is affine, which is only possible when Therefore we also have for all Therefore the functions can be extended to a single affine function on the whole of">
  </outline>
</outline>
<outline text="Applications">
  <outline text="Information theory" _note="If only integer values of a code-length function are allowed then there are only finitely many actions that are not dominated. Therefore the function given by is piece-wise linear. In particular is not differentiable so that the regret is not a Bregman divergence and cannot be monotone according to Proposition  . In information theory monotonicity of a divergence function is closely related to the DATA PROCESSING INEQUALITY and since the data processing inequality is one of the most important tools for deriving inequalities in information theory we need to modify our notion of code-length function in order to achieve a data processing inequality.  We now formulate a version of Kraft’s inequality that allow the code length function to be non-integer valued.   Let be a function. Then the function satisfies Kraft’s inequality ( ) if and only if for all there exists an integer and a uniquely decodable fixed-to-variable length block code such that where denotes the length divided by The uniquely decodable block code can be chosen to be prefix free.  Assume that satisfies Kraft’s inequality. Then Therefore the function given by is integer valued and satisfies Kraft’s inequality ( ) and there exists a prefix-free code such that Therefore so for any choose such that  Assume that for all there exists a uniquely decodable fixed-to-variable length code such that for all strings Then satisfies Kraft’s Inequality( ) and Therefore for all and the result is obtained.  Like in Bayesian statistics we focus on finite sequences. Contrary to Bayesian statistics we should always consider a finite sequence as a prefix of LONGER FINITE sequences. Contrary to frequential statistics we do not have to consider a finite sequence as a prefix of an INFINITE sequence.  If we minimize the mean code-length over functions that satisfy Kraft’s inequality ( ), but without an integer constraint the code-length should be and the function is given by The function is proportional to the Shannon entropy and the (negative) proportionality factor is determined by the size of the output alphabet.  In lossy source coding and rate distortion theory it is important to choose a distortion function with tractable properties. The notion of sufficiency for divergence functions was introduced in in order to characterize such tractable distortions functions. In this paper the main result was that sufficiency together with properties related to Bregman divergence lead directly to the information bottleneck method introduced by N. Tishby . Logarithmic loss has also been studied for lossy compression in .">
  </outline>
  <outline text="Statistics" _note="In statistics one is often interested in scoring rules that are local, which means a scoring rule where the payoff only depends on the probability of the observed value and not on the predicted distribution over unobserved values. The notion of locality has recently been extended by Dawid, Lauritzen and Parry , but here we shall focus on the original definition. The basic result is that the only local strictly proper scoring rule is logarithmic score that was proved by Bernardo under the assumption that scoring rule is given by a smooth function .  A LOCAL STRICTLY PROPER SCORING RULE is a scoring rule of the form  On a finite space a local strictly proper scoring rule is given by a local regret function.  The regret function of a local strictly proper scoring rule is given by If and and are mutually singular then and we see that the regret does not depend on because vanish on the support of Therefore the regret function is local.  On a finite space with at least three elements a local strictly proper scoring rule is given by a function of the form for some constants and  Also the notion of sufficiency plays an important role in statistics. Here we will restrict the discussion to 1-dimensional exponential families. A natural exponential family is a family of probability distributions of the form where is a reference measure on the real numbers and is the moment generating function given by . Then is a sufficient statistic for the family  In a Bernoulli model a sequence is predicted with probability The function induces a sufficient map from probability distributions on to probability distributions on The reverse map maps a measure concentrated in into a uniform distributions over sequences that satisfy  The mean value of is The set of possible mean values is called the mean value range and is an interval. Let denote the element in the exponential family with mean value Then a Bregman divergence on the mean value range is defined by Note that the mapping is not affine so the Bregman divergence will in general not be given by the formula for information divergence with the family of binomial distributions as the only exception. Nevertheless the Bregman divergence encode important information about the exponential family. In statistics it is common to use squared Euclidean distance as distortion measure, but often it is better to use the Bregman divergence as distortion measure. Note that is only proportional to squared Euclidean distance for the Gaussian location family.  An exponential distribution has density This leads to a Bregman divergence on the interval given by This Bregman divergence is called the ISAKURA-SAITO DISTANCE. The Isakura-Saito distance is defined on an unbounded set so our previous results cannot be applied. Affine bijections on have the form for some constant . The Isakura-Saito distance obviously satisfy sufficiency for such maps and it is a simple exercise to check that the Isakura-Saito distance is the only Bregman divergence on that satisfies sufficiency. Any affine map is composed of a map where and a right translation where The Itakura-Saito distance decreases under right translations because Thus the Isakura-Saito distance is monotone.  Both sufficiency and the Bregman identity are closely related to inference rules. In I. Csisz[á]{}r explained why information divergence is the only divergence function on the cone of positive measures that lead to tractable inference rules. One should observe that his inference rules are closely related to sufficiency and the Bregman identity, and the present paper may be view as a generalization of these results of I. Csisz[á]{}r.">
  </outline>
  <outline text="Statistical mechanics" _note="Statistical mechanics can be stated based on classical mechanics or quantum mechanics. For our purpose this makes no difference because our theorems are valid for both classical systems and quantum systems.  As we have seen before Our general results for Bregman divergences imply that the Bregman divergence based on this exergy satisfies Therefore for any map that is sufficient for The equality holds for any regret function that is reversible and conserves the state that is in equilibrium with the environment. Since a different temperature of the environment leads to a different state that is in equilibrium the equality holds for any reversible map that leave some equilibrium state invariant. We see that is uniquely determined as long as there exists a sufficiently large set of maps that are reversible.  In this exposition we have made some short-cuts. First of all we did not derive equation  . In particular the notion of temperature was used without discussion. Secondly we identified the internal energy with the mean value of the Hamiltonian and identified the thermodynamic entropy with times the Shannon entropy. Finally, in the argument above we need to verify in all details that the set of reversible maps is sufficiently large to determine the regret function. For classical thermodynamics the most comprehensive exposition was done by Lieb and Yngvason . In their exposition randomness was not taken into account. With the present framework it is also possible to handle randomness so that one can make a bridge between thermodynamics and statistical mechanics. A detailed exposition will be given in a future paper.  According to Equation ( ) any bit of information can be converted into an amount of energy! One may ask how this is related to the mixing paradox (a special case of Gibbs’ paradox). Consider a container divided by a wall with a blue and a yellow gas on each side of the wall. The question is how much energy can be extracted by mixing the blue and the yellow gas?  (8.,5.) – (5.,5.) – (5.,3.) – (8.,3.) – cycle; (2.,5.) – (5.,5.) – (5.,3.) – (2.,3.) – cycle; (2.,2.) – (8.,2.) – (8.,0.) – (2.,0.) – cycle; (2.,5.)– (8.,5.); (8.,5.)– (8.,3.); (8.,3.)– (2.,3.); (2.,3.)– (2.,5.); (5.,5.)– (5.,3.);  (2.,2.)– (8.,2.); (8.,2.)– (8.,0.); (8.,0.)– (2.,0.); (2.,0.)– (2.,2.); (5.,2.)– (5.,0.);  We loose one bit of information about each molecule by mixing the blue and the green gas, but if the color is the ONLY DIFFERENCE no energy can be extracted. This seems to be in conflict with Equation ( ), but in this case different states cannot be converted into each other by reversible processes. For instance one cannot convert the blue gas into the yellow gas. To get around this problem one can restrict the set of preparations and one can restrict the set of measurements. For instance one may simply ignore measurements of the color of the gas. What should be taken into account and what should be ignored, can only be answered by an experienced physicist. Formally this solves the mixing paradox, but from a practical point of view nothing has been solved. If for instance the molecules in one of the gases are much larger than the molecules in the other gas then a semi-permeable membrane can be used to create an osmotic pressure that can be used to extract some energy. It is still an open question which differences in properties of the two gases that can be used to extract energy.">
  </outline>
  <outline text="Monotone regret for portfolios" _note="We know that in general a local regret function on a state space with at least three orthogonal states is proportional to information divergence. In portfolio theory we get the stronger result that monotonicity implies that we are in the situation of gambling introduced by Kelly .   Assume that none of the assets are dominated by a portfolio of other assets. If the regret function given by ( ) is monotone then the regret function equals information divergence and the measures and are supported by distinct price relative vectors of the form , until  If there are more than three price relative vectors then a monotone regret function is always proportional to information divergence which is a strict regret function. Therefore we may assume that there are only two price relative vectors. Assume that the regret function is not strict. Then the function defined by ( ) is not strictly convex. Assume that so that is affine between and . Let be a contraction around one of the end points of intersection between the state space and the line through and . Then monotonicity implies that so that is affine on the line between and . This holds for contractions around any point. Therefore is affine on the whole state space which implies that there is a single portfolio that dominates all assets. Such a portfolio must be supported on a single asset. Therefore monotonicity implies that if two assets are not dominated then the regret function is strict and according to Theorem   we have already proved that a strict regret function in portfolio theory is proportional to information divergence.  If the regret function divergence is monotone and one of the assets is the safe asset then there exists a portfolio such that for all Equivalently which is possible if and only if One say that the gamble is FAIR if . If the gamble is SUPER-FAIR, i.e. , then the portfolio gives a price relative equal to independently of what happens, which is a DUTCH BOOK.  In portfolio theory the regret function given by ( ) is monotone if and only if it is strict.  We use that in portfolio theory the regret function is monotone if and only it is proportional to information.">
  </outline>
</outline>
<outline text="Concluding remarks" _note="In it was proved that if is a function such that the Bregman divergence based on is monotone on any (simple) C\*-algebra then the Bregman divergence is jointly convex. As we have seen that monotonicity implies that the Bregman divergence must be proportional to inform divergence, which is jointly convex in both arguments. We also see that in general joint convexity is not a sufficient condition for monotonicity, but in the case where the state space has only two orthogonal states it is not known if joint convexity of a Bregman divergence is sufficient to conclude that the Bregman divergence is monotone.  One should note that the type of optimization presented in this paper is closely related to a game theoretic model developed by F. Topsøe . In his game theoretic model he needed what he called the [PERFECT MATCH PRINCIPLE]{}. Using the terminology presented in this paper the perfect match principle states that the regret function is a strict Bregman divergence. As we have seen the perfect match principle is only fulfilled in portfolio theory if all the assets are gambling assets. Therefore the theory of F. Topsøe can only be used to describe gambling while our optimization model can describe general portfolio theory and our sufficient conditions can explain exactly when our general model equals gambling.  The original paper of Kullback and Leibler was called “On Information and Sufficiency”. In the present paper we have made the relation between information divergence and the notion of sufficiency more explicit. The results presented in this paper are closely related to the result that a divergence that is both an -divergence and a Bregman divergence is proportional to information divergence (see or and references therein). All -divergences satisfy a sufficiency condition, which is the reason why this class of divergences has played such a prominent role in the study of the relation between information theory and statistics. One major question has been to find reasons for choosing between the different -divergences. For instance -divergences of power type (often called Tsallis divergences or Cressie-Read divergences) are popular, but there are surprisingly few papers that can point at a single value of the power that is optimal for a certain problem except if this value is 1. In this paper we have started with Bregman divergences because each optimization problem comes with a specific Bregman divergence. Often it is possible to specify a Bregman divergence for an optimization problem and only in some of the cases this Bregman divergence is proportional to information divergence.  The idea of sufficiency has different relevance in different applications, but in all cases information divergence prove to be the quantity that convert the general notion of sufficiency into a number. In information theory information divergence appear as a consequence of Kraft’s inequality. For code length functions of integer length we get functions that are piecewise linear. Only if we are interested in extend-able sequences we get a regret function that satisfies a data processing inequality. In this sense information theory is a theory of extend-able sequences. For scoring functions in statistics the notion of locality is important. These applications do not refer to sequences. Similarly the notion of sufficiency that plays a major role in statistics, does not refer to sequences. Both sufficiency and locality imply that regret is proportional to information divergence, but these reasons are different from the reasons why information divergence is used in information theory. Our description of statistical mechanics does not go into technical details, but the main point is that the many symmetries in terms of reversible maps form a set of maps so large that our result on invariance of regret under sufficient maps applies. In this sense statistical mechanics and statistics both apply information divergence for reasons related to sufficiency. For portfolio theory the story is different. In most cases one has to apply the general theory of Bregman divergences because we deal with an optimization problem. The general Bregman divergences only reduce to information divergence when the assets are gambling assets.  Often one talk about applications of information theory in statistics, statistical mechanics and portfolio theory. In this paper we have argued that information theory is mainly a theory of sequences, while some problems in statistics and statistical mechanics are also relevant without reference to sequences. It would be more correct to say that convex optimization has various application such as information theory, statistics, statistical mechanics, and portfolio theory and that certain conditions related to sufficiency lead to the same type of quantities in all these applications.">
</outline>
<outline text="Acknowledgment" _note="The author want to thank Prasad Santhanam for inviting me to the Electrical Engineering Department, University of Hawaii at Mānoa, where many of the ideas presented in this paper were developed. I also want to thank Alexander M[ü]{}ller-Hermes, Frank Hansen, and Flemming Tops[ø]{}e for stimulating discussions and correspondence. Finally I want to thank the reviewers for their valuable comments.  [——-]{}  [\#1]{}  Kullback, S.; Leibler, R. On Information and Sufficiency. , [22]{}, 79–86.  Jaynes, E.T. Information Theory and Statistical Mechanics, [I]{} and [II]{}. , [106 AND 108]{}, 620–630 and 171–190.  Jaynes, E.T. Clearing up mysteries – The original goal. In [MAXIMUM ENTROPY AND [B]{}AYESIAN METHODS]{}; Skilling, J., Ed.; Kluwer: Dordrecht, 1989.  Liese, F.; Vajda, I. ; Teubner: Leipzig, 1987.  Barron, A.R.; Rissanen, J.; Yu, B. The Minimum Description Length Principle in Coding and Modeling. , [44]{}, 2743–2760. Commemorative issue.  Csisz[á]{}r, I.; Shields, P. ; Foundations and Trends in Communications and Information Theory, Now Publishers Inc., 2004.  Gr[ü]{}nwald, P.D.; Dawid, A.P. Game Theory, Maximum Entropy, Minimum Discrepancy, and Robust [B]{}ayesian Decision Theory. , [ 32]{}, 1367–1433.  Gr[ü]{}nwald, P. ; MIT Press, 2007.  Holevo, A.S. ; Vol. 1, [NORTH-HOLLAND SERIES IN STATISTICS AND PROBABILITY]{}, North-Holland: Amsterdam, 1982.  Krumm, M.; Barnum, H.; Barrett, J.; M[ü]{}ller, M. Thermodynamics and the structure of quantum theory. arXiv:1608.04461.  Barnum, H.; M[ü]{}ller, M.P.; Ududec, C. Higher-order interference and single-system postulates characterizing quantum theory. , [16]{}, 123029.  Harremo[ë]{}s, P. Maximum Entropy and Sufficiency. Proceedings MaxEnt2016. American Institute of Physics (AIP), 2016, [[  ]{}](http://xxx.lanl.gov/abs/arXiv:1607.02259).  Harremo[ë]{}s, P. Quantum information on Spectral Sets. arXiv:1701.06688 Accepted for presentation at ISIT 2017.  Servage, L.J. The Theory of Statistical Decision. , [46]{}, 55–67.  Kiwiel, K.C. Proximal Minimization Methods with Generalized Bregman Functions. , [ 35]{}, 1142–1168, [[  ]{}](http://xxx.lanl.gov/abs/http://dx.doi.org/10.1137/S0363012995281742).  Kiwiel, K.C. Free-steering Relaxation Methods for Problems with Strictly Convex Costs and Linear Constraints. , [22]{}, 326–349.  Rockafellar, R.T. ; Princeton Univ. Press: New Jersey, 1970.  Hendrickson, A.D.; Buehler, R.J. Proper scores for probability forecasters. , [42]{}, 1916–1921.  Rao, C.R.; Nayak, T.K. Cross Entropy, Dissimilarity Measures, and Characterizations of Quadratic Entropy. , [31]{}, 589–593.  Banerjee, A.; Merugu, S.; Dhillon, I.S.; Ghosh, J. Clustering with [B]{}regman Divergences. , [ 6]{}, 1705–1749.  arthy, J. Measures of the value of information. , [42]{}, 654–655.  Gneiting, T.; Raftery, A.E. Strictly Proper Scoring Rules, Prediction, and Estimation. , [102]{}, 359–378, [[  ]{}](http://xxx.lanl.gov/abs/http://dx.doi.org/10.1198/016214506000001437).  Ovcharov, E.Y. Proper Scoring Rules and Bregman Divergences. Sept. 2015. arXiv:1502.01178.  Gundersen, T. An Introduction to the Concept of Exergy and Energy Quality. Technical report, Department of Energy and Process Engineering, Norwegian University of Science and Technology, Trondheim, Norway, 2011. http://www.ivt.ntnu.no/ept/fag/tep4120/innhold/Exergy Harremo[ë]{}s, P. ; Vol. 255, [ IMFUFA-TEKST]{}, IMFUFA Roskilde University, 1993. Original in Danish entitled Tid og Betinget Uafh[æ]{}ngighed. English translation partially available.  Kelly, J.L. A New Interpretation of Information Rate. , [35]{}, 917–926.  Cover, T.; Thomas, J.A. ; Wiley, 1991.  Uhlmann, A. On the [S]{}hannon Entropy and Related Functionals on Convex Sets. , [1]{}, 147–159.  M[ü]{}ller-Hermes, A.; Reeb, D. Monotonicity of the Quantum Relative Entropy Under Positive Maps. , [[  ]{}](http://xxx.lanl.gov/abs/Sept. 2016. arXiv:1512.06117v2).  Christandl, M.; M[ü]{}ller-Hermes, A. Relative Entropy Bounds on Quantum, Private and Repeater Capacities. April, 2016. arXiv:1604.03448.  Petz, D. Monotonicity of Quantum Relative Entropy Revisited. , [15]{}, 79–91, [[  ]{}](http://xxx.lanl.gov/abs/http://www.worldscientific.com/doi/pdf/10.1142/S0129055X03001576).  Petz, D. Sufficiency of Channels over von [N]{}eumann algebras. , [39]{}, 97–108,.  Jen[č]{}ov[á]{}, A.; Petz, D. Sufficiency in quantum statistical inference. , [ 263]{}, 259–276.  Harremo[ë]{}s, P.; Tishby, N. The Information Bottleneck Revisited or How to Choose a Good Distortion Measure. Proceedings ISIT 2007, Nice. IEEE Information Theory Society, 2007, pp. 566–571.  Jiao, J.; amd Albert No, T.C.; Venkat, K.; Weissman, T. Information Measures: the Curious Case of the Binary Alphabet. , [60]{}, 7616–7626.  Jen[č]{}ov[á]{}, A. Preservation of a quantum [R]{}[é]{}nyi relative entropy implies existence of a recovery map. , [50]{}, 085303.  Tishby, N.; Pereira, F.; Bialek, W. The information bottleneck method. Proceedings of the 37-th Annual Allerton Conference on Communication, Controland Computing, 1999, pp. 368–377.  No, A.; Weissman, T. Universality of logarithmic loss in lossy compression. 2015 IEEE International Symposium on Information Theory (ISIT), 2015, pp. 2166–2170.  Dawid, A.P.; Lauritzen, S.; Perry, M. Proper local scoring rules on discrete sample spaces. , [40]{}, 593–603.  Bernardo, J.M. Expected Information as Expected Utility. , [7]{}, 686–690. Institute of Mathematical Statistics.  Csisz[á]{}r, I. Why least squares and maximum entropy? An axiomatic approach to inference for linear inverse problems. , [19]{}, 2032–2066.  Lieb, E.; Yngvason, J. A Guide to Entropy and the Second Law of Thermodynamics. , [45]{}, 571–581.  Lieb, E.; Yngvason, J., The Mathematics of the Second Law of Thermodynamics. In [VISIONS IN MATHEMATICS]{}; Alon, N.; Bourgain, J.; Connes, A.; Gromov, M.; Milman, V., Eds.; Birkh[ä]{}user Basel, 2010; pp. 334–358.  Pitrik, J.; Virosztek, D. On the Joint Convexity of the Bregman Divergence of Matrices. , [ 105]{}, 675–692.  Tops[ø]{}e, F. Game theoretical optimization inspired by information theory. , [43]{}, 553.  Tops[ø]{}e, F. Cognition and Inference in an Abstract Setting. Proceedings WITMSE 2011, 2011.  Amari, S.I. -Divergence Is Unique, Belonging to Both -Divergence and Bregman Divergence Classes. , [ 55]{}, 4925–4931.">
</outline>
  </body>
</opml>