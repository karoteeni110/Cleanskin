<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>An estimate for an expectation of the simultaneous renewal for
time-inhomogeneous Markov chains</title>
    <abstract>In this paper, we consider two time-inhomogeneous Markov chains , , with
discrete time on a general state space. We assume the existence of some
renewal set and investigate the time of simultaneous renewal, that is,
the first positive time when the chains hit the set simultaneously. The
initial distributions for both chains may be arbitrary. Under the
condition of stochastic domination and nonlattice condition for both
renewal processes, we derive an upper bound for the expectation of the
simultaneous renewal time. Such a bound was calculated for two
time-inhomogeneous birth–death Markov chains. </abstract>
  </head>
  <body>
<outline text="Introduction">
  <outline text="Overview" _note="Simultaneous renewal is an important topic for a practical application of Markov chains. Although it has its own value, for example, in queuing theory, we are interested in its investigation because it plays an essential role in coupling construction, which can be used to derive stability estimates of the -step transition probabilities and other results like the law of large numbers and limit theorems.  For example, in , we can find how a stability estimate can be calculated using the coupling method for two time-inhomogeneous Markov chains with discrete time on the general state space. Good examples of applications of the coupling method (for both homogeneous and inhomogeneous Markov chains) are given in .  It worth mentioning that the coupling construction for time-inhomogeneouschains is slightly different from its classical setup (see, e.g., ). Such a time-inhomogeneous coupling for general state space can be found in . Its modification, called the maximal coupling, can be used for a discrete space. More information about maximal coupling and its application to stability in the time-homogeneous case can be found in .  For maximal coupling and its application to stability in the time-inhomogeneous case, see .  The crucial problem in the application of the results in the listed papers was calculation of the expectation for the coupling moment deriving from the simultaneous renewal. But there were no good estimates for the expectation of a simultaneous renewal for the time-inhomogeneous case.  For the time-homogeneous case, the paper proposes such an estimate based on the Daley inequality (see ).  In , we derived conditions (see Thm. 3.1) that guarantee that the expectation for the simultaneous renewal time is finite. But there were no practical estimates for the expectation.  In , we derived an analogue of the Daley inequality that is used in this paper. The key condition for this inequality is a finiteness of the second moment for the stochastic dominant of the original renewal process. Thats why it is a crucial condition for the estimate construction.">
  </outline>
  <outline text="Definitions and notation" _note="We consider two independent time-inhomogeneous Markov chains with discrete time and general state space . We assume that both chains are defined on the same probability space . Denote these chains as . We use the following notation for the one-step transition probabilities: where is an arbitrary element, , and is an arbitrary set. We continue to use the definitions and notation from . We consider some set , and our goal is to find an upper bound for the expectation of the first time of visiting the set by both chains.  Define the renewal intervals where , and renewal times  Then we can define the renewal probabilities It is worth mentioning that, in general, also depends on the value of which can hit different states inside . However, we will omit for simplicity. We refer the reader to for more details about definition ( ).  Let us define the renewal sequence recursively:  The time of simultaneous hitting the set is defined as  The notion of the overshoot or excess is defined as follows: It is, in fact, the next time after when the chain hits the set .">
  </outline>
</outline>
<outline text="Estimate for the expectation of the simultaneous hitting time" _note="First, we need put the condition on that guarantees its separation from 0. In the time-homogeneous case, this follows from the renewal theorem, but for the time-inhomogeneous case, there is no such theorem. Therefore, we need the following condition.  CONDITION A. There are a constant and a number such that, for all and , It is important that this condition also guarantees certain “regularity” of a chain in terms of periodicity. The periodic chains obviously do not satisfy it.  There are various theorems that allow us to check Condition A in practice. See, for example, , Theorems 4.1, 4.2, 4.3. We will later use some of them.  We need a condition of the stochastic domination in order to apply Theorem 3.1 from .  CONDITION B. Distributions are stochastically dominated by some sequence , , which means that and that the stochastic dominant has finite first and second moments  The sequence is nonincreasing because .  It is worth mentioning that we do not require to be a probability distribution, that is, the total mass not necessarily equals .    Assume that conditions (A) and (B) hold for the chains , , defined before and that the renewal sequences are generated by them. Then the expectation of the simultaneous hitting time for the set satisfies the inequality where  Let us recall the notation from : and further on  The moments are called coupling trials. Let us define and the sequence of sigma-fields , , by  We will use the same idea as in the Theorem 5.1 from .\ First, we assume that , which means that the second chain starts from the set .  The next representation of time is following directly from the definitions:  Using Lemma   and the fact that , we can derive the following inequality:  Lemma 8.5 from implies  Taking the unconditional expectation of the both parts in ( ) gives us  Applying this inequality to ( ), we have  Now, we have to get rid of the assumption . The same calculations as in after formula (20) give us">
</outline>
<outline text="Application to the birth–death processes" _note="Consider two time-inhomogeneous processes and with the following transition probabilities on the th step: and  We would like to estimate the expectation applying Theorem  . So we have to check the regularity condition A and the domination condition B.  We will need the second moment of the dominating distribution, which is difficult to derive for chains and . So the idea is to construct a domination sequence based on some simple homogeneous Markov chain whose renewal sequence is well studied and whose second moment can be calculated easily. The closest chain similar to the birth–death chains we consider here is a random walk on the half-line.  The domination sequence based on such a random walk is constructed in Lemma  , and Lemma   gives its first and second moments that we need for Theorem  .  Next, we will check regularity condition A. First, we assume that, for every , , and  We will use Corollary to Theorem 4.2 from in order to check Condition A. It says that if and a domination sequence exists, then Condition A holds. Moreover, its proof (see , inequality for ) contains an estimate for : Finally, we can state the following result.    Assume that for chains with transition probabilities , defined before, condition ( ) holds and that there exists that satisfies condition ( ) for both chains and . If both chains start from the zero state, then the expectation of their simultaneous renewal satisfies the inequality where are defined in Lemma  , and is defined in ( ).  The statement of the theorem follows from Theorem  , applied to chains and with domination sequence constructed in Lemma  , the constant defined before, and the variables and calculated in Lemma  .">
</outline>
<outline text="Auxiliary results" _note="  We have the inequality for , where is defined in ( ).  From Lemma 8.3 of we can derive:  At the same time, Theorem 3.1 from gives us the inequality taking into account the domination condition B.  Putting ( ) into formulas ( ) yields the required result ( ).    Consider the following time-inhomogeneous birth–death Markov chain with the transition probabilities on the -th step and the time-homogeneous random walk with the transition probability matrix Let and let be a distribution of the first after returning into for the chain , which is in the zero state at the moment .  Assume that there exists some such that, for all , the following inequations hold: Denote by the renewal probability for the chain ( is the probability of the first returning to for the chain started at ): and let , , and .  Then the sequence stochastically dominates , or, in other words, where , , and , and , are the probabilities and expectations on the canonical probability space for the chains and , respectively.  First of all, notice that is not a probability distribution. But this is not a big problem since the domination sequence in our construction does not have to be a distribution.  We will show that for all .  Let us start with :  For , consider the event It can be interpreted as a set of trajectories , where if goes up and otherwise. It is clear that, in order to return back to at time , there should be exactly steps up (the first one must be step up) and steps down. It is worth mentioning that not every trajectory of length that has steps up and down belongs to because some of them might visit before , which is not acceptable for . The exact number of such trajectories in is unknown and not important for this proof. What is important, is that each corresponds to the same trajectory for the chain . This means that summing for all gives the probability . Strictly speaking, the chains  and are defined on different probability spaces, but there is an obvious correspondence between the trajectories, and the difference is only in the probabilities. So we can use the same symbol for both.  Since has exactly steps up and steps down, its probability is a product of different and different , for . Notice that some of can be the same.  This means that, after reordering, the probability of such can be presented as for some . We emphasize again that the terms in that product may repeat, but this is not important for this proof.  At the same time, it follows from condition ( ) that for any indexes, and Summing over all such , we obtain ( ) for .    The sequence defined in Lemma   has the finite first and second moments  First we note that since , , and , we have and , where and are the expectation and the second moment for the probability distribution .  The generating function for the distribution equals (see, e.g., )  So, and .  [17]{}  : . , – ().  : . , – ()  , , : . , – ().  , , : . , – ()  , , : . , – ().  , , : . , – ()  : . ().  : . ()  : . , – ().  : . , – ()  : . , – ().  : . , – ()  : . , – ()  : . , – ()  : . , – ()  : . , – ()  , : . , – ()  , : . , – ()  , : . , – ().  , : . , – ()  , : . , – ()  , : . , – ()  , , : . , – ()  , , : . , – ()  , : . , – ().  , : . , – ()  , : . , – ().  , : . , – ()  , : . , – ().  , : . , – ()  : . ().  : . ()  : . , ().  : . , ()">
</outline>
  </body>
</opml>