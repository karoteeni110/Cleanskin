<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>Textual Entailment with Structured Attentions and Composition</title>
    <abstract>Deep learning techniques are increasingly popular in the textual
entailment task, overcoming the fragility of traditional discrete models
with hard alignments and logics. In particular, the recently proposed
attention models achieves state-of-the-art accuracy by computing soft
word alignments between the premise and hypothesis sentences. However,
there remains a major limitation: this line of work completely ignores
syntax and recursion, which is helpful in many traditional efforts. We
show that it is beneficial to extend the attention model to tree nodes
between premise and hypothesis. More importantly, this subtree-level
attention reveals information about entailment relation. We study the
recursive composition of this subtree-level entailment relation, which
can be viewed as a soft version of the Natural Logic framework .
Experiments show that our structured attention and entailment
composition model can correctly identify and infer entailment relations
from the bottom up, and bring significant improvements in accuracy. </abstract>
  </head>
  <body>
<outline text="Introduction">
</outline>
<outline text="Structured Attentions &amp;amp; Entailment Composition">
</outline>
<outline text="Structured Tree Entailment">
</outline>
<outline text="Review: Recursive Tree Meaning Representations">
</outline>
<outline text="Empirical Evaluations">
</outline>
<outline text="Discussion">
</outline>
<outline text="Conclusion" _note="We have presented an approach to model the composition of the entailment relation following the tree structure for the sentence entailment task. We adapted the attention model for tree structures. Experiments show that our model bring significant improvements in accuracy, and is easy to interpret.">
</outline>
<outline text="Acknowledgments" _note="We thank the anonymous reviewers for helpful comments. We are also grateful to James Cross, Dezhong Deng, and Lemao Liu for suggestions. This project was supported in part by NSF IIS-1656051, DARPA FA8750-13-2-0041 (DEFT), and a Google Faculty Research Award.">
</outline>
  </body>
</opml>