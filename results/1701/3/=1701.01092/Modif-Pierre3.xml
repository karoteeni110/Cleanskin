<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title>Inverting the coupling of the signed Gausssian free field with a loop
soup</title>
    <abstract>Lupu introduced a coupling between a random walk loop-soup and a
Gaussian free field, where the sign of the field is constant on each
cluster of loops. This coupling is a signed version of isomorphism
theorems relating the square of the GFF to the occupation field of
Markovian trajectories. His construction starts with a loop-soup, and by
adding additional randomness samples a GFF out of it. In this article we
provide the inverse construction: starting from a signed free field and
using a self-interacting random walk related to this field, we construct
a random walk loop-soup. Our construction relies on the previous work by
Sabot and Tarrès, which inverts the coupling from the square of the GFF
rather than the signed GFF itself. As a consequence, we also deduce an
inversion of the coupling between the random current and the FK-Ising
random cluster models introduced by Lupu and Werner. </abstract>
  </head>
  <body>
<outline text="Introduction" _note="Let be a connected undirected graph, with at most countable and each vertex of finite degree. We do not allow self-loops, however the edges might be multiple. Given an edge, we will denote and its end-vertices, even though is non-oriented and one can interchange and . Each edge is endowed with a conductance . There may be a killing measure on vertices.  We consider the MARKOV JUMP PROCESSES on which being in , jumps along an adjacent edge with rate . Moreover if , the process is killed at with rate (the process is not defined after that time). will denote the time up to which is defined. If , then either the process has been killed by the killing measure (and ) or it has gone off to infinity in finite time (and infinite). We will assume that the process is transient, which means, if is finite, that . will denote the law of started from . Let be the Green function of : Let be the Dirichlet form defined on functions on with finite support: will be the law of the centred GAUSSIAN FREE FIELD (GFF) on with covariance . In case is finite, the density of is Given a finite subset of , and a function on , will denote the law of the GFF conditioned to equal on . will denote the family of local times of : For all , , let Recall the generalized second Ray-Knight theorem on discrete graphs by Eisenbaum, Kaspi, Marcus, Rosen and Shi (see also ):  For any and ,   under  has the same law as   under .  Sabot and Tarrès showed in that the so-called “magnetized” reverse Vertex-Reinforced Jump Process provides an inversion of the generalized second Ray-Knight theorem, in the sense that it enables to retrieve the law of conditioned on . The jump rates of that latter process can be interpreted as the two-point functions of the Ising model associated to the time-evolving weights.  However in the link with the Ising model is only implicit, and a natural question is whether Ray-Knight inversion can be described in a simpler form if we enlarge the state space of the dynamics, and in particular include the “hidden” spin variables.  The answer is positive, and goes through an extension of the Ray-Knight isomorphism introduced by Lupu , which couples the sign of the GFF to the path of the Markov chain. The Ray-Knight inversion will turn out to take a rather simple form in Theorem   of the present paper, where it will be defined not only through the spin variables but also random currents associated to the field though an extra Poisson Point Process.  The paper is organised as follows.  In Section   we recall some background on loop soup isomorphisms and on related couplings and state and prove a signed version of generalized second Ray-Knight theorem. We begin in Section   by a statement of Le Jan’s isomorphism which couples the square of the Gaussian Free Field to the loop soups, and recall how the generalized second Ray-Knight theorem can be seen as its Corollary: for more details see . In Subsection   we state Lupu’s isomorphism which extends Le Jan’s isomorphism and couples the sign of the GFF to the loop soups, using a cable graph extension of the GFF and Markov Chain. Lupu’s isomorphism yields an interesting realisation of the well-known FK-Ising coupling, and provides as well a “Current+Bernoulli=FK” coupling lemma , which occur in the relationship between the discrete and cable graph versions. We briefly recall those couplings in Sections   and  , as they are implicit in this paper. In Section   we state and prove the generalized second Ray-Knight “version” of Lupu’s isomorphism, which we aim to invert.  Section   is devoted to the statements of inversions of those isomorphisms. We state in Section   a signed version of the inversion of the generalized second Ray-Knight theorem through an extra Poisson Point Process, namely Theorem  . In Section   we provide a discrete-time description of the process, whereas in Section   we yield an alternative version of that process through jump rates, which can be seen as an annealed version of the first one. We deduce a signed inversion of Le Jan’s isomorphism for loop soups in Section  , and an inversion of the coupling of random current with FK-Ising in Section  . Finally Section   is devoted to the proof of Theorem  : Section   deals with the case of a finite graph without killing measure, and Section   deduces the proof in the general case.">
</outline>
<outline text="Le Jan’s and Lupu’s isomorphisms">
  <outline text="Loop soups and Le Jan’s isomorphism" _note="The LOOP MEASURE associated to the Markov jump process is defined as follows. Let be the bridge probability measure from to in time (conditionned on ). Let be the transition probabilities of .  Let be the measure on time-parametrised nearest-neighbour based loops (i.e. loops with a starting site) The loops will be considered here up to a rotation of parametrisation (with the corresponding pushforward measure induced by ), that is to say a loop will be the same as , where denotes the concatenation of paths. A LOOP SOUP of intensity , denoted , is a Poisson random measure of intensity . We see it as a random collection of loops in . Observe that a.s. above each vertex , contains infinitely many trivial “loops” reduced to the vertex . There are also with positive probability non-trivial loop that visit several vertices.  Let be the OCCUPATION FIELD of on i.e., for all , In Le Jan shows that for transient Markov jump processes, for all a.s. For he identifies the law of :   has the same law as under .  Let us briefly recall how Le Jan’s isomorphism enables one to retrieve the generalized second Ray-Knight theorem stated in Section  : for more details, see for instance . We assume that is supported by : the general case can be dealt with by an argument similar to the proof of Proposition  . Let , and note that the isomorphism in particular implies that conditionally on has the same law as conditionally on .  On the one hand, given the classical energy decomposition, we have , with the GFF associated to the restriction of to , where and are independent. Now conditionally on has the law of , where is the sign of , which is independent of . But is symmetric, so that the latter also has the law of .  On the other hand, the loop soup can be decomposed into the two independent loop soups contained in and hitting . Now has the law of and conditionally on has the law of the occupation field of the Markov chain under , which enables us to conclude.">
  </outline>
  <outline text="Lupu’s isomorphism" _note="As in , we consider the METRIC GRAPH associated to . Each edge is replaced by a continuous line of length .  The GFF on with law can be extended to a GFF on as follows. Given , one considers inside a conditionally independent Brownian bridge, actually a bridge of a STANDARD BROWNIAN MOTION, of length , with end-values and . This provides a continuous field on the metric graph which satisfies the spatial Markov property.  Similarly one can define a standard Brownian motion on , whose trace on indexed by the local times at has the same law as the Markov process on with jump rate to an adjacent edge up to time , as explained in Section 2 of . One can associate a measure on time-parametrized continuous loops , and let be the Poisson Point Process of loops of intensity : the discrete-time loops can be obtained from by taking the print of the latter on .  Lupu introduced in an isomorphism linking the GFF and the loop soup on .    There is a coupling between the Poisson ensemble of loops and defined above, such that the two following constraints hold:  For all ,  The clusters of loops of are exactly the sign clusters of .  Conditionally on , the sign of on each of its connected components is distributed independently and uniformly in .  Lupu’s isomorphism and the idea of using metric graphs were applied in to show that on the discrete half-plane , the scaling limits of outermost boundaries of clusters of loops in loop soups are the Conformal Loop Ensembles .  Let (resp. ) be the set of edges such that (resp. ) does not touch on , in other words such that all the edge remains in the same sign cluster of (resp. ). Let be the set of edges that are crossed (i.e. visited consecutively) by the trace of the loops on .  In order to translate Lupu’s isomorphism back onto the initial graph , one needs to describe on one hand the distribution of conditionally on the values of , and on the other hand the distribution of conditionally on and the cluster of loops on the discrete graph . These two distributions are described respectively in Subsections   and  , and provide realisations of the FK-Ising coupling and the “Current+Bernoulli=FK” coupling lemma .">
  </outline>
  <outline text="The FK-Ising distribution of  conditionally on" _note="  Conditionally on , is a family of independent random variables and  Conditionally on , are constructed as independent Brownian bridges on each edge, so that are independent random variables, and it follows from the reflection principle that, if , then  Let us now recall how the conditional probability in Lemma   yields a realisation of the FK-Ising coupling.  Assume is finite. Let be a family of positive weights. An ISING MODEL on with interaction constants is a probability on configuration of spins such that An FK-ISING RANDOM CLUSTER MODEL with weights is a random configuration of open (value ) and closed edges (value ) such that where “” denotes the number of clusters created by open edges.  The well-known FK-Ising and Ising coupling reads as follows.    Given an FK-Ising model, sample on each cluster an independent uniformly distributed spin. The spins are then distributed according to the Ising model. Conversely, given a spins configuration following the Ising distribution, consider each edge , such that , closed, and each edge , such that open with probability . Then the open edges are distributed according to the FK-Ising model. The two couplings between FK-Ising and Ising are the same.  Consider the GFF on distributed according to . Let be the random interaction constants  Conditionally on , follows an Ising distribution with interaction constants : indeed, the Dirichlet form ( ) can be written as Similarly, when has boundary condition on , then has an Ising distribution with interaction and conditioned on .  Now, conditionally on , has FK-Ising distribution with weights . Indeed, the probability for conditionally on is , by Lemma  , as in Proposition  .  Note that, given that has FK-Ising distribution, the fact that the sign of on its connected components is distributed independently and uniformly in can be seen either as a consequence of Proposition  , or from Theorem  .  Given on the discrete graph , we introduce in Definition   as the random set of edges which has the distribution of conditionally on .    We let be a random set of edges which has the distribution of conditionally on given by Lemma  .">
  </outline>
  <outline text="Distribution of  conditionally on" _note="The distribution of conditionally on can be retrieved by Corollary 3.6 in , which reads as follows.    Conditionally on , the events , , are independent and have probability  This result gives rise, together with Theorem  , to the following discrete version of Lupu’s isomorphism, which is stated without any recourse to the cable graph induced by .    Let be a percolation defined as follows: conditionally on , the random variables are independent, and equals with conditional probability given by .  Let the set of edges:    Given a loop soup , let be as in Definition  . Let be random spins taking constant values on clusters induced by ( if ) and such that the values on each cluster, conditional on and , are independent and uniformly distributed. Then is a Gaussian free field distributed according to .  Proposition   induces the following coupling between FK-Ising and random currents.  If is finite, a RANDOM CURRENT MODEL on with weights is a random assignment to each edge of a non-negative integer such that for all , is even, which is called the PARITY CONDITION. The probability of a configuration satisfying the parity condition is where actually . Let The open edges in induce clusters on the graph .  Given a loop soup , we denote by the number of times the loops in cross the nonoriented edge . The transience of the Markov jump process implies that is a.s. finite for all . If , we have the following identity (see for instance ):  Assume is finite and consider the loop soup . Conditionally on the occupation field , is distributed as a random current model with weights . If is the GFF on given by Le Jan’s or Lupu’s isomorphism, then these weights are .  Conditionally on the occupation field , are the edges occupied by a random current and the edges occupied by FK-Ising. Lemma   and Proposition   imply the following coupling, as noted by Lupu and Werner in .    Assume is finite. Let be a random current on with weights . Let be an independent percolation, each edge being opened (value ) independently with probability . Then is distributed like the open edges in an FK-Ising with weights .">
  </outline>
  <outline text="Generalized second Ray-Knight “version” of Lupu’s isomorphism" _note="We are now in a position to state the coupled version of the second Ray-Knight theorem.    Let . Let with distribution , and define as in Definition  . Let be an independent Markov jump process started from .  Fix . If , we let be the random subset of which contains , the edges used by the path , and additional edges opened conditionally independently with probability We let be random spins sampled uniformly independently on each cluster induced by , pinned at , i.e. , and define  Then, conditionally on , has distribution , and has distribution conditionally on .  One consequence of that coupling is that the path stays in the positive connected component of for . This yields a coupling between the range of the Markov chain and the sign component of inside a GFF .  [PROOF OF THEOREM  : ]{} The proof is based on . Let , and let be the loop soup of intensity on the cable graph , which we decompose into (resp. ) the loop soup hitting (resp. not hitting) , which are independent. We let and (resp. ) be the prints of these loop soups on (resp. on ). We condition on .  Theorem   implies (recall also Definition  ) that we can couple with so that for all , and .  Define from by, for all , and , where are random spins sampled uniformly independently on each cluster induced by , pinned at , i.e. . Then, by Theorem  , has distribution .  For all , we have  On the other hand, conditionally on , where we use in the third equality that the event is measurable with respect to the -field generated by , which is independent of , and where we use Lemma   in the fourth equality, for and for .  We conclude the proof by observing that conditionally on has the law of the occupation field of the Markov chain under . []{}">
  </outline>
</outline>
<outline text="Inversion of the signed isomorphism" _note="In , Sabot and Tarrès give a new proof of the generalized second Ray-Knight theorem together with a construction that inverts the coupling between the square of a GFF conditioned by its value at a vertex and the excursions of the jump process from and to . In this paper we are interested in inverting the coupling of Theorem   with the signed GFF : more precisely, we want to describe the law of conditionally on .  We present in section   an inversion involving an extra Poisson process. We provide in Section   a discrete-time description of the process and in Section   an alternative description via jump rates. Sections   and   are respectively dedicated to a signed inversion of Le Jan’s isomorphism for loop soups, and to an inversion of the coupling of random current with FK-Ising.">
  <outline text="A description via an extra Poisson point process" _note="Let be a real function on such that for some . Set We define a self-interacting process living on as follows. The process starts at . For , we set where is the local time of the process up to time . Let be an independent Poisson Point Processes on with intensity 1, for each edge . We set We also denote by the configuration of edges such that . As time increases, the interaction parameters decreases for the edges neighboring , and at some random times may drop by 1. The process is defined as the process that jumps only at the times when one of the drops by 1, as follows:  if decreases by 1 at time , but does not create a new cluster in , then crosses the edge with probability or does not move with probability ,  if decreases by 1 at time , and does create a new cluster in , then moves/or stays with probability 1 on the unique extremity of which is in the cluster of the origin in the new configuration.  We set clearly, the process is well-defined up to time .  For all , is in the connected component of of the configuration . If is finite, the process ends at , i.e. .    Assume that is finite. With the notation of Theorem  , conditioned on , has the law of .  Moreover, conditioned on , has the law of where are random spins sampled uniformly independently on each cluster induced by , with the condition that . If is infinite, then -a.s., (with the initial condition ) ends at , i.e. and . All previous conclusions for the finite case still hold.">
  </outline>
  <outline text="Discrete time description of the process" _note="We give a discrete time description of the process that appears in the previous section. Let and be the stopping times when one of the stacks decreases by , where is the time when one of the stacks is completely depleted. It is elementary to check the following:    The discrete time process is a stopped Markov process. The transition from time to is the following:  first chose an edge adjacent to the vertex according to a probability proportional to ,  decrease the stack by 1,  if decreasing by 1 does not create a new cluster in , then crosses the edge with probability or does not move with probability ,  if decreasing by 1 does create a new cluster in , then moves/or stays with probability 1 on the unique extremity of which is in the cluster of the origin in the new configuration.">
  </outline>
  <outline text="An alternative description via jump rates" _note="We provide an alternative description of the process that appears in Section  .    The process defined in section   can be alternatively described by its jump rates : conditionally on its past at time , if , and , then   jumps to without modification of at rate  the edge is closed in at rate and, conditionally on that last event:  - if is connected to in the configuration , then simultaneously jumps to with probability and stays at with probability  - otherwise moves/or stays with probability 1 on the unique extremity of which is in the cluster of the origin in the new configuration.  It is clear from this description that the joint process is Markov process, and well defined up to the time  One can also retrieve the process in Section   from the representation in Proposition   as follows. Consider the representation of Proposition   on the graph where each edge is replaced by a large number of parallel edges with conductance . Consider now the number of parallel edges that are open in the configuration between and . Then, when , , converges in law to , defined in section  .  [PROOF OF PROPOSITION  : ]{} Assume , fix and let . Recall that iff .  Let us first prove (1): Similarly, (2) follows from the following computation: []{}  We easily deduce from the Proposition   and Theorem   the following alternative inversion of the coupling in Theorem  .    With the notation of Theorem  , conditionally on , has the law of self-interacting process defined by jump rates of Proposition   starting with Moreover has the same law as where is a configuration of signs obtained by picking a sign at random independently on each connected component of , with the condition that the component of has a + sign.">
  </outline>
  <outline text="A signed version of Le Jan’s isomorphism for loop soup" _note="Let us first recall how the loops in are connected to the excursions of the jump process .    Let and . is distributed according to a Gamma law, where is the Green’s function. Let , and consider the path conditioned on . Let be an independent Poisson-Dirichlet partition of . Let and Let Consider the family of paths It is a countable family of loops rooted in . It has the same law as the family of all the loops in that visit , conditioned on .  Next we describe how to invert the discrete version fo Lupu’s isomorphism Proposition   for the loop-soup in the same way as in Theorem  .  Let be a real function on such that for some . Set  Let be an enumeration of (which may be infinite). We define by induction the self interacting processes . will denote the end-time for , and . By definition, . will denote where are the occupation times for . For , we set The end-times are defined by inductions as Let be independent Poisson Point Processes on with intensity 1, for each edge . We set We also denote by the configuration of edges such that . starts at . For ,  if decreases by 1 at time , but does not create a new cluster in , then crosses the edge with probability or does not move with probability ,  if decreases by 1 at time , and does create a new cluster in , then moves/or stays with probability 1 on the unique extremity of which is in the cluster of the origin in the new configuration.  By induction, using Theorem  , we deduce the following:    Let be a GFF on with the law . If one sets in the preceding construction, then for all , , and the path has the same law as a concatenation in of all the loops in a loop-soup that visit , but none of the . To retrieve the loops out of each path , on has to partition it according to a Poisson-Dirichlet partition as in Proposition  . The coupling between the GFF and the loop-soup obtained from is the same as in Proposition  .">
  </outline>
  <outline text="Inverting the coupling of random current with FK-Ising" _note="By combining Theorem   and the discrete time description of Section  , and by conditionning on the occupation field of the loop-soup, one deduces an inversion of the coupling of Proposition   between the random current and FK-Ising.  We consider that the graph and that the edges are endowed with weights . Let be an enumeration of . Let be a subset of open edges of . Let be a family of random integers such that if , and are independent Poisson random variables, where .  We will consider a family of discrete time self-interacting processes . starts at at and is defined up to a integer time . Let , with . The end-times are defined by induction as For , will denote which is consistent with the notation .  The evolution is the following. For , the transition from time to time is the following:  first chose an edge adjacent to the vertex with probability proportional to ,  decrease the stack by 1,  if decreasing by 1 does not create a new cluster in , then crosses with probability and does not move with probability .  if decreasing by 1 does create a new cluster in , then moves/or stays with probability 1 on the unique extremity of which is in the cluster of the origin in the new configuration.  Denote the number of times the edge has been crossed, in both directions, by all the walks .  A.s., for all , and . If the initial configuration of open edges is random and follows an FK-Ising distribution with weights , then the family of integers is distributed like a random current with weights . Moreover, the coupling between the random current and the FK-Ising obtained this way is the same as the one given by Proposition  .">
  </outline>
</outline>
<outline text="Proof of theorem [thm-Poisson]">
  <outline text="Case of finite graph without killing measure" _note="Here we will assume that is finite and that the killing measure .  In order to prove Theorem  , we first enlarge the state space of the process . We define a process living on the space as follows. Let be a GFF pinned at . Let be the signs of the GFF with the convention that . The process is as usual the Markov Jump process starting at with jump rates . We set The initial values are choosen independently on each edge with distribution where is a Poisson random variable with parameter . Let be independent Poisson point processes on with intensity 1. We define the process by where is the number of crossings of the edge by the Markov jump process before time .  Note that compared to the process defined in Section  , the speed of the Poisson process is related to and not .  We will use the following notation Recall that for . To simplify notation, we will write for in the sequel. We define by where are random spins sampled uniformly independently on each cluster induced by with the condition that .    The random vector thus defined has the same distribution as defined in Theorem  .  It is clear from construction, that has the same law as (cf Definition  ), the FK-Ising configuration coupled with the signs of as in Proposition  . Indeed, for each edge such that , the probability that is . Moreover, conditionally on , has the same law as defined in Theorem  . Indeed, is the union of the set , the set of edges crossed by the process , and the additional edges such that . Clearly independently with probability which coincides with the probability given in Theorem  .  We will prove the following theorem that, together with Lemma  , contains the statements of both Theorem   and  .    The random vector is a GFF distributed according to . Moreover, conditionally on , the process has the law of the process described in section  .  [**Step 1 :**]{} We start by a simple lemma.    The distribution of is given by the following formula for any bounded measurable test function where the integral is on the set and and is the number of clusters induced by the edges such that .  Indeed, by construction, summing on possible signs of , we have where the first sum is on the set and the second sum is on the set of (we write to mean that vanishes on the edges such that ). Since we deduce that the integrand in ( ) is equal to where we used in the first equality that on the edges such that . Thus, Inverting the sum on and and summing on the number of possible signs which are constant on clusters induced by the configuration of edges , we deduce Lemma  .  [**Step 2 :**]{} We denote by the process defined previously and by its law with initial condition .  We now introduce a process , which is a “time reversal” of the process . This process will be related to the process defined in section   in Step 4, Lemma  .  For and such that we define the process with values in as follows. The process is a Markov jump process with jump rates (so that ), and , are defined by where is the local time of the process up to time , where are independent Poisson point process on with intensity 1 for each edge , and is the number of crossings of the edge by the process before time . We set This process is well-defined up to time We denote by its law. Clearly is a Markov process, we will later on make explicit its generator.  We have the following change of variable lemma.    For all bounded measurable test functions where the integral on the l.h.s. is on the set with and the integral on the r.h.s. is on the set with  We start from the left-hand side, i.e. the process, . We define and (The law of the processes such defined will later be identified with the law of the processes ( defined at the beginning of step 2, cf ( ) and ( )). We also set which is also the number of crossings of the edge by the process , between time 0 and . With these notations we clearly have where is the local time of at time , and By time reversal, the law of is the same as the law of the Markov Jump process , where . Hence, we see that up to the time , the process has the same law as the process defined at the beginning of step 2.  Then, following , we make the following change of variables conditionally on the processes which is bijective onto the set (Note that we always have .) The last conditions on and are equivalent to the conditions and . The Jacobian of the change of variable is given by  [**Step 3:**]{} With the notations of Theorem  , we consider the following expectation for and bounded measurable test functions By definition, we have where are random signs sampled uniformly independently on clusters induced by and conditioned on the fact that . Hence, we define for and where means that the signs are constant on clusters of and such that . Hence, setting using lemma   in the first equality and lemma   in the second equality, we deduce that ( ) is equal to with notations of Lemma  . Let be the filtration generated by . We define the -adapted process , defined up to time by where denotes the cluster of the origin induced by the configuration . Note that at time , we also have since vanishes on the event where , with . Indeed, if , then and for such that . It means that is equal to 0 if for some edge neighboring . Thus, is null unless is a cluster in . Hence, if since contains the indicator of the event that and are in the same cluster.  Hence, using identities ( ) and ( ) we deduce that ( ) is equal to  [**Step 4 :**]{} We denote by the process defined in section  , which is well defined up to stopping time , and . We denote by the law of the process conditionnally on the initial value , i.e. conditionally on . The last step of the proof goes through the following lemma.    i) Under , ends at a.s. and for all .  ii\) Let and be the law of the process and , then   Using this lemma we obtain that in the right-hand side of ( ) Hence, we deduce, using formula ( ) and proceeding as in lemma  , that ( ) is equal to where the last integral is on the set , , and where means that and if . Finally, we conclude that where in the right-hand side is a GFF and is the process defined in section   from the GFF . This exactly means that and that This concludes the proof of Theorem  .  The generator of the process defined in ( ) is given, for any bounded and for the second component test function , by where is the value obtained by removing 1 from at edge . Indeed, since , we have which is explains the first term in the expression. The second term is obvious from the definition of , and corresponding to the term induced by jumps of the Markov process . The last term corresponds to the decrease of due to the increase in the process . Indeed, on the interval , the probability that is equal to 1 is of order using identity ( ).  Let be the generator of the Markov jump process . We have that the generator is equal, for any smooth test function , to where correspond to the following disjoint events   if the numbers of connected clusters induced by is the same as that of .   if a new cluster is created in compared with and if is in the connected component of in the cluster induced by .   if a new cluster is created in compared with and if is in the connected component of in the cluster induced by .  Indeed, conditionally on the value of at time , the point process on the interval has the law of independent points with uniform distribution on . Hence, the probability that a point lies in the interval is of order We define the function so that To prove the lemma it is sufficient to prove (, Chapter 11) that for any bounded smooth test function Let us first consider the first term in ( ). Direct computation gives For the second part, remark that the indicators and imply that vanishes if or if . By inspection of the expression of , we obtain for , Similarly, for , Combining these three identities with the expression ( ) we deduce It exactly coincides with the expression for since .">
  </outline>
  <outline text="General case" _note="  The conclusion of Theorem   still holds if the graph is finite and the killing measure is non-zero ().  Let be the function on defined as By definition . Moreover, for all , Define the conductances , and the corresponding jump process , and the GFF and with conditions respectively at . The Theorem   holds for the graph with conductances and with zero killing measure. But the process has the same law as the process , conditioned on , after the change of time This means in particular that for the occupation times, Moreover, we have the equalities in law Indeed, at the level of energy functions, we have: where means that this term does not depend of once the value of the function at fixed.  Let be the inverse process for the conductances and the initial condition for the field , given by Theorem  . By applying the time change   to the process , we obtain an inverse process for the conductances and the field .    Assume that the graph is infinite. The killing measure may be non-zero. Then the conclusion of Theorem   holds.  Consider an increasing sequence of connected sub-graphs of which converges to the whole graph. We assume that contains . Let be the graph obtained by adding to an abstract vertex , and for every edge , where and , adding an edge , with the equality of conductances . will denote the Markov jump process on , started from . Let be the first hitting time of or the first killing time by the measure . Let , will denote the GFFs on with condition respectively at , with condition at , and taking in account the possible killing measure . The limits in law of respectively are respectively .  We consider the process be the inverse process on , with initial field . , conditional on , has the same law as . Taking the limit in law as tends to infinity, we conclude that , conditional on , has the same law as on the infinite graph . The same for the clusters. In particular, where in the first two probabilities we also average by the values of the free fields. Hence">
  </outline>
</outline>
<outline text="Acknowledgements" _note="TL acknowledges the support of Dr. Max Rössler, the Walter Haefner Foundation and the ETH Zurich Foundation.">
</outline>
  </body>
</opml>