<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <abstract> </abstract>
  </head>
  <body>
<outline text="The Single Source Shortest Path problem" _note="In Section   we argued that an efficient multisplit primitive would have helped Davidson et al.  in their delta-stepping formulation of the Single Source Shortest Path (SSSP) problem on the GPU. In this section, we show that by using our multisplit implementation, we can achieve significant speedups in SSSP computation, especially on highly connected graphs with low diameters.">
  <outline text="The Single Source Shortest Path (SSSP) problem" _note="Given an arbitrary graph , with non-negative weights assigned to each edge and a source vertex , the SSSP problem finds the minimum cost path from the source to every other vertex in the graph. As described in Section  , Dijkstra’s  and Bellman-Ford-Moore’s  algorithms are two classical approaches to solve the SSSP problem. In the former, vertices are organized in a single priority queue and are processed sequentially from the lowest to the highest weight. In the latter, for each vertex we process all its neighbors (i.e., processing all edges). This can be done in parallel and is repeated over multiple iterations until convergence. Dijkstra is highly work-efficient but essentially sequential and thus unsuitable for parallelization. Bellman-Ford-Moore is trivially parallel but does much more work than necessary (especially for highly connected graphs).  As an alternative algorithm between these two extremes (sequential processing of all vertices vs. processing all edges in parallel), delta-stepping allows the selective processing of a subset of vertices in parallel . In this formulation, nodes are put into different buckets (based on their assigned weights) and buckets with smaller weights are processed first. Davidson et al.  proposed multiple GPU implementations based on the delta-stepping formulation. Their two most prominent implementations were based on a NEAR-FAR strategy and a BUCKETING strategy. Both divide vertices into multiple buckets, which can be processed in parallel. Both use efficient load-balancing strategies to traverse all vertices within a bucket. Both iterate over multiple rounds of processing until convergence is reached. The main difference between the two is in the way they organize the vertices to be processed next (work frontiers):  Near-Far strategy  :   In this strategy the work queue is prioritized based on a variable     splitting distance. In every iteration, only those vertices less     than this threshold (the NEAR SET) are processed. Those falling     beyond the threshold are appended to a FAR PILE. Elements in the far     pile are ignored until work in the near set is completely exhausted.     When all work in the near set is exhausted (this could be after     multiple relaxation phases), this strategy increases the splitting     distance (by adding an incremental weight to it) and removes invalid     elements from the far pile (those which have been updated with     similar distances), finally splitting this resulting set into a new     near set and far pile. This process continues until both the near     set and far pile are empty (the convergence criterion).  Bucketing strategy  :   In this strategy, vertices are partitioned into various buckets     based on their weights (Davidson et al. reported the best     performance resulted from 10 buckets). This strategy does a more     fine-grained classification of vertices compared to Near-Far,     resulting in a greater potential reduction in work queue size and     hence less work necessary to converge. The downside, however, is the     more complicated bucketing process, which due to lack of an     efficient multisplit primitive was replaced by a regular radix sort     in the original work. As a result of this expensive radix sort     overhead, Near-Far was more efficient in practice .  ">
  </outline>
  <outline text="Multisplit-SSSP" _note="Now that we have implemented an efficient multisplit GPU primitive in this paper, we can use it in the Bucketing strategy explained above to replace the costly radix sort operation. We call this new Bucketing implementation MULTISPLIT-SSSP. Our Multisplit-SSSP should particularly perform well on highly connected graphs with relatively large out degrees and smaller diameters (such as in social graphs), causing fewer iterations and featuring large enough work fronts to make multisplit particularly useful. However, graphs with low average degrees and large diameters (such as in road networks) require more iterations over smaller work frontiers, resulting in high kernel launch overheads (because of repetitive multisplit usage) without large enough work frontiers to benefit from the efficiency of our multisplit. We note that this behavior for different graph types is not limited to our SSSP implementation; GPU graph analytics in general demonstrate their best performance on highly connected graphs with low diameters .">
  </outline>
  <outline text="Performance Evaluation" _note="In this part, we quantitatively evaluate the performance of our new Multisplit-SSSP compared to Davidson et al.’s Bucketing and Near-Far approaches. Here, we choose a set of graph datasets listed in Table  .[^1] For those graphs that are not weighted, we randomly assign a non-negative integer weight between 0 and 1000 to each edge.  Table   shows the convergence time for Near-Far, Bucketing, and Multisplit-SSSP (in million traversed edges per second, MTEPS), with Multisplit-SSSP’s speedup against Near-Far. Multisplit-SSSP is always better than Bucketing, on both devices and on every graph we tested (up to 9.8x faster on Tesla K40c and 9.1x faster on the GeForce GTX 1080). This behavior was expected because of the performance superiority of our multisplit compared to a regular radix-sort (Fig.  ).  Against Near-Far, our performance gain depends on the type of graph. As we expected, on highly connected graphs with low diameters (such as rmat), we achieve up to 1.58x and 2.17x speedup against Near-Far, on the Tesla K40c and GeForce GTX 1080 respectively. However, for high diameter graphs such as road networks (e.g., belgium\_osm), we are closer to Near-Far’s performance: Multisplit-SSSP is slower than Near-Far on Tesla K40c (0.93x) and marginally faster on GeForce GTX 1080 (1.04x). Road graphs have significantly higher diameter and hence more iterations. As a result, the extra overhead in each phase of Multisplit-SSSP on large diameters can become more important than the saved operations due to fewer edge re-relaxations.  [^1]: All matrices except for rmat are downloaded from University of     Florida Sparse Matrix Collection . Rmat was generated with     parameters .">
  </outline>
</outline>
  </body>
</opml>