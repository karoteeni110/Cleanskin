\section{Related Work}\label{sec:related}

Anomalous link quality degradation is 
%Detection of anomalous link quality degradation is crucial to maintain the performance of deployed networks as link quality degradation is 
%often reported as 
a major cause of high packet losses in WSNs, reported by previous deployments \cite{6850017, 4408504, 6661323, 1182885}. Among various link quality metrics \cite{2240123}, RSSI provides direct channel quality information at the receiver, which is typically a required input for remedy systems in order to tune stack parameters such as transmission power \cite{Lin:atpc} or other layer parameters \cite{2185730,7164923}. Many studies \cite{levis2006rssi, 7164923} analyzed the relation between RSSI and packet loss and studied the temporal properties of RSSI \cite{2893729}. Only very few works have investigated how to use RSSI readings to detect good links (with low packet losses) turning into weak links (with high packet losses) with \textit{optimal} performance, i.e., \textit{robust detection with minimal detection error}. Our work is related to previous research on two topics: (1) network monitoring approaches for detecting link-related failures, and (2) anomaly detection techniques developed for WSNs. 

Existing approaches of network monitoring and diagnosis generally rely on active collection of node and network status. Some of them are centralized approaches, e.g., Sympathy \cite{1367278} and Emstar \cite{1267061}, in which a large amount of status information from individual sensor nodes (e.g., packet counter) is delivered to the sink to determine the failure causes. Agnostic Diagnosis \cite{6661323} constructs correlation graphs at the back-end server from collected system metrics to detect link failures. Other approaches, e.g., self-diagnosis \cite{6850017}, avoid sending all information to the sink by encouraging multiple sensor nodes to exchange information for cooperative failure detection. All these systems are powerful at detecting various failure types. However, they introduce large communication overhead to energy-constrained WSNs. Besides, \textit{most of these systems use metrics like packet counter or retransmission counter}. Though such metrics enable easy detection of packet losses, they can hardly be used to determine the cause, e.g., whether a loss is due to bad channel condition or packet collision. Instead, RADIUS utilizes RSSI, a channel quality attribute resident within every received packet, which does not require active information collection, allowing fully distributed anomaly detection. 

The research on anomaly detection in wired and wireless ad hoc networks is quite mature, but only a few solutions can be directly applied to WSNs due to the limited memory and computational capability of sensor nodes. Data mining and computational intelligence-based techniques, such as clustering \cite{4085803}, support vector machine \cite{4289308} and neural networks \cite{4797294}, own strong detection generality and accuracy as long as adequate attributes are in use \cite{1988328}. However, they all come with high complexity. In addition, they often rely on a central entity to cope with heavy tasks. PAD \cite{5356174} deduces link level errors with a probabilistic inference model maintained at a server. Statistical techniques such as kernel density estimator also require high computational capability to generate the density estimator. A recent work of employing such techniques is RASID \cite{6199865}, implementing the system on more powerful devices (WiFi access points) to detect intruders. Due to the limited resources of sensor nodes, data mining or machine learning oriented approaches are normally infeasible for distributed anomaly detection systems in WSNs. 


The most widely used anomaly detection technique in WSNs is the statistical measure-based technique (e.g. mean, variance, maximum, self-defined) due to its low complexity and high effectiveness of finding detection boundaries (i.e. thresholds). For example, Fine-grained Analysis \cite{2517408} detects security attacks when RSSI changes exceed the measured maximum fluctuation occurred during the initial training phase. In the statistical measure category, there are two often used techniques: (1) \textit{CDF-based} thresholding (or percentile-based thresholding), and (2) \textit{Chebyshev inequality}-based thresholding. In CDF-based schemes, the threshold is defined as the \textit{x-th percentile} of the underlying data distribution of the monitored attribute. An example is the Memento system \cite{4068315} where an empirical CDF of consecutively missing heartbeat numbers is used to detect sensor failures. Another example is RASID \cite{6199865} which also defines a threshold at a given percentile after the density function is estimated. In other cases, when the underlying probability distribution of the monitored attribute is not known \textit{a priori}, the Chebyshev thresholding technique has often been applied. For instance, Chebyshev thresholding is used in \cite{1592596} to troubleshoot the network performance issues. 
%Memento \cite{4068315} uses an empirical CDF of consecutively missing heartbeat numbers to detect sensor failures. RASID \cite{6199865} also defines a threshold at a given percentile after the density function is estimated. In other cases, when the underlying probability distribution of the monitored attribute is not known \textit{a priori}, the Chebyshev thresholding technique is often applied\cite{4068315, 1592596, 1689248}. 
% The threshold for attribute \textit{m} by applying the Chebyshev's inequality is defined as follows. 
% \setlength{\belowdisplayskip}{3pt} \setlength{\belowdisplayshortskip}{3pt}
% \setlength{\abovedisplayskip}{3pt} \setlength{\abovedisplayshortskip}{3pt}
% \begin{equation}\label{equ:chebyTHD}
% T_{cheby} = \overline{m} +  \sigma_m \ast \sqrt{\frac{1-P_{target}}{P_{target}}}
% \end{equation}
% Where $P_{target}$ is a user-defined parameter for desired false positive rate.  
In \cite{1689248}, a fusion threshold bound is derived using the Chebyshev inequality for target detection in WSNs. %Giza \cite{1592596} applies one-side Chebyshev inequality to troubleshoot the performance issues in an IPTV network. 

Despite their low complexity and easy adaptation to WSNs, both CDF-based and Chebyshev inequality-based methods are not designed for optimizing detection accuracy. In addition, achieving robust performance in detection accuracy by them is also a challenge. Later in this paper, we show that employing these two methods to achieve best detection accuracy implicitly requires manual fine-tuning of the threshold parameters
%(Percentile or $P_{target}$) 
for each monitored link, which is difficult to do in practice. In RADIUS, we employ the Bayes decision theory \cite{melsa1978decision} to minimize the detection error, which is also a thresholding technique and has been widely used in other fields, e.g., signal detection and image analysis. Specifically, we apply the Bayesian thresholding technique to identify good links and weak links based on the monitored RSSI values. Its complexity is similar to that of the CDF or Chebyshev thresholding technique. Additionally, we combine the Bayesian thresholding technique with several supporting techniques to build a robust and accurate system for detecting anomalous link quality degradation in WSNs. %Under the assumption of Gaussian channels, 

