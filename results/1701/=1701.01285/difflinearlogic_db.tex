\documentclass[english,letter paper,12pt,reqno]{article}
\usepackage{etex} % to fix "no room for new dimen" error. Voodoo.
\usepackage{array}
\usepackage{varwidth}
\usepackage{bussproofs}
\usepackage{epigraph}
\usepackage{stmaryrd}
\usepackage{mathdots}
\usepackage{amsmath, amscd, amssymb, mathrsfs, accents, amsfonts,amsthm}
\usepackage[all]{xy}
\usepackage{mathtools} % for bra-ket
\usepackage{tikz}
\usetikzlibrary{calc}

\AtEndDocument{\bigskip{\footnotesize%
  James Clift \par
  \textsc{Department of Mathematics, University of Melbourne} \par
  \textit{E-mail address}: \texttt{j.clift3@student.unimelb.edu.au} \par
  \vspace{0.3cm}
  Daniel Murfet \par
  \textsc{Department of Mathematics, University of Melbourne} \par  
  \textit{E-mail address}: \texttt{d.murfet@unimelb.edu.au} \par
}}

% Labels in tabular
\newcommand{\tagarray}{\mbox{}\refstepcounter{equation}$(\theequation)$}

\newenvironment{mathprooftree}
  {\varwidth{.9\textwidth}\centering\leavevmode}
  {\DisplayProof\endvarwidth}
  
% Bra-ket stuff
\DeclarePairedDelimiter\bra{\langle}{\rvert}
\DeclarePairedDelimiter\ket{\lvert}{\rangle}
\DeclarePairedDelimiterX\braket[2]{\langle}{\rangle}{#1 \delimsize\vert #2}
\DeclarePairedDelimiterX\inner[2]{\langle}{\rangle}{#1,#2}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\DeclarePairedDelimiter\set{\lbrace}{\rbrace}

%\begin{align*}
%\bra{a}       &= \bra*{\frac{a}{1}}\    \ket{a}       &= \ket*{\frac{a}{1}}\    \braket{a}{b} &= \braket*{\frac{a}{1}}{\frac{b}{1}}\    %\inner{a}{b}  &= \inner*{\frac{a}{1}}{\frac{b}{1}}\    \abs{a}       &= \abs*{\frac{a}{1}}\    \norm{a}      &= \norm*{\frac{a}%{1}}\    \set{a,b}     &= \set*{\frac{a}{1},\frac{b}{1}}
%\end{align*}

% TikZ stuff
\def\drawbang{\draw[color=teal!50, line width=2pt]}
\def\drawprom{\draw[color=gray, line width=3pt]}
\def\bluenode{\node[circle,draw=blue!50,fill=blue!20]}
\def\mapnode{\node[circle,draw=black,fill=black,inner sep=0.5mm]}
\def\whitenode{\node[circle,draw=blue!50,fill=blue!5]}
\def\dernode{\node[circle,draw=black,fill=white]}
\definecolor{Myblue}{rgb}{0,0,0.6}
\usepackage[a4paper,colorlinks,citecolor=Myblue,linkcolor=Myblue,urlcolor=Myblue,pdfpagemode=None]{hyperref}

\SelectTips{cm}{}

\setlength{\evensidemargin}{0.1in}
\setlength{\oddsidemargin}{0.1in}
\setlength{\textwidth}{6.3in}
\setlength{\topmargin}{0.0in}
\setlength{\textheight}{8.5in}
\setlength{\headheight}{0in}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\newtheoremstyle{example}{\topsep}{\topsep}
	{}
	{}
	{\bfseries}
	{.}
	{2pt}
	{\thmname{#1}\thmnumber{ #2}\thmnote{ #3}}
	
	\theoremstyle{example}
	\newtheorem{definition}[theorem]{Definition}
	\newtheorem{example}[theorem]{Example}
	\newtheorem{remark}[theorem]{Remark}
	\newtheorem{question}[theorem]{Question}

%\numberwithin{equation}{section}

% Operators
\def\eval{\operatorname{ev}}
\def\sh{\operatorname{Sh}}
\def\res{\operatorname{Res}}
\def\Coker{\operatorname{Coker}}
\def\Ker{\operatorname{Ker}}
\def\im{\operatorname{Im}}
\def\can{\operatorname{can}}
\def\K{\mathbf{K}}
\def\D{\mathbf{D}}
\def\N{\mathbf{N}}
\def\LG{\mathcal{LG}}
\def\Ab{\operatorname{Ab}}
\def\Hom{\operatorname{Hom}}
\def\modd{\operatorname{mod}}
\def\Modd{\operatorname{Mod}}
\def\vacu{\ket{\emptyset}}
\def\be{\begin{equation}}
\def\ee{\end{equation}}
\DeclareMathOperator{\Ext}{Ext}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\tot}{Tot}
\DeclareMathOperator{\ch}{ch}
\DeclareMathOperator{\str}{str}
\DeclareMathOperator{\hmf}{hmf}
\DeclareMathOperator{\HMF}{HMF}
\DeclareMathOperator{\hf}{HF}
\DeclareMathOperator{\At}{At}
\DeclareMathOperator{\Cat}{Cat}
\DeclareMathOperator{\Spec}{Spec}
\DeclareMathOperator{\MSpec}{MSpec}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\LC}{LC}
\DeclareMathOperator{\ILL}{ILL}
\def\inta{\bold{int}}
\def\comp{\underline{\textup{comp}}}
\def\contract{\;\lrcorner\;}

% SCprooftree environment
\newenvironment{scprooftree}[1]
{\gdef\scalefactor{#1}\begin{center}\proofSkipAmount \leavevmode}
{\scalebox{\scalefactor}{\DisplayProof}\proofSkipAmount \end{center} }
  
\begin{document}

% Bussproof things
\def\ScoreOverhang{1pt}

% Commands
\def\Res{\res\!}
\newcommand{\ud}[1]{\operatorname{d}\!{#1}}
\newcommand{\Ress}[1]{\res_{#1}\!}
\newcommand{\cat}[1]{\mathcal{#1}}
\newcommand{\lto}{\longrightarrow}
\newcommand{\xlto}[1]{\stackrel{#1}\lto}
\newcommand{\mf}[1]{\mathfrak{#1}}
\newcommand{\md}[1]{\mathscr{#1}}
\newcommand{\church}[1]{\underline{#1}}
\newcommand{\prf}[1]{\underline{#1}}
\newcommand{\den}[1]{\llbracket #1 \rrbracket}
\def\l{\,|\,}
\def\sgn{\textup{sgn}}
\def\cont{\operatorname{cont}}
\def\counit{\varepsilon}
\def\inta{\textbf{int}}
\def\binta{\textbf{bint}}
\def\comp{\underline{\textup{comp}}}
\def\mult{\underline{\textup{mult}}}
\def\repeat{\underline{\textup{repeat}}}
\def\contract{\;\lrcorner\;}

\title{Cofree coalgebras and differential linear logic}
\author{James Clift, Daniel Murfet}

\maketitle

\begin{abstract} We prove that the semantics of intuitionistic linear logic in vector spaces which uses cofree coalgebras to model the exponential is a model of differential linear logic. Thus, in this semantics, proof denotations have natural derivatives. We give several examples of these derivatives.
\end{abstract}

\section{Introduction}

The idea of taking derivatives of programs is an old one \cite[\S 2]{paige} with many manifestations, including automatic differentiation of algorithms computing real-valued functions \cite{autodiff} and incremental computation \cite{incdiff}. However, these approaches are limited to restricted classes of computations, and it is only recently with the development of the differential $\lambda$-calculus by Ehrhard-Regnier \cite{difflambda} and its refinement differential linear logic \cite{blutecs, ehrhard-survey} that derivatives have been defined for general higher-order programs. As with ordinary calculus, the aim of these theories is to assign to a program $P$ another program $\partial P$ (the derivative) which computes the change in the output of $P$ resulting from an infinitesimal change to its input. Here we give ourselves arbitrary $\mathbb{C}$-linear combinations of programs (meaning $\lambda$-terms or proofs in linear logic) as a starting point so that ``small'' changes to the input make sense.

This paper is about the semantics of differential linear logic, following \cite{blutecs}. The aim is to explain how the natural semantics of intuitionistic linear logic in vector spaces \cite{hyland, murfet_ll} is already a model of differential linear logic. The key point is that tangent vectors and derivatives appear as soon as we introduce cofree coalgebras to model the exponential, which shows that the differential structure is intrinsic to the algebra of linear logic.

To see this, let $\den{-}$ denote semantics in vector spaces and suppose we are given a proof $\pi$ in linear logic computing a function from inputs of type $A$ to outputs of type $B$:
\[
\begin{mathprooftree}
\AxiomC{$\pi$}
\noLine\UnaryInfC{$\vdots$}
\def\extraVskip{5pt}
\noLine\UnaryInfC{${!} A \vdash B$\,.}
\end{mathprooftree}
\]
The space of inputs to $\den{\pi}$ is $\den{A}$, and a small change in the input starting from $P \in \den{A}$ is a tangent vector $\nu$ at $P$, viewing $\den{A}$ as a smooth manifold or a scheme. This is equivalent to the data of a linear map
\be
\xymatrix@C+2pc{
(\mathbb{C}[\varepsilon]/\varepsilon^2)^* \ar[r] & \den{A}
}
\ee
where $\mathbb{C}[\varepsilon]/\varepsilon^2$ is the ring of dual numbers (this bijection is reviewed in Appendix \ref{section:tangent_vectors}). If $\den{{!} A}$ is the universal cocommutative counital coalgebra mapping to $\den{A}$ then there is a unique lifting of this linear map to a morphism of coalgebras
\be\label{eq:toucan}
\xymatrix@C+2pc{
(\mathbb{C}[\varepsilon]/\varepsilon^2)^* \ar[r] & \den{{!} A}\,.
}
\ee
Similarly the linear map $\den{\pi}: \den{{!} A} \lto \den{B}$ lifts to a morphism of coalgebras $\den{{!} A} \lto \den{{!} B}$ which may be composed with \eqref{eq:toucan} to give a morphism of coalgebras
\be\label{eq:toucan2}
\xymatrix@C+2pc{
(\mathbb{C}[\varepsilon]/\varepsilon^2)^* \ar[r] & \den{{!} A} \ar[r] & \den{{!} B}
}
\ee
which, in turn, defines a tangent vector at the point $\den{\pi}\ket{\emptyset}_P \in \den{B}$, where $\ket{\emptyset}_P$ is the point of $\den{{!} A}$ corresponding to $P$. The tangent vector \eqref{eq:toucan2} gives the infinitesimal variation of the output of $\pi$ on the input $P$, when the input is varied in the direction of $\nu$.

The formal statement is that for any algebraically closed field $k$ of characteristic zero the semantics of intuitionistic linear logic in $k$-vector spaces defined using cofree coalgebras is model of differential linear logic (Theorem \ref{main_theorem}). We refer to this as the \emph{Sweedler semantics}, since the explicit description of this universal coalgebra is due to him  \cite{sweedler,murfet_ll}. The proof is elementary and we make no claim here to technical novelty; the link between the symmetric coalgebra and differential calculus is well-known. Perhaps our main contribution is to give several detailed examples showing how to compute these derivatives. We do this with the aim of reinforcing the fact that differentiating programs, even higher-order ones, is a natural thing to do.
\\
% Among the reasons that have been put forward for considering this extension are that it simplifies the resource $\lambda$-calculus \cite[\S 6]{diffnets}, the Taylor expansion of proofs is related to head normal form and Krivine's machine \cite{??}, and that it allows for the representation of concurrent and nondeterministic processes \cite{ehrhard-laurent}. 

We conclude this introduction with a sketch of one such example and a comparison of our work to other semantics of differential linear logic. To elaborate a little more on the notation: for any type $A$ of linear logic (which for us has only connectives $\otimes, \multimap, !$) there is a vector space $\den{A}$, and for any proof $\pi$ of $A \vdash B$ there is a linear map $\den{\pi}: \den{A} \lto \den{B}$. In particular every proof $\xi$ of type $A$ has a denotation $\den{\xi} \in \den{A}$, and the promotion of $\xi$ has for its denotation a vector $\ket{\emptyset}_{\den{\xi}} \in \den{!A}$, see \cite[\S 5.3]{murfet_ll}.

For any binary sequence $S \in \{0,1\}^*$ there is an encoding of $S$ as a proof $\underline{S}$ of type
\[
\textbf{bint}_A = {!}(A \multimap A) \multimap \big({!}(A \multimap A) \multimap (A \multimap A)\big)\,.
\]
Repetition of sequences can be encoded as a proof
\[
\begin{mathprooftree}
\AxiomC{$\prf{\mathrm{repeat}}$}
\noLine\UnaryInfC{$\vdots$}
\def\extraVskip{5pt}
\noLine\UnaryInfC{${!} \textbf{bint}_A \vdash \textbf{bint}_A$\,.}
\RightLabel{\scriptsize $\multimap R$}
\end{mathprooftree}
\]
The denotation is a linear map $\den{ {!}\textbf{bint}_A } \lto \den{ \textbf{bint}_A }$ sending $\ket{\emptyset}_{\den{\underline{S}}}$ to $\den{\underline{SS}}$. The derivative of $\prf{\mathrm{repeat}}$ according to the theory of differential linear logic is another a proof
\[
\begin{mathprooftree}
\AxiomC{$\partial\, \prf{\mathrm{repeat}}$}
\noLine\UnaryInfC{$\vdots$}
\def\extraVskip{5pt}
\noLine\UnaryInfC{${!} \textbf{bint}_A, \textbf{bint}_A \vdash \textbf{bint}_A$\,}
\RightLabel{\scriptsize $\multimap R$}
\end{mathprooftree}
\]
which can be derived from $\prf{\mathrm{repeat}}$ by new deduction rules called codereliction, cocontraction and coweakening (see Section \ref{section:coder}). We prove in Section \ref{section:bint} that the denotation of this derivative in the Sweedler semantics is the linear map
\begin{gather*}
\den{\partial\, \prf{\mathrm{repeat}}}: \den{ {!}\textbf{bint}_A } \otimes \den{ \textbf{bint}_A} \lto \den{ \textbf{bint}_A }\,,\\
\ket{\emptyset}_{\den{\underline{S}}} \otimes \den{\underline{T}} \longmapsto \den{\underline{ST}} + \den{\underline{TS}}
\end{gather*}
whose value on the tensor $\ket{\emptyset}_{\den{\underline{S}}} \otimes \den{\underline{T}}$ we interpret as the derivative of the repeat program at the sequence $S$ in the direction of the sequence $T$. This can be justified informally by the following calculation using an infinitesimal $\varepsilon$
\begin{align*}
(S + \varepsilon T)( S + \varepsilon T) = SS + \varepsilon( ST + TS ) + \varepsilon^2 TT,
\end{align*}
which says that varying the sequence infinitesimally from $S$ in the direction of $T$ causes a variation of the repetition in the direction of $ST + TS$. 
\\


The Sweedler semantics is far from the first semantics of differential linear logic: basic examples include the categories of sets and relations \cite[\S 2.5.1]{blutecs} and suplattices \cite[\S 2.5.2]{blutecs}. The motivating examples using topological spaces and differentiable functions are the K\"othe and finiteness space semantics of Ehrhard \cite{ehrhard-kothe, ehrhard-finiteness} and the semantics of Blute-Ehrhard-Tasson \cite{blutecon} based on the theory of convenient vector spaces \cite{frolicher}. These papers explain that the geometric ``avatar'' of the exponential connective of linear logic is the functor sending a space $X$ to the space of distributions on $X$ (for a precise statement, see Remark \ref{remark:distr}). This remarkable analogy between logic and geometry deserves further study. One obstacle is that it seems difficult to compute examples of denotations and their derivatives in the convenient vector space setting of \cite{blutecon}. For example the coproduct \cite[p.12]{blutecon} is defined by extension to a Mackey closure, and is rather implicit.

Conceptually the Sweedler semantics is similar to these examples in that the exponential is modelled by a space of distributions (with finite support) but it is purely algebraic and there are simple explicit formulas for all the structure maps. Moreover in the algebraic approach the differential structure emerges naturally from the exponential structure, rather than being ``baked in''. The downside is that the smoothness of proof denotations in our semantics is obscured; in particular, in the case $k = \mathbb{C}$ some extra work is required to see the relation between our differential structure and the derivatives in the usual sense.
\\

For background material on linear logic and its semantics see \cite{girard_llogic, girard_prooftypes, mellies}. The formal theory of coalgebras is simpler over algebraically closed fields, which explains why we use $k = \mathbb{C}$ in our examples, but this is not really important: one could work over $k = \mathbb{R}$ by taking $\mathbb{C}$-points into account in the explicit description of the cofree coalgebra.
\\

\emph{Acknowledgements.} Thanks to Kazushige Terui, who stimulated this project by asking if the cofree coalgebra gave a model of differential linear logic.

\section{Main Theorem}

Let $k$ be an algebraically closed field of characteristic zero and $\cat{V}$ the category of $k$-vector spaces. This is a model of intuitionistic linear logic, as observed in \cite[p.5]{hyland} and developed in detail in \cite{murfet_ll}. Our notation is as in \cite{murfet_coalg} and \cite[\S 5]{murfet_ll}, see Appendix \ref{section:background} for a review. 

For a vector space $V$ we denote by ${!} V$ the universal cocommutative counital coalgebra mapping to $V$, with $d: {!} V \lto V$ the universal map. The map $V \mapsto {!} V$ extends to a comonad on $\cat{V}$ with natural transformation $\delta: {!} \lto {!} {!}$. The coproduct and counit are respectively denoted $\Delta: {!} V \lto {!} V \otimes {!} V$ and $w: {!} V \lto k$. Given vector spaces $V,W$ we write $\sigma_{V,W}: V \otimes W \lto W \otimes V$ for the swap map $\sigma_{V,W}(x \otimes y) = y \otimes x$.

By \cite[Proposition 2.6]{blutecs} to equip $\cat{V}$ with the coalgebra modality $({!}, \delta, d, \Delta, w)$ as a differential category, we need to define a deriving transformation \cite[Definition 2.5]{blutecs}. 

\begin{definition} A \emph{deriving transformation} for $(\cat{V}, {!}, \delta, d, \Delta, w)$ is a family of morphisms
\[
D_V: {!} V \otimes V \lto {!} V
\]
natural in $V$, satisfying the following properties for all $V$:
\begin{itemize}
\item[(D.1)] $w \circ D = 0$, that is,
\be
\xymatrix@C+2pc{
V \otimes {!} V \ar[r]^-{D} & {!} V \ar[r]^-{w} & k
} = 0\,.
\ee
\item[(D.2)] $\Delta \circ D = (1 \otimes D) \circ (\Delta \otimes 1) + (D \otimes 1) \circ (1 \otimes \sigma) \circ (\Delta \otimes 1)$, that is,
\be
\xymatrix@C+2pc{
{!} V \otimes V \ar[r]^-{D} & {!} V \ar[r]^-{\Delta} & {!} V \otimes {!} V
}
\ee
is equal to the sum
\begin{gather*}
\xymatrix@C+2pc{{!} V \otimes V \ar[r]^-{\Delta \otimes 1} & {!} V \otimes {!} V \otimes V \ar[r]^-{1 \otimes D} & {!} V \otimes {!} V} \quad +\\
\xymatrix@C+2pc{{!} V \otimes V \ar[r]^-{\Delta \otimes 1} & {!} V \otimes {!} V \otimes V \ar[r]^-{1 \otimes \sigma_{{!}V, V}}_{\cong} & {!} V \otimes V \otimes {!} V \ar[r]^-{D \otimes 1} & {!} V \otimes {!} V}
\end{gather*}
\item[(D.3)] $d \circ D = a \circ (w \otimes 1)$, that is,
\be
\xymatrix@C+2pc{
{!} V \otimes V \ar[r]^-{D} & {!} V \ar[r]^-{d} & V 
}
\quad = \quad
\xymatrix@C+2pc{
{!} V \otimes V \ar[r]^-{w \otimes 1} & k \otimes V \ar[r]^-{a}_-{\cong} & V
}
\ee
where $a(\lambda \otimes x) = \lambda x$.
\item[(D.4)] $\delta \circ D = D_{{!} V} \circ (\delta \otimes D) \circ (\Delta \otimes 1)$, that is,
\be
\xymatrix@C+2pc{
{!} V \otimes V \ar[r]^-{D} & {!} V \ar[r]^-{\delta} & {!}{!} V
}
\ee
is equal to
\be\label{eq:D4final}
\xymatrix@C+2pc{
{!} V \otimes V \ar[r]^-{\Delta \otimes 1} & {!} V \otimes {!} V \otimes V \ar[r]^-{\delta \otimes D} & {!}{!} V \otimes {!} V \ar[r]^-{D_{{!}V}} & {!}{!} V\,.
}
\ee
\end{itemize}
\end{definition}

We refer to \cite[\S 2.2]{blutecs} for an explanation of these axioms. Briefly, (D.1) says the derivative of constant maps is zero, (D.2) is the product rule, (D.3) says the derivative of a linear map is constant, and (D.4) is the chain rule. Clearly the rules specify how to commute $D$ past the structural maps $\delta, d, \Delta, w$. Here $d$ stands for the dereliction rule in linear logic, $\Delta$ for contraction and $w$ for weakening. The map $\delta$ stands for promotion, since for a linear map $\phi: {!} V \lto W$ the unique lifting to a morphism of coalgebras $\Phi: {!} V \lto {!} W$ can be obtained as the composite
\be
\xymatrix@C+2pc{
{!} V \ar[r]^-{\delta} & {!!} V \ar[r]^-{{!} \phi} & {!} W\,.
}
\ee

\begin{definition}\label{defn:D} We define the $k$-linear map $D_V: {!} V \otimes V \lto V$ by
\be\label{defn:DV}
D_V\big( \ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \big) = \ket{ \nu, \nu_1,\ldots,\nu_s }_P\,.
\ee
\end{definition}

See Remark \ref{remark:justify} for a justification of this definition from the point of view of \cite{murfet_coalg}.

\begin{theorem}\label{main_theorem} $D_V$ is a deriving transformation for any vector space $V$.
\end{theorem}

We split the proof into a series of lemmas. We prefer to give the proofs without first choosing a basis of $V$, but if one is willing to do so, then the connection between these identities and the usual rules of calculus follows from writing the formula for the coproduct $\Delta$ as a kind of Taylor expansion; see for example \cite[(B.65)]{seiler}.

\begin{lemma} (D.1) holds for $V$.
\end{lemma}
\begin{proof}
This is clear, since the counit $w: {!} V \lto V$ vanishes on $\ket{\omega_1,\ldots,\omega_t}_P$ if $t > 0$.
\end{proof}

\begin{lemma} (D.2) holds for $V$.
\end{lemma}
\begin{proof}
Setting $\nu_0 = \nu$ we have
\begin{align*}
\Delta D \big( \ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \big) &= \Delta \ket{\nu, \nu_1, \ldots, \nu_s }_P\\
&= \sum_{I \subseteq \{0,1,\ldots,s\}} \ket{\nu_I}_P \otimes \ket{\nu_{I^c}}_P\\
&= \sum_{0 \in I} \ket{\nu_I}_P \otimes \ket{\nu_{I^c}}_P + \sum_{0 \notin I} \ket{\nu_I}_P \otimes \ket{\nu_{I^c}}_P \\
&= \sum_{J \subseteq \{1,\ldots,s\}}\ket{\nu, \nu_J}_P \otimes \ket{\nu_{J^c}}_P + \sum_{J \subseteq \{1,\ldots,s\}} \ket{\nu_J}_P \otimes \ket{\nu, \nu_{J^c}}_P \\
&= \sum_{J \subseteq \{1,\ldots,s\}} \Big\{ D\big( \ket{\nu_J}_P \otimes \nu \big) \otimes \ket{\nu_{J^c}}_P + \ket{\nu_J}_P \otimes D\big( \ket{\nu_{J^c}}_P \otimes \nu \big) \Big\}
\end{align*}
as claimed, where for $I \subseteq \{0,1,\ldots,s\}$ we write $I^c$ for $\{0,\ldots,s\} \setminus I$ and for $J \subseteq \{1,\ldots,s\}$, we write $J^c$ for $\{1,\ldots,s\} \setminus J$.
\end{proof}

\begin{lemma} (D.3) holds for $V$.
\end{lemma}
\begin{proof}
We have
\[
d D\big( \ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \big) = d\ket{\nu,\nu_1,\ldots,\nu_s}_P = \delta_{s=0} \nu
\]
while
\[
a( w \otimes 1 )\big( \ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \big) = w\ket{\nu_1,\ldots,\nu_s}_P \cdot \nu = \delta_{s=0} \nu\,.
\]
\end{proof}

\begin{lemma} (D.4) holds for $V$.
\end{lemma}
\begin{proof}
The trivial case is, with $Q = \ket{\emptyset}_P$,
\[
\delta D( \ket{\emptyset}_P \otimes \nu ) = \delta\ket{\nu}_P = \big|\, \ket{\nu}_P \big\rangle_Q
\]
and on the other side
\begin{align*}
D_{{!} V}( \delta \otimes D )( \Delta \otimes 1)( \ket{\emptyset}_P \otimes \nu ) &= D_{{!} V}( \delta \otimes D)( \ket{\emptyset}_P \otimes \ket{\emptyset}_P \otimes \nu )\\
&= D_{{!} V}( \ket{\emptyset}_Q \otimes \ket{\nu}_P )\\
&= \big|\, \ket{\nu}_P \big\rangle_Q\,.
\end{align*}
Now we consider the case $s > 0$. Putting $\nu_0 = \nu$ and writing $\cat{P}_T$ for the set of partitions of $T$ we have
\[
\delta D\big(  \ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \big) = \sum_{X \in \cat{P}_{\{0,1,\ldots,s\}}} \Big| \otimes_{x \in X} \ket{\nu_{x}}_P \Big\rangle_Q
\]
where for a partition $X = \{ x_1,\ldots,x_t \}$ the notation means
\[
\Big| \otimes_{x \in X} \ket{\nu_{x}}_P \Big\rangle_Q = \Big|\, \ket{\nu_{x_1}}_P, \ldots, \ket{\nu_{x_t}}_P \Big\rangle_Q\,. 
\]
See Appendix \ref{section:background} for the definition of $\ket{\nu_x}$ when $x$ is a set. There is a surjective function
\begin{gather*}
\theta: \cat{P}_{\{0,1,\ldots,s\}} \lto \cat{P}_{\{1,\ldots,s\}}\\
\theta( X ) = \big\{ x \setminus \{0\} \l x \in X \text{ and } x \neq \{0\} \big\}
\end{gather*}
and given a partition $X = \{ x_1,\ldots,x_t \}$ of $\{1,\ldots,s\}$,
\begin{align*}
\theta^{-1}(X) &= \Big\{ \{ x_1 \cup \{0\}, x_2, \ldots, x_t \},\\
&\quad\{ x_1, x_2 \cup \{0\}, \ldots, x_t \},\\
&\quad\ldots,\\
&\quad\{ x_1, x_2, \ldots, x_{t-1}, x_t \cup \{0\} \}\\
&\quad\{ x_1, x_2, \ldots, x_t, \{0\} \} \Big\}\,.
\end{align*}
With this in mind we have, writing $\otimes_{x' \neq x} \ket{\nu_{x'}}_P$ for the list of $\ket{\nu_{x'}}_P$ as $x'$ ranges over elements of $X \setminus \{x\}$, that $\delta D\big(  \ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \big)$ is equal to
\be\label{eq_written72}
\sum_{X \in \cat{P}_{\{1,\ldots,s\}}} \Big\{ \sum_{x \in X} \Big|\, \ket{\nu, \nu_x}_P\,, \otimes_{x' \neq x} \ket{\nu_{x'}}_P\Big\rangle_Q + \Big|\, \ket{\nu}_P\,, \otimes_{x \in X} \ket{\nu_x}_P \Big\rangle_Q \Big\}\,.
\ee
Note that when $X = \big\{ \{ 1,\ldots,s \} \big\}$ the summand is
\[
\Big|\, \ket{\nu,\nu_1,\ldots,\nu_s}_P \Big\rangle_Q + \Big|\, \ket{\nu}_P, \ket{\nu_1,\ldots,\nu_s}_P \Big\rangle_Q\,.
\]
On the other hand, the right hand side \eqref{eq:D4final} of the (D.4) identity is
\begin{align*}
&D_{{!} V}(\delta \otimes D)(\Delta \otimes 1)\big(  \ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \big)\\
&= \sum_{I \subseteq \{1,\ldots,s\}} D_{{!}V}(\delta \otimes D)\Big( \ket{\nu_I}_P \otimes \ket{\nu_{I^c}}_P \otimes \nu \Big)\\
&= \sum_{I \subseteq \{1,\ldots,s\}} D_{{!} V}\Big( \delta \ket{\nu_I}_P \otimes \ket{\nu, \nu_{I^c}}_P \Big)\\
&= D_{{!} V}\Big( \delta\ket{\emptyset}_P \otimes \ket{\nu, \nu_1, \ldots, \nu_s }_P \Big)\\
&\qquad + \sum_{\emptyset \subset I} \sum_{Y \in \cat{P}_I} D_{{!}V}\Big( \big| \otimes_{y \in Y} \ket{\nu_y}_P \big\rangle_Q \otimes \ket{\nu, \nu_{I^c}}_P \Big)\\
&= \Big|\, \ket{ \nu, \nu_1,\ldots,\nu_s }_P \Big\rangle_Q + \sum_{\emptyset \subset I}\sum_{Y \in \cat{P}_I}  \Big|\, \ket{\nu, \nu_{I^c}}_P\,, \otimes_{y \in Y} \ket{\nu_y}_P \Big\rangle_Q\\
&= \Big|\, \ket{ \nu, \nu_1,\ldots,\nu_s }_P \Big\rangle_Q + \sum_{Y \in \cat{P}_{\{1,\ldots,s\}}} \Big|\, \ket{\nu}_P\,, \otimes_{y \in Y} \ket{\nu_y}_P \Big\rangle_Q\\
&\qquad+ \sum_{\emptyset \subset I \subset \{1,\ldots,s\}} \sum_{Y \in \cat{P}_I} \Big|\, \ket{\nu, \nu_{I^c}}_P\,, \otimes_{y \in Y} \ket{\nu_y}_P \Big\rangle_Q
\end{align*}
which matches \eqref{eq_written72} since the last sum can be rewritten as
\[
\sum_{\substack{X \in \cat{P}_{\{1,\ldots,s\}}\\ \text{ with } |X| > 1}} \sum_{x \in X} \Big|\, \ket{\nu, \nu_x}_P\,, \otimes_{x' \neq x} \ket{\nu_{x'}}_P \Big\rangle_Q\,.
\]
\end{proof}

\begin{corollary} $\cat{V}$ is a differential category.
\end{corollary}
\begin{proof}
This follows from \cite[Proposition 2.6]{blutecs}.
\end{proof}

\subsection{Codereliction, cocontraction, coweakening}\label{section:coder}

An alternative formulation of the differential structure in differential linear logic is in terms of \emph{codereliction, cocontraction} and \emph{coweakening} maps; see \cite{fiore} and \cite[\S 5.1]{blutecon}. This has the advantage of providing an appealing symmetry to the formulation of the syntax. In this section we briefly sketch the definition of these maps in the Sweedler semantics. Throughout linear logic means intuitionistic linear logic with the connectives ${!}, \otimes, \multimap$.

First we recall the canonical commutative Hopf structure on ${!} V$ of \cite[\S 6.4]{sweedler}. Given vector spaces $V_1,V_2$ then (see \cite[Remark 2.19]{sweedler}) there is an isomorphism of coalgebras
\begin{gather*}
\Psi: {!} V_1 \otimes {!} V_2 \lto {!} (V_1 \oplus V_2)\,,\\
\ket{\nu_1,\ldots,\nu_s}_P \otimes \ket{\omega_1,\ldots,\omega_t}_Q \longmapsto \ket{\nu_1,\ldots,\nu_s,\omega_1,\ldots,\omega_t}_{(P,Q)}\,.
\end{gather*}
Using this and the definitions in \cite{sweedler}, it is easy to check that the product $\nabla$ is
\begin{gather*}
\nabla: {!} V \otimes {!} V \lto {!} V\,,\\
\ket{\nu_1,\ldots,\nu_s}_P \otimes \ket{\omega_1,\ldots,\omega_t}_Q \longmapsto \ket{\nu_1,\ldots,\nu_s,\omega_1,\ldots,\omega_t}_{P+Q}\,,
\end{gather*}
while the antipode $S$ is
\begin{gather*}
S: {!} V \lto {!} V\,,\\
\ket{\nu_1,\ldots,\nu_s}_P \longmapsto \ket{-\nu_1,\ldots,-\nu_s}_{-P}
\end{gather*}
and the unit $u: k \lto {!} V$ is $u(1) = \ket{\emptyset}_0$. By \cite[Theorem 6.4.8]{sweedler} these maps make ${!} V$ into a commutative (and cocommutative) Hopf algebra. In the terminology of \cite{ehrhard-survey} the map $\nabla$ is the \emph{cocontraction} map and $u$ is the \emph{coweakening} map (the antipode seems not to have a formal role in differential linear logic). Finally,

\begin{definition} The \emph{codereliction} $\bar{d}$ is the composite
\[
\xymatrix@C+2pc{
V \cong V \otimes k \ar[r]^-{1 \otimes u} & V \otimes {!} V \ar[r]^-{D} & {!} V
}
\]
which is given by $\nu \mapsto \ket{\nu}_0$.
\end{definition}

Note that we can recover $D$ as
\begin{gather*}
\xymatrix@C+2pc{
{!} V \otimes V \ar[r]^-{1 \otimes \bar{d}} & {!} V \otimes {!} V \ar[r]^-{\nabla} & {!} V
}\\
\ket{\nu_1,\ldots,\nu_s}_P \otimes \nu \mapsto \ket{\nu_1,\ldots,\nu_s}_P \otimes \ket{\nu}_0 \mapsto \ket{\nu,\nu_1,\ldots,\nu_s}_P\,.
\end{gather*}
It seems more convenient to model differentiation syntactically using the codereliction, cocontraction and coweakening maps, rather than the deriving transformation $D$ itself. We briefly sketch how this works, following \cite{ehrhard-survey}. In the sequent calculus for linear logic one introduces three new deduction rules ``dual'' to dereliction, contraction and weakening:
\[
\AxiomC{$\Gamma, {!}A, \Delta \vdash B$}
\LeftLabel{(Codereliction): }
\RightLabel{\scriptsize coder}
\UnaryInfC{$\Gamma, A, \Delta \vdash B$}
\DisplayProof
\]
\[
\AxiomC{$\Gamma, !A, \Delta \vdash B$}
\LeftLabel{(Cocontraction): }
\RightLabel{\scriptsize coctr}
\UnaryInfC{$\Gamma, !A, !A, \Delta \vdash B$}
\DisplayProof
\]
\[
\AxiomC{$\Gamma, !A, \Delta \vdash B$}
\LeftLabel{(Coweakening): }
\RightLabel{\scriptsize coweak}
\UnaryInfC{$\Gamma, \Delta \vdash B$}
\DisplayProof
\]
together with new cut-elimination rules \cite[\S 1.4.3]{ehrhard-survey}. 

\begin{definition}\label{defn:derivative_proof} Given a proof $\pi$ of ${!} A \vdash B$ in linear logic, the \emph{derivative} $\partial \pi$ is the proof
\be
\begin{mathprooftree}
\AxiomC{$\pi$}
\noLine\UnaryInfC{$\vdots$}
\def\extraVskip{5pt}
\noLine\UnaryInfC{${!} A \vdash B$}
\RightLabel{\scriptsize coctr}
\UnaryInfC{${!} A, {!} A \vdash B$}
\RightLabel{\scriptsize coder}
\UnaryInfC{${!} A, A \vdash B$}
\end{mathprooftree}
\ee
whose denotation is, by our earlier remark, the composite
\be
\xymatrix@C+2pc{
{!} \den{A} \otimes \den{A} \ar[r]^-{D} & {!} \den{A} \ar[r]^-{\den{\pi}} & \den{B}\,.
}
\ee
\end{definition}

\begin{remark}\label{remark:totem}
Given $\pi$ as above we have the function \cite[Definition 5.10]{murfet_ll}
\be
\den{\pi}_{nl}: \den{A} \lto \den{B}\,, \qquad P \longmapsto \den{\pi}\ket{\emptyset}_P\,,
\ee
and for $P, \nu \in \den{A}$ we interpret the vector
\be
\den{\pi}D( \ket{\emptyset}_P \otimes \nu ) = \den{\pi}\ket{\nu}_P \in \den{B}
\ee
as the derivative of $\den{\pi}_{nl}$ at the point $P$ in the direction of $\nu$. Here we implicitly identify $\den{A}$ with the tangent space $T_P\den{A}$ and $\den{B}$ with the tangent space $T_{\den{\pi}_{nl}(P)} \den{B}$. This interpretation is justified by the following elaboration of the remarks in the Introduction. 

Let $\operatorname{prom}(\pi)$ denote the proof which is the promotion of $\pi$, which has for its denotation the unique morphism of coalgebras $\den{ \operatorname{prom}(\pi) }: {!} \den{A} \lto {!} \den{B}$ with $d \circ \den{ \operatorname{prom}(\pi) } = \den{\pi}$. Let $\Psi: (k[\varepsilon]/\varepsilon^2)^* \lto {!} \den{A}$ be the morphism of coalgebras as in \eqref{eq:app_psiman} corresponding to the tangent vector $\nu$ at a point $P \in \den{A}$. Then the morphism of coalgebras
\be\label{eq:prompiafterpsi}
\den{ \operatorname{prom}(\pi) } \circ \Psi : (k[\varepsilon]/\varepsilon^2)^* \lto {!} \den{B}
\ee
has the following values, writing $Q = \den{\pi}_{nl}(P)$, we have by \cite[Theorem 2.22]{murfet_coalg}
\begin{align*}
\den{ \operatorname{prom}(\pi) }\Psi(1) &= \den{ \operatorname{prom}(\pi) } \ket{\emptyset}_P = \ket{\emptyset}_Q\,,\\
\den{ \operatorname{prom}(\pi) }\Psi(\varepsilon^*) &= \den{ \operatorname{prom}(\pi) } \ket{\nu}_P = \Big|\, \den{\pi}\ket{\nu}_P \Big\rangle_Q\,.
\end{align*}
Under the bijection of Section \ref{section:tangent_vectors} the morphism of coalgebras \eqref{eq:prompiafterpsi} therefore corresponds to the tangent vector $\den{\pi}\ket{\nu}_P \in \den{B}$ at $Q$.
\end{remark}

It is easy using the formulas for $\nabla, D$ to check that the $\nabla$-rule of \cite[\S 4.3]{blutecs} is satisfied:

\begin{lemma} The diagram
\be
\xymatrix@C+2pc{
V \otimes {!} V \otimes {!} V \ar[d]_-{D \otimes 1} \ar[r]^-{1 \otimes \nabla} & V \otimes {!} V \ar[d]^-{D}\\
{!} V \otimes {!} V \ar[r]_-{\nabla} & {!} V
}
\ee
commutes.
\end{lemma}

This, together with \cite[Theorem 4.12]{blutecs}, shows that $\cat{V}$ with the comonad ${!}$ and deriving transformation $D$ is a model of the differential calculus in the sense of \cite[Definition 4.11]{blutecs}.

\begin{corollary} $\cat{V}$ is a categorical model of the differential calculus.
\end{corollary}

\section{Examples}\label{section:examples}

In this section we give various examples of proofs $\pi$ and the derivatives $\den{\pi} \circ D$ of their denotations, according to Definition \ref{defn:derivative_proof}. We recall briefly the definition of the semantics $\den{-}$ in the category $\cat{V}$ of $k$-vector spaces from \cite{hyland} and \cite[\S 5.1, \S 5.3]{murfet_ll}. For a propositional variable $x$ the denotation $\den{x}$ is any finite-dimensional vector space, and
\begin{align*}
\den{A \multimap B} &= \Hom_k(\den{A},\den{B})\,,\\
\den{A \otimes B} &= \den{A} \otimes \den{B}\,,\\
\den{{!}A} &= {!} \den{A}\,,
\end{align*}
where ${!} V$ denotes the universal cocommutative counital coalgebra mapping to $V$.
\vspace{0.2cm}

The encoding of integers and binary sequences in linear logic is based on the following encoding of the composition rule.

\begin{definition} For any formula $A$ let $C^1_A$ denote the proof
\begin{center}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$A, A \multimap A \vdash A$}
\DisplayProof
\end{center}
We define recursively for $n > 1$ a proof $C^n_A$ of $A, (A \multimap A)^n \vdash A$, where $(A \multimap A)^n$ denotes a sequence of $n$ copies of $A \multimap A$, to be
\begin{center}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\AxiomC{$C^{n-1}_A$}
\noLine\UnaryInfC{$\vdots$}
\noLine\UnaryInfC{$A, (A \multimap A)^{n-1} \vdash A$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$A, (A \multimap A)^n \vdash A$}
\DisplayProof
\end{center}
\end{definition} 

\begin{definition} For $n \ge 1$ let $\comp^n_A$ denote the proof
\begin{center}
\AxiomC{$C^{n}_A$}
\noLine\UnaryInfC{$\vdots$}
\noLine\UnaryInfC{$A, (A \multimap A)^{n} \vdash A$}
\RightLabel{\scriptsize$\multimap R$}
\UnaryInfC{$(A \multimap A)^n \vdash A \multimap A$}
\DisplayProof
\end{center}
We define $\comp^0_A$ to be the proof
\begin{center}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\RightLabel{\scriptsize$\multimap R$}
\UnaryInfC{$\vdash A \multimap A$}
\DisplayProof
\end{center}
\end{definition}

\begin{remark}
If $V = \den{A}$ and $\alpha_i \in \den{A \multimap A} = \End_k(V)$ for $1 \le i \le n$ then
\be\label{order_comp}
\den{\comp^n_A}( \alpha_1 \otimes \cdots \otimes \alpha_n ) = \alpha_n \circ \cdots \circ \alpha_1\,,
\ee
while $\den{\comp^0_A} = 1_V$.
\end{remark}

\subsection{Church numerals}\label{section:church}

\begin{definition} The type of \emph{integers on $A$} \cite[\S 5.3.2]{girard_llogic} is:
\[
\inta_A = {!}( A \multimap A ) \multimap (A \multimap A)\,.
\]
For $n \ge 0$ we define the Church numeral $\underline{n}_A$ to be the proof
\begin{center}
\AxiomC{$\comp^n_A$}
\noLine\UnaryInfC{$\vdots$}
\noLine\UnaryInfC{$(A \multimap A)^{n} \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize $n \times$ der}
\UnaryInfC{${!}(A \multimap A)^n \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize $n \times$ ctr}
\UnaryInfC{${!}(A \multimap A) \vdash A \multimap A$}
\RightLabel{\scriptsize $\multimap R$}
\UnaryInfC{$\vdash \inta_A$}
\DisplayProof
\end{center}
Generally we omit the final step, since it is irrelevant semantically. In the case $n = 0$ the ${!}(A \multimap A)$ is introduced on the left by a weakening rule.
\end{definition}

\begin{example} The proof $\underline{2}_A$ (see e.g. \cite[Example 5.9]{murfet_ll}) is
\begin{center}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$A, A \multimap A \vdash A$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$A, A \multimap A, A \multimap A \vdash A$}
\RightLabel{\scriptsize$\multimap R$}
\UnaryInfC{$A \multimap A, A \multimap A \vdash A \multimap A$}
\RightLabel{\scriptsize der}
\UnaryInfC{$!( A \multimap A ), A \multimap A \vdash A \multimap A$}
\RightLabel{\scriptsize der}
\UnaryInfC{$!( A \multimap A), !(A \multimap A) \vdash A \multimap A$}
\RightLabel{\scriptsize ctr}
\UnaryInfC{$!( A \multimap A) \vdash A \multimap A$}
\DisplayProof
\end{center}
\end{example}

From now on $A$ is fixed and we write $\underline{n}$ for $\underline{n}_A$. Let $V = \den{A}$ so $\den{A \multimap A} = \End_k(V)$. In the notation of Remark \ref{remark:totem}, there is a function
\be
\den{\underline{n}}_{nl}: \End_k(V) \lto \End_k(V)\,.
\ee

\begin{lemma} For $n \ge 0$ and $\alpha \in \End_k(V)$, we have $\den{\underline{n}}\ket{\emptyset}_\alpha = \alpha^n$ so $\den{\underline{n}}_{nl}(\alpha) = \alpha^n$.
\end{lemma}
\begin{proof}
This is an easy exercise, see \cite{murfet_ll} for the case $n = 2$.
\end{proof}

The derivative $\partial\, \underline{n}$ of Definition \ref{defn:derivative_proof} is a proof of ${!}(A \multimap A), A \multimap A \vdash A \multimap A$ and for $\alpha, \nu \in \End_k(V)$ the value of its denotation $\den{\partial\, \underline{n}} = \den{\underline{n}} \circ D$ on $\ket{\emptyset}_\alpha \otimes \nu$, that is, the derivative of $\underline{n}$ at $\alpha$ in the direction of $\nu$, is $\den{\underline{n}} \ket{\nu}_\alpha$. 

\begin{lemma}\label{lemma:nderiv} $\den{\underline{n}}\ket{\nu}_\alpha = \sum_{i = 1}^{n} \alpha^{i-1} \nu \alpha^{n-i}$.
\end{lemma}
\begin{proof}
This may be computed using the formulas of \cite[p.19]{murfet_ll}. For example, in the case $n = 2$ the image of $\ket{\nu}_\alpha$ under $\den{\underline{n}}$ is given by
\begin{align*}
\ket{\nu}_\alpha 
&\xmapsto{\makebox[1cm]{\scriptsize ctr}} \ket{\nu}_\alpha \otimes \ket{\emptyset}_\alpha + \ket{\emptyset}_\alpha \otimes \ket{\nu}_\alpha
\\&\xmapsto{\makebox[1cm]{\scriptsize $2 \times$ \text{der}} } \nu \otimes \alpha + \alpha \otimes \nu
\\&\xmapsto{\makebox[1cm]{\scriptsize $ - \circ -$} } \alpha \circ \nu + \nu \circ \alpha\,,
\end{align*}
as claimed.
\end{proof}

\begin{remark} When $k = \mathbb{C}$, $V$ is $r$-dimensional and $\varphi = \den{\underline{n}}_{nl}$, the vector $\den{\underline{n}}\ket{\nu}_\alpha$ agrees with the image of $\nu$ under the usual tangent map of the smooth map $\varphi$
\[
\xymatrix@C+2pc{
M_r(\mathbb{C}) \cong T_\alpha \End_k(V) \ar[r]^-{T_\alpha \varphi} & T_{\alpha^n}\End_k(V) \cong M_r(\mathbb{C})\,.
}
\]
This justifies in this case the interpretation of $\den{\underline{n}}\ket{\nu}_\alpha$ as the derivative.
\end{remark}


\subsection{Binary integers}\label{section:bint}

\begin{definition}
The type of \emph{binary integers on $A$} \cite[\S 2.5.3]{girard_complexity} is:
\[
\binta_A = {!}( A \multimap A) \multimap ({!}( A \multimap A) \multimap ( A \multimap A)).
\]
Given a sequence $S \in \{0,1\}^*$ we define a proof $\underline{S}_A$ of $\binta_A$ as follows. Let $l \ge 0$ be the length of $S$. The proof tree for $\underline{S}_A$ matches that of the Church numeral $\underline{l}$ up to the step where we perform contractions, that is,
\begin{equation}\label{bint_Upto}
\begin{mathprooftree}
\AxiomC{$\comp^l_A$}
\noLine\UnaryInfC{$\vdots$}
\noLine\UnaryInfC{$(A \multimap A)^{l} \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize $n \times$ der}
\UnaryInfC{${!}(A \multimap A)^l \vdash A \multimap A$}
\end{mathprooftree}
\end{equation}
We match each copy of ${!}(A \multimap A)$ on the left with the corresponding position in $S$, and using a series of contractions we identify all copies corresponding to a position in which $0$ appears in $S$, and likewise all copies corresponding to positions with a $1$. After these contractions, there will be two copies of ${!}(A \multimap A)$ on the left (the first being by convention the remnant of all the $0$-associated copies) unless $S$ contains only $0$'s or only $1$'s. In this case we use further a weakening rule to introduce the ``missing'' ${!}(A \multimap A)$, giving finally the desired proof $\underline{S}_A$:
\begin{center}
\AxiomC{$\comp^l_A$}
\noLine\UnaryInfC{$\vdots$}
\noLine\UnaryInfC{$(A \multimap A)^{l} \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize $n \times$ der}
\UnaryInfC{${!}(A \multimap A)^l \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize ctr and possibly weak}
\UnaryInfC{${!}(A \multimap A), {!}(A \multimap A) \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize $2 \times \multimap R$}
\UnaryInfC{$\vdash \binta_A$}
\DisplayProof
\end{center}
In the final right $\multimap R$ introduction rules, the second copy of ${!}(A \multimap A)$ (associated with the $1$'s in $S$) is moved across the turnstile first. If $S$ is the empty sequence, then $l = 0$ and the proof is a pair of weakenings on the left followed by the $\multimap R$ introduction rules.
\end{definition}

For the rest of this section $A$ is fixed and we write $\underline{S}$ for $\underline{S}_A$.

\begin{example} The proof $\underline{001}$ is 
\begin{center}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\AxiomC{}
\UnaryInfC{$A \vdash A$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$A, A \multimap A \vdash A$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$A, A \multimap A, A \multimap A \vdash A$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$A, A \multimap A, A \multimap A, A \multimap A \vdash A$}
\RightLabel{\scriptsize$\multimap R$}
\UnaryInfC{$A \multimap A, A \multimap A, A \multimap A \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize $3 \times$ der}
\UnaryInfC{$\textcolor{red}{!(A \multimap A)}, \textcolor{red}{!( A \multimap A)}, \textcolor{blue}{!(A \multimap A)} \vdash A \multimap A$}
\RightLabel{\scriptsize ctr}
\UnaryInfC{$\textcolor{red}{!(A \multimap A)}, \textcolor{blue}{!( A \multimap A)} \vdash A \multimap A$}
\doubleLine\RightLabel{\scriptsize $2 \times \multimap R$}
\UnaryInfC{$\vdash \binta_A$}
\DisplayProof
\end{center}
where the colouring indicates which copies of ${!}(A \multimap A)$ are contracted. Using \eqref{order_comp},
\be
\den{\underline{001}}\big(\vacu_\gamma \otimes \vacu_\delta\big) = \den{\comp^3_A}\big(\vacu_\gamma \otimes \vacu_\gamma \otimes \vacu_\delta \big) = \delta \circ \gamma \circ \gamma\,.
\ee
\end{example}

Generalising the calculation of Section \ref{section:church} we now describe the derivatives of binary integers. The general formula computes, for $S \in \{0,1\}^*$, the linear operator
\[
\den{ \underline{S} }\big( \ket{\alpha_1,\ldots,\alpha_r}_{\gamma} \otimes \ket{\beta_1,\ldots,\beta_s}_{\delta} \big) \in \End_k(V)\,.
\]
Informally, this operator is described by inserting $\gamma$ for $0$ and $\delta$ for $1$ in (the reversal of) $S$, and then summing over all ways of replacing $r$ of the $\gamma$'s in this composite with $\alpha_i$'s, and $t$ of the $\delta$'s with $\beta_j$'s. Let $\operatorname{Inj}(P,Q)$ denote the set of injective functions $P \lto Q$, and write $[s] = \{1,\ldots,s\}$.

\begin{lemma}\label{lemma:derivative_bint} Let $S = a_l a_{l-1} \cdots a_1$ with $a_i \in \{0,1\}$ be a binary sequence, and set
\[
N_0 = \{ j \l a_j = 0 \}\,, \qquad N_1 = \{ j \l a_j = 1 \}\,.
\]
Then we have
\be\label{eq:formula_derivative_bint}
\den{ \underline{S} }\big( \ket{\alpha_1,\ldots,\alpha_s}_{\gamma} \otimes \ket{\beta_1,\ldots,\beta_r}_{\delta} \big) = \sum_{f \in \operatorname{Inj}([s],N_0)} \sum_{g \in \operatorname{Inj}([r],N_1)} \Gamma^{f,g}_1 \circ \cdots \circ \Gamma^{f,g}_l\,,
\ee
where
\[
\Gamma^{f,g}_i = \begin{cases}
\gamma & i \in N_0 \setminus \operatorname{Im}(f)\,,\\
\delta & i \in N_1 \setminus \operatorname{Im}(g)\,,\\
\alpha_j & \text{if } i \in \operatorname{Im}(f) \text{ and } f(j) = i\,,\\
\beta_j & \text{if } i \in \operatorname{Im}(g) \text{ and } g(j) = i\,.
\end{cases}
\]
In particular this vanishes if $s > |N_0|$ or $r > |N_1|$.
\end{lemma}
\begin{proof}
This is clear, since $\den{\underline{S}}$ applies $n = |N_0|$ coproducts to $\ket{\alpha_1,\ldots,\alpha_s}_{\gamma}$ yielding
\[
\sum_{\substack{J_1,\ldots,J_n\\ \text{pairwise disjoint, s.t.} \\ J_1 \cup \cdots \cup J_n = \{1,\ldots,s\}}} \ket{\alpha_{J_1}}_\gamma \otimes \cdots \otimes \ket{\alpha_{J_n}}_\gamma\,,
\]
to which the dereliction operator $d^{\otimes n}$ is applied, which annihilates those tuples $(J_1,\ldots,J_n)$ where any $J_i$ contains more than one element. The resulting sum is over $f \in \operatorname{Int}([s],N_0)$ and each summand is $\gamma \otimes \cdots \otimes \alpha_{\sigma(1)} \otimes \cdots \otimes \gamma \otimes \cdots \alpha_{\sigma(s)} \otimes \cdots \otimes \gamma$ for a permutation $\sigma$. The same is true of $\ket{\beta_1,\ldots,\beta_r}_{\delta}$, and after the two resulting tensors are intertwined the final step is compose all the operators, yielding \eqref{eq:formula_derivative_bint}.
\end{proof}

\begin{example} For $S = 001$ we have
\begin{align*}
\den{\underline{001}}\big( \ket{\alpha}_\gamma \otimes \ket{\emptyset}_\delta \big) &= \delta \circ \alpha \circ \gamma + \delta \circ \gamma \circ \alpha\,,\\
\den{\underline{001}}\big( \ket{\alpha_1,\alpha_2}_\gamma \otimes \ket{\emptyset}_\delta \big) &= \delta \circ \alpha_1 \circ \alpha_2 + \delta \circ \alpha_2 \circ \alpha_1\,,\\
\den{\underline{001}}\big( \ket{\emptyset}_\gamma \otimes \ket{\beta}_\delta \big) &= \beta \circ \gamma \circ \gamma\,,\\
\den{\underline{001}}\big( \ket{\alpha}_\gamma \otimes \ket{\beta}_\delta \big) &= \beta \circ \alpha \circ \gamma + \beta \circ \gamma \circ \alpha\,,\\
\den{\underline{001}}\big( \ket{\alpha_1,\alpha_2}_\gamma \otimes \ket{\beta}_\delta \big) &= \beta \circ \alpha_1 \circ \alpha_2 + \beta \circ \alpha_2 \circ \alpha_1\,.
\end{align*}
and zero for all other inputs.
\end{example}

More interestingly we can also compute the derivatives of proofs of ${!}\binta_A \vdash \binta_A$. In what follows $A$ is fixed and $E = A \multimap A$.

\begin{definition} The proof $\repeat$ is
\begin{center}
\AxiomC{}
\UnaryInfC{$\textcolor{red}{{!}E} \vdash {!}E$}
\AxiomC{}
\UnaryInfC{$\textcolor{blue}{{!}E} \vdash {!}E$}
\AxiomC{}
\UnaryInfC{$\textcolor{red}{{!}E} \vdash {!}E$}
\AxiomC{}
\UnaryInfC{$\textcolor{blue}{{!}E} \vdash {!}E$}
\AxiomC{$\comp^2_A$}
\noLine\UnaryInfC{$\vdots$}
\noLine\UnaryInfC{$E, E \vdash E$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$\textcolor{blue}{{!} E}, {!}E \multimap E, E \vdash E$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$\textcolor{red}{{!} E}, \textcolor{blue}{{!} E}, \binta_A, E \vdash E$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$\textcolor{blue}{{!} E}, \textcolor{red}{{!} E}, \textcolor{blue}{{!} E}, \binta_A, {!}E \multimap E \vdash E$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{$\textcolor{red}{{!} E}, \textcolor{blue}{{!} E}, \textcolor{red}{{!} E}, \textcolor{blue}{{!} E}, \binta_A, \binta_A \vdash E$}
\RightLabel{\scriptsize ctr}
\UnaryInfC{$\textcolor{red}{{!} E},\textcolor{blue}{{!} E},\textcolor{blue}{{!} E}, \binta_A, \binta_A \vdash E$}
\RightLabel{\scriptsize ctr}
\UnaryInfC{$\textcolor{red}{{!} E},\textcolor{blue}{{!} E}, \binta_A, \binta_A \vdash E$}
\doubleLine\RightLabel{\scriptsize$2\times \multimap R$}
\UnaryInfC{$\binta_A, \binta_A \vdash \binta_A$}
\doubleLine\RightLabel{\scriptsize$2\times$ der}
\UnaryInfC{${!}\binta_A, {!}\binta_A \vdash \binta_A$}
\RightLabel{\scriptsize ctr}
\UnaryInfC{${!}\binta_A \vdash \binta_A$}
\DisplayProof
\end{center}
%To see that this really does repeat a given binary sequence $S$, we let $\alpha = \den{S}$ and compute $\den{\repeat_A} \vacu_\alpha (\vacu_\gamma, \vacu_\delta)$:
%\begin{align*}
%\vacu_\alpha 
%&\xmapsto{\text{ctr}} \vacu_\alpha \otimes \vacu_\alpha 
%\\&\xmapsto{2 \times \text{der}} \alpha \otimes \alpha
%\\&\xmapsto{2\times R \multimap} \vacu_\gamma \otimes \vacu_\delta \otimes \alpha \otimes \alpha
%\\&\xmapsto{2\times \text{ctr}} \vacu_\gamma \otimes \vacu_\delta \otimes \vacu_\gamma \otimes \vacu_\delta \otimes \alpha \otimes \alpha
%\\&\xmapsto{} \alpha(\vacu_\gamma, \vacu_\delta) \circ \alpha(\vacu_\gamma, \vacu_\delta)
%\\&= \den{SS}(\vacu_\gamma, \vacu_\delta)
%\end{align*}
which repeats a binary sequence in the sense that the cutting it against the promotion of $\underline{S}$ is equivalent under cut-elimination to $\underline{SS}$. In particular, $\den{\repeat}\ket{\emptyset}_{\den{\underline{S}}} = \den{\underline{SS}}$.
\end{definition}

Given $S, T \in \{0,1\}^*$ the derivative of $\repeat$ at $S$ in the direction of $T$ is
\be
\den{\repeat}\ket{\den{\underline{T}}}_{\den{\underline{S}}} \in \den{\binta_A} = \Hom_k( {!} \End_k(V) \otimes {!}\End_k(V), \End_k(V))\,,
\ee
and as promised in the Introduction:

\begin{lemma} $\den{\repeat}\ket{\den{\underline{T}}}_{\den{\underline{S}}} = \den{\underline{ST}} + \den{\underline{TS}}$.
\end{lemma}
\begin{proof}
The value of the left-hand side on a tensor $\ket{\alpha_1,\ldots,\alpha_s}_{\gamma} \otimes \ket{\beta_1,\ldots,\beta_r}_{\delta}$ is computed by reading the proof-tree for $\repeat$ from bottom to top:
\begin{align*}
\ket{\den{\underline{T}}}_{\den{\underline{S}}} 
&\xmapsto{\makebox[1cm]{\scriptsize\text{ctr}}} \ket{\den{\underline{T}}}_{\den{\underline{S}}} \otimes \ket{\emptyset}_{\den{\underline{S}}} + \ket{\emptyset}_{\den{\underline{S}}} \otimes \ket{\den{\underline{T}}}_{\den{\underline{S}}}
\\&\xmapsto{\makebox[1cm]{\scriptsize$2\times$ der}} \den{\underline{T}} \otimes \den{\underline{S}} + \den{\underline{S}} \otimes \den{\underline{T}}
\\&\xmapsto{\makebox[1cm]{\scriptsize${2\times} {R \multimap}$}} \ket{\alpha_1,\ldots,\alpha_s}_{\gamma} \otimes \ket{\beta_1,\ldots,\beta_r}_{\delta} \otimes \big(\den{\underline{T}} \otimes \den{\underline{S}} + \den{\underline{S}} \otimes \den{\underline{T}}\big)
\\&\xmapsto{\makebox[1cm]{\scriptsize$2\times$ ctr}} \sum_{I,J} \ket{\alpha_I}_{\gamma} \otimes \ket{\beta_J}_{\delta} \otimes \ket{\alpha_{I^c}}_{\gamma} \otimes \ket{\beta_{J^c}}_{\delta} \otimes \big( \den{\underline{T}} \otimes \den{\underline{S}} + \den{\underline{S}} \otimes \den{\underline{T}} \big)
\\&\xmapsto{\makebox[1cm]{}} \sum_{I,J} \den{\underline{S}}\big( \ket{\alpha_I}_{\gamma} \otimes \ket{\beta_J}_{\delta} \big) \circ \den{\underline{T}}\big( \ket{\alpha_{I^c}}_{\gamma} \otimes \ket{\beta_{J^c}}_{\delta} \big)
\\& \qquad\qquad + \sum_{I,J} \den{\underline{T}}\big( \ket{\alpha_I}_{\gamma} \otimes \ket{\beta_J}_{\delta} \big) \circ \den{\underline{S}}\big( \ket{\alpha_{I^c}}_{\gamma} \otimes \ket{\beta_{J^c}}_{\delta} \big)
\end{align*}
which agrees with $\den{\underline{ST}} + \den{\underline{TS}}$ on $\ket{\alpha_1,\ldots,\alpha_s}_{\gamma} \otimes \ket{\beta_1,\ldots,\beta_r}_{\delta}$ by Lemma \ref{lemma:derivative_bint}.
\end{proof}

\subsection{Multiplication}\label{section:mult}

The multiplication of Church numerals is encoded by a proof $\mult_A$ of ${!} \inta_A, \inta_A \vdash \inta_A$, see for example \cite[\S 2.5.2]{girard_complexity}. To construct the proof tree it will be convenient to introduce the following intermediate proof $\gamma$, writing $E = A \multimap A$ as above:
\begin{center}
\AxiomC{}
\UnaryInfC{${!}E \vdash {!}E$}
\AxiomC{}
\UnaryInfC{$E \vdash E$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{${!}E, \inta_A \vdash E$}
\RightLabel{\scriptsize der}
\UnaryInfC{${!}E, {!}\inta_A \vdash E$}
\RightLabel{\scriptsize prom}
\UnaryInfC{${!}E, {!}\inta_A \vdash {!}E$}
\DisplayProof
\end{center}
Then $\den{\gamma}: {!}\End_k(V) \otimes {!}\den{\inta_A} \to {!}\End_k(V)$ is a morphism of coalgebras  such that 
\[\den{\gamma}(t \otimes \vacu_\alpha) = \vacu_{\alpha(t)} \qquad \text{and} \qquad \den{\gamma}(t \otimes \ket{\nu}_\alpha) = \ket{\nu(t)}_{\alpha(t)},\]
for $\alpha, \nu \in \den{\inta_A} = \Hom_k({!}\End_k(V), \End_k(V))$ and $t \in {!} \End_k(V)$. The proof $\mult_A$ is
\begin{center}
\AxiomC{$\gamma$}
\noLine\UnaryInfC{$\vdots$}
\noLine\UnaryInfC{$!E, {!}\inta_A \vdash {!}E$}
\AxiomC{}
\UnaryInfC{$E \vdash E$}
\RightLabel{\scriptsize$\multimap L$}
\BinaryInfC{${!}E, {!}\inta_A, \inta_A \vdash E$}
\RightLabel{\scriptsize$\multimap R$}
\UnaryInfC{${!}\inta_A, \inta_A \vdash \inta_A$}
\DisplayProof
\end{center}
Let $l,m,n \ge 0$ be integers. We write $\mult_A(-,n)$ for the proof of ${!} \inta_A \vdash \inta_A$ obtained from the above by cutting against the proof $\underline{n}$ of $\vdash \inta_A$. The derivative of this proof at $\alpha = \den{\underline{l}}$ in the direction of $\nu = \den{\underline{m}}$ is the element of $\den{\inta_A}$ given on $t \in {!} \End_k(V)$ by
\begin{align*} 
\den{\mult_A}\big(\ket{\nu}_\alpha \otimes \den{\underline{n}}\big)(t)
= \den{\underline{n}}\big(\ket{\nu(t)}_{\alpha(t)}\big)
= \sum_{i = 1}^{n} \alpha(t)^{i-1} \nu(t) \alpha(t)^{n-i}
\end{align*}
using Lemma \ref{lemma:nderiv} in the last step. When $t = \vacu_x$ for $x \in \End_k(V)$, this evaluates to
\[ 
\sum_{i = 1}^{n} \alpha(t)^{i-1} \nu(t) \alpha(t)^{n-i} 
= \sum_{i = 1}^{n} x^{l(i-1)} x^m x^{l(n-i)} 
= n x^{l(n-1)+m}.
\]
This result agrees with a more traditional calculus approach using limits:
\begin{align*}
&\lim_{h \to 0} \frac{\den{\mult_A}(\vacu_{\den{\underline{l}} + h \den{\underline{m}}} \otimes \den{n})\vacu_x  - \den{\mult_A}(\vacu_{\den{\underline{l}}} \otimes \den{\underline{n}})\vacu_x}{h}\\
&= \lim_{h \to 0} \frac{\den{\underline{n}}\vacu_{x^l + h x^m} - \den{\underline{n}}\vacu_{x^l}}{h} \\
\\&= \lim_{h \to 0} \frac{(x^l + h x^m)^n - x^{ln}}{h} 
\\&= nx^{l(n-1)+m}.
\end{align*}
This agreement between limits and the derivatives of Definition \ref{defn:derivative_proof} holds more generally, but will be discussed elsewhere.
\appendix

\section{The cofree coalgebra}\label{section:background}

Let $k$ be an algebraically closed field of characteristic zero and $\cat{V}$ the category of $k$-vector spaces (possibly infinite dimensional). It is straightforward to check that the universal counital cocommutative coalgebra mapping to a finite-dimensional vector space $V$ (i.e. the cofree coalgebra) is the space $\Hom_k^{\cont}(\Sym(V^*),k)$ of linear functionals on the symmetric algebra $\Sym(V^*)$ which vanish on an ideal of finite codimension \cite{hyland}. Using the Chinese remainder theorem one sees further that this coalgebra breaks into a sum of pieces each isomorphism to a symmetric algebra, that is, that there is an isomorphism of coalgebras
\be\label{eq:isocontnu}
\Hom_k^{\cont}(\Sym(V^*),k) \cong \bigoplus_{P \in V} \Sym_P(V)
\ee
where $\Sym_P(V)$ is the symmetric algebra with its usual coproduct structure. Following the tradition of linear logic, we denote this universal coalgebra ${!} V$. The explicit formulas for the coproduct $\Delta_V$, counit $w_V$ and universal morphism $d_V: {!} V \lto V$ are given in \cite{murfet_coalg} and \cite[\S 5.2]{murfet_ll}. The universality of $d_V$ means more precisely that for any cocommutative coalgebra $C$ there is an isomorphism
\begin{gather*}
\Hom_{\operatorname{Coalg}(k)}(C, {!} V) \cong \Hom_{k}(C, V)\,,\\
\Phi \longmapsto d_V \circ \Phi
\end{gather*}
where the left hand side denotes morphisms of $k$-coalgebras.

We use the following notation from \cite{murfet_coalg,murfet_ll}: the image in the summand $\Sym_P(V)$ of ${!} V$ of a tensor $\nu_1 \otimes \cdots \otimes \nu_s \in V^{\otimes s}$ is denoted
\[
\ket{\nu_1,\ldots,\nu_s}_P = \overline{\nu_1 \otimes \cdots \otimes \nu_s} \in \Sym_P(V) \subseteq {!} V\,.
\]
By definition $\ket{\nu_{\tau(1)}, \ldots, \nu_{\tau(s)}}_P$ is the same element of ${!} V$ for any permutation $\tau \in \mathfrak{S}_s$. The identity $1 \in \Sym_P(V)$ is denoted $\ket{\emptyset}_P$. Given a subset $C = \{i_1,\ldots,i_t\} \subseteq \{1,\ldots,s\}$ we write $\ket{\nu_C}_P$ for $\ket{\nu_{i_1},\ldots,\nu_{i_t}}_P$. By \cite[Theorem 2.22]{murfet_coalg} the unique morphism of coalgebras $\delta: {!} V \lto {!} {!} V$ lifting the identity on ${!} V$, that is, satisfying $d_{{!} V} \circ \delta = 1_{{!} V}$, is given for $P, \nu_1,\ldots,\nu_s \in V$ by the formula
\be
\delta \ket{\nu_1, \ldots, \nu_s}_P = \sum_{\substack{C \text{ a partition}\\ \text{of } \{1,\ldots,s\}}} \Big|\, \ket{\nu_{C_1}}_P, \ldots, \ket{\nu_{C_l}}_P \Big\rangle_Q\,
\ee
where $Q = \ket{\emptyset}_P$. As a special case $\delta\ket{\emptyset}_P = \ket{\emptyset}_Q$. By construction the tuple $({!}, \delta, d, \Delta, w)$ is a coalgebra modality on $\cat{V}$ in the sense of \cite[Definition 2.1]{blutecs}.

\subsection{Tangent vectors}\label{section:tangent_vectors}

There is a well-known connection between the cofree coalgebra and tangent vectors, arising from the identification of the former with a coalgebra of distributions on $V$. We review this point of view at the end of Section \ref{section:residues}. But first we recall the approach to this connection of \cite[Appendix B]{murfet_ll} which emphasises the ring of dual numbers $k[\varepsilon]/(\varepsilon^2)$. In algebraic geometry this ring represents tangent vectors, in the sense that there is a bijection between morphisms of $k$-schemes $\Spec(k[\varepsilon]/\varepsilon^2) \lto X$ and pairs $(P, \nu)$ consisting of a closed point $P \in X$ and a tangent vector $\nu \in T_P X = (\mf{m}/\mf{m}^2)^*$ where $\mf{m} \subseteq \cat{O}_{X,P}$ is the maximal ideal.

When $X = \Spec(\Sym(V^*))$ for a finite-dimensional vector space $V$, the closed points of $X$ are in bijection with vectors in $V$, and the tangent space $T_P X$ is canonically isomorphic to $V$. Hence a morphism $\Phi: \Spec(k[\varepsilon]/(\varepsilon^2)) \lto X$ is determined by two vectors $P, \nu \in V$. This data is naturally associated with the element
\[
\ket{\nu}_P \in {!} V
\]
as follows. Let $\cat{T} = (k[\varepsilon]/(\varepsilon^2))^*$ with its natural coalgebra structure. Then
\begin{align*}
\Hom_{\operatorname{Sch}/k}\!\big(\Spec(k[\varepsilon]/(\varepsilon^2)), X\big) &\cong \Hom_{\operatorname{Alg}(k)}\!\big(\Sym(V^*), k[\varepsilon]/(\varepsilon^2)\big)\\
&\cong \Hom_{k}(V^*, k[\varepsilon]/(\varepsilon^2))\\
&\cong \Hom_{k}(\cat{T}, V)\\
&\cong \Hom_{\operatorname{Coalg}(k)}(\cat{T}, {!} V)\,.
\end{align*}
Under these bijections the scheme morphism $\Phi$ corresponds to the linear map
\be
\varphi: V^* \lto k[\varepsilon]/(\varepsilon^2)\,, \qquad \varphi(f) = f(P) \cdot 1 + \partial_\nu( f )|_{x=P} \cdot \varepsilon
\ee
and to the morphism of coalgebras
\be\label{eq:app_psiman}
\Psi: \cat{T} \lto {!} V\,, \qquad \Psi( 1 ) = \vacu_P, \; \Psi( \varepsilon^* ) = \ket{ \nu }_P\,.
\ee
This justifies the identification of $\ket{\nu}_P \in {!} V$ with the tangent vector $\nu$ at $P \in X$. 

Under the isomorphism \eqref{eq:isocontnu} the element $\ket{\nu}_P$ corresponds to the functional taking the derivative of a function $f \in \Sym(V^*)$ in the direction $\nu$ at $P$. One way to talk about such distributions for arbitrary fields is the framework of local cohomology and residues, which we now recall from \cite{murfet_coalg}.

\subsection{Local cohomology and residues}\label{section:residues}

For a finite-dimensional vector space $V$ of dimension $n$ with $R = \Sym(V^*)$, one proves using local duality \cite[Theorem 2.6]{murfet_coalg} that there is an isomorphism
\be\label{eq:otherbangV}
\bigoplus_{P \in V} H^{n}_{P}(R, \Omega^n_{R/k}) \cong \Hom_k^{\cont}(\Sym(V^*),k) \,,
\ee
where $H^n_P$ denotes local cohomology at $P$ \cite{residuesduality}. This isomorphism is defined by sending a class $\tau$ in the local cohomology at $P$ to the functional $f \mapsto \Res_P(f \tau)$ where $\Res_P$ denotes a generalised residue and $f \tau$ the action by $R$ on local cohomology. The connection between \eqref{eq:otherbangV} and \eqref{eq:isocontnu} is given by an isomorphism $H^{n}_{P}(R, \Omega^n_{R/k}) \cong \Sym_P(V)$ identifying the identity $\ket{\emptyset}_P$ in $\Sym_P(V)$ with the class of the meromorphic differential form \cite[Definition 2.9]{murfet_coalg}
\be
\left[ \frac{\ud x_1 \wedge \cdots \wedge \ud x_n}{(x_1-P_1), \ldots, (x_n-P_n)} \right] \in H^{n}_{P}(R, \Omega^n_{R/k})\,.
\ee
It is easy to see that 
\begin{equation}\label{eq:residue_differentiates}
\Res_P\Big( f \ket{\nu}_P \Big) = \partial_{\nu}( f )|_{x = P}\,,
\end{equation}
and more generally that \cite[Lemma 2.13]{murfet_coalg}
\begin{equation}\label{eq:residue_differentiates2}
\Res_P\Big( f \ket{\nu_1,\ldots,\nu_s}_P \Big) = \partial_{\nu_1} \cdots \partial_{\nu_s}( f )|_{x = P}\,.
\end{equation}
Thus we may identify elements of ${!} V$ with functionals on the space of polynomial functions, given by taking derivatives at points of $V$.

\begin{remark} When $k = \mathbb{C}$ with $V = \mathbb{C} \nu$ and $z = \nu^*$ the generator of $R = \mathbb{C}[z]$, this is nothing but the Cauchy integral formula since we have
\be
\ket{\emptyset}_P = \left[ \frac{\ud z }{z-P} \right], \qquad \ket{\nu}_P = \left[ \frac{\ud z }{(z-P)^2} \right]
\ee
and the Cauchy formula says
\[
f'(P) = \frac{1}{2 \pi i} \oint_\gamma \frac{f(z)}{(z-P)^2} \ud z\,.
\]
\end{remark}

\begin{remark}\label{remark:distr} When $k = \mathbb{R}$ this agrees with the analytic theory of distributions, since by \cite[Theorem 3.2.1]{friedlander} the $\mathbb{C}$-vector space of distributions on the real manifold $V$ supported at a point $P$ is spanned by the functions
\[
f \longmapsto \partial_{\nu_1} \cdots \partial_{\nu_s}(f)|_{x=P}
\]
as $s \ge 0$ and $\nu_1,\ldots,\nu_s$ varies over all sequences in $V$. So in this case we can identify the coalgebra ${!} V \otimes_{\mathbb{R}} \mathbb{C}$ with the space of distributions on $V$ with finite support.

In the semantics of differential linear logic defined using finiteness spaces \cite{ehrhard-finiteness} and convenient vector spaces \cite{blutecon} the space ${!} V$ is a closure of the linear span of Dirac distributions (in our notation, $\ket{\emptyset}_P$) on $V$. More precisely, if $V$ is a finite-dimensional convenient vector space then ${!} V$ consists of distributions of compact support, which are obtained as limits of Dirac distributions. For example, see \cite[Theorem 5.7]{blutecs} for the limit defining the distribution $\ket{v}_0$ in our notation. There is a very similar role for Dirac distributions in the Coherent Banach space semantics of linear logic in \cite[\S 3.2]{girard_banach}. 

It is interesting to note that functional programs extended with Dirac distributions have already been considered in the literature on automatic differentiation; see \cite{nilsson}. For an abstract categorical theory of distributions via monads, see \cite{kock}.
\end{remark}

\begin{remark}
Any cocommutative coalgebra is the direct limit of finite-dimensional coalgebras, and the category of finite-dimensional cocommutative coalgebras is isomorphic to the category of zero-dimensional schemes over $k$. This is taken as the starting point of one approach to noncommutative geometry which has been influential in the study of $A_\infty$-algebras, where one posits that an arbitrary coalgebra is the coalgebra of distributions on a ``noncommutative space'' \cite[p.15]{kontnc}, \cite{kontnc2, lebruyn}.
\end{remark}

\begin{remark}\label{remark:justify}
Definition \ref{defn:D} is justified as follows: adding $\nu$ to a ket, under the residue, contributes a partial derivative in the direction of $\nu$ by \eqref{eq:residue_differentiates2}. Stating this in a different way, observe that there is a canonical map $\iota: V \lto \cat{D}(R)$ sending $\nu \in V$ to the differential operator $\partial_\nu$ and we have a $k$-linear map
\be
\xymatrix@C+2pc{
H^n_P(R, \Omega^n_{R/k}) \otimes V \ar[r]^-{1 \otimes \iota} & H^n_P(R, \Omega^n_{R/k}) \otimes \cat{D}(R) \ar[r]^-{a} & H^n_P(R, \Omega^n_{R/k})
}
\ee
where $a$ denotes the action of the ring $\cat{D}(R)$ on local cohomology \cite[Lemma 2.7]{murfet_coalg}. These maps assemble in the colimit \eqref{eq:otherbangV} to give \eqref{defn:DV}.
\end{remark}

\bibliographystyle{amsalpha}
\providecommand{\bysame}{\leavevmode\hbox to3em{\hrulefill}\thinspace}
\providecommand{\href}[2]{#2}


\end{document}