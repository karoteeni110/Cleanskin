\begin{abstract}


%\ignore{Based on this notion, we propose an ODC framework that could be applied to various kernel machines, \eg Gaussian Process Regression(GPR)  and Twin Gaussian Processes (TGP). The framework was evaluated on POSER, Human Eva and Human3.6M datasets. The results indicate accurate and fast prediction are  achieved by the proposed framework on both GPR and TGP. We also achieved quadratic prediction complexity for TGP instead of cubic complexity in prior work. }
%\ignore{Regression in large scale systems has been a very challenging task with many applications in pattern recognition and computer vision.} In this paper, we present the Overlapping Domain Cover (ODC) notion for kernel machines, as a set of overlapping subsets of the data that covers the entire training set and optimized to be spatially cohesive as possible. We showed the value of this notion for overlapping local kernel machines for regression in terms of speed and accuracy. \ignore{Adopting this notion,} We propose an ODC framework that reduces the computational complexity of \ignore{the local scheme in} Twin Gaussian Processes (TGP) regression from cubic to quadratic in the number of points in the local kernel machine. Our ODC framework also is scalable in the number of dimensions of the input domain which is a limitation is some method in the literature. It is also applicable to other  regression methods (\eg   Gaussian Process Regression(GPR) and IWTGP regression), as shown in our experiments. We validated and analyzed the parameters of our framework on three Human 3D pose estimation datasets and interesting findings are been discussed.

%\ignore{
%In this paper, we present the Overlapping Domain Cover (ODC) notion for kernel machines, as a set of overlapping subsets of the data that covers the entire training set and optimized to be spatially cohesive as possible. We showed the value of this notion in local kernel machines for regression in terms of speed and accuracy. We propose an ODC framework that reduces the computational complexity of Twin Gaussian Processes (TGP) regression from cubic to quadratic in the number of points in the local kernel machine. Our ODC framework also is scalable in the number of dimensions of the input domain which is a limitation is some method in the literature. It is also applicable to other  regression methods (\eg   Gaussian Process Regression(GPR) and IWTGP regression), as shown in our experiments. We validated and analyzed the parameters of our framework on three Human 3D pose estimation datasets and interesting findings are  discussed.}

We present the Overlapping Domain Cover (ODC) notion for kernel machines, as a set of overlapping subsets of the data that covers the entire training set and optimized to be spatially cohesive as possible. We show how this notion benefit the speed of local kernel machines for regression in terms of both speed while achieving while minimizing the prediction error. We propose an efficient ODC framework, which is applicable to various regression models and in particular reduces the complexity of Twin Gaussian Processes (TGP) regression from cubic to quadratic. Our notion is also applicable to several kernel methods (\eg   Gaussian Process Regression(GPR) and IWTGP regression, as shown in our experiments). We also theoretically justified the idea behind our method to improve local prediction by the overlapping cover. We validated and analyzed our method on three benchmark human pose estimation datasets and interesting findings are discussed.  

%Section 4, presents an idea of how to build a domain decomposition TGP 

\end{abstract}