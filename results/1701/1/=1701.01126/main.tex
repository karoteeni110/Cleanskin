%!TEX program = pdflatex
%
% File naaclhlt2016.tex
%

\documentclass[11pt,letterpaper]{article}
\usepackage{coling2016}
\usepackage{times}
\usepackage{latexsym}

\usepackage{amsmath}
\usepackage{amssymb,amsmath,epsfig}
\usepackage{bbm}
\usepackage{cprotect}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage[position=b]{subcaption}

\usepackage{color}
\usepackage{tablefootnote}
\usepackage{calc}
\usepackage{array}
\usepackage[export]{adjustbox}
\usepackage{url}
%\makesavenoteenv{tabular}
%\makesavenoteenv{table}
%\naaclfinalcopy % Uncomment this line for the final submission
%\def\naaclpaperid{688} %  Enter the naacl Paper ID here

% To expand the titlebox for more authors, uncomment
% below and set accordingly.
% \addtolength\titlebox{.5in}    

\newcommand\BibTeX{B{\sc ib}\TeX}



\input{defs}

\title{Textual Entailment with Structured Attentions and Composition}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}
% If the title and author information does not fit in the area allocated,
% place \setlength\titlebox{<new height>} right after
% at the top, where <new height> can be something larger than 2.25in
\author{Kai Zhao \and Liang Huang \and Mingbo Ma \\
School of Electrical Engineering and Computer Science \\ 
Oregon State University \\ Corvallis, Oregon, USA \\
{\tt \{kzhao.hf, lianghuang.sh, cosmmb\}@gmail.com}}

\date{}

\begin{document}

\maketitle

\vspace{-0.35in}
\begin{abstract}
Deep learning techniques are increasingly popular 
in the textual entailment task, % is witnessing a burgeoning
%interest in leveraging the generalization power of 
%deep learning techniques
overcoming the fragility of traditional discrete models with hard alignments and logics.
In particular, the recently proposed attention models 
\cite{rocktaschel2015reasoning,wang2015learning} achieves state-of-the-art accuracy by
computing soft word alignments between %words
the premise and hypothesis sentences.
However, there remains a major limitation:
this line of work completely ignores syntax and recursion,
%outperforming traditional models with sparse features. % on a large dataset.
%However, syntactic trees, 
which is helpful in many traditional efforts.
%is completely ignored in this line of work.
We show that it is beneficial to extend the attention model 
to tree nodes between premise and hypothesis.
More importantly, this subtree-level
attention reveals information about entailment relation.
We study the recursive composition of this subtree-level entailment relation,
%and propose to combine the attention calculation and the entailment
%composition,
which can be viewed as a soft version of 
the Natural Logic framework
\cite{maccartney2009extended}.
Experiments show that our structured attention and
entailment composition model can correctly identify and infer
entailment relations from the bottom up,
and bring significant improvements in accuracy.
\end{abstract}


\section{Introduction}
\label{sec:intro}
\input{intro}


\section{Structured Attentions \& Entailment Composition}
\label{sec:model}
\input{attention}

\iffalse
\section{Structured Tree Entailment}
\label{sec:entailment}
\input{entailment}
\fi

\section{Review: Recursive Tree Meaning Representations}
\label{sec:treelstm}
\input{treelstm}

\section{Empirical Evaluations}
\label{sec:exp}
\input{exp}

\iffalse
\section{Discussion}
\label{sec:disc}
\input{disc}
\fi

\section{Conclusion}
\label{sec:conclusion}
We have presented an approach to model the composition
of the entailment relation following the tree structure for the sentence entailment task. We adapted the attention model
for tree structures. Experiments show that
our model bring significant improvements in accuracy,
and is easy to interpret.

\section*{Acknowledgments}
We thank the anonymous reviewers for helpful comments.
We are also grateful to James Cross, Dezhong Deng, and Lemao Liu for suggestions.
This project was supported in part
by NSF IIS-1656051, DARPA FA8750-13-2-0041
(DEFT), and a Google Faculty Research Award.

\bibliography{entailment}
\bibliographystyle{acl}


\end{document}
