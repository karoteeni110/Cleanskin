0 0.6235 ,cor corresponding author,c,e,august,n,shapes arrows,arrows shapes,o,k,results,f f,ge,preface,68q 68q,economics theory,submitted to proceedings of the national academy of sciences of the united states of america,received,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper
1 0.5371 d,all,figures,sort compress,l,w,figs,matrix,march,the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest,summary,kamienna pl bia ystok poland,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,the nonlinear inverse problem is characterized by a quadratic nonlinearity when using the scheme with linearization the nonlinear term is approximated with the first order with respect to it is possible to apply the linearized scheme of second order let us consider the approximation approximation of equation with the boundary conditions using the crank-nicolson scheme yields the linearized scheme the scheme belongs to the class of linearized schemes in comparison with the scheme it has a higher order of accuracy in time to implement we again use the decomposition in this case for we have the auxiliary function is defined as the solution of the equation further as in the case of the first-order scheme we employ the crank-nicholson scheme for numerical solving the direct problems for parabolic equations is not very often used in computational practice it is inferior to the fully implicit scheme in sense of conservation of monotonicity fulfilment of the maximum principle for the grid problem it has poor asymptotic properties for solving problems with large integration time and it is not unconditionally sm-stable scheme for this reason it is appropriate to consider another variant of linearization of this inverse problem where the second-order approximation is applied only for the nonlinear term in this case instead of we put the numerical implementation of the scheme is performed in the standard way using the decomposition,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,to demonstrate possibilities of the above linearization schemes for solving the problem of the identification of the lower coefficient of the parabolic equation we consider a 2d model problem in the examples below we put the problem is considered on a triangular grid which consists of nodes triangles and is shown in fig here is the trapezoid with the vertices coordinates the calculations were carried out for the coefficient is taken in the form the solution of the direct problem at the observation point is depicted in fig it was otained using the fully implicit scheme with different time steps the solution at the final time moment is presented in fig the results of solving the inverse problem with variuos grids in time are shown in fig the solution of the direct problem obtained with is used as the input data the function in the condition it is easy to see that the approximate solution of the inverse problem converges with decreasing the time step these results were obtained using the first-order scheme numerical results obtained for the above problem using the second-order scheme are shown in fig for the discontinuous right-hand side we observe characteristic wiggles of the identified coefficient such oscillations of the approximate solution are typical for the scheme if the desired solution the coefficient is smooth then the effect of using the second-order approximation is clearly expressed as an example we present the results of numerical solving the inverse problem where the lower coefficient the exact solution has the form the approximate solution obtained via the first-order scheme is shown in fig whereas fig demonstrates the computations conducted by means of the second-order scheme
2 0.3538 s,and,the authors declare no competing financial interests,g,nolistsep,let then,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme
3 0.3515 appendix,f,cor corresponding author tel,shapes,tomoyuki yamakami,suffix,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation,in this section we describe the family of cuts that we will use when defining our embedding into these are cuts that we call monotone and intuitively correspond to sets that only cross every ray at most once we also describe a specific shifting operation that will allow us to modify a cut in order to adapt to the finer geometry of a given space let be a pyramid with basepoint and let we say that is monotone or monotone when is clear from the context if and for any ray in is a prefix of in particular this implies that is a connected subgraph see figure let be a monotone cut we define the vertex boundary of denoted by to be the set of all such that all children of are not in we also define the edge boundary of denoted by to be finally we define the graph see figure let be a pyramid let be the skeleton of let and then we denote by the set of all vertices such that is an ancestor of in and let be a monotone cut let and let with let be a decomposition of with and for any we define a partition by setting and we define the odd shift of to be the cut given by similarly we define the even shift of to be the cut given by we say that a cut is a shift of if it is either the odd or the even shift of see figure for an example,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches
4 0.3120 0pt,arrows automata,related work,tabular,discussion sec discussion,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme
5 0.3026 m,input output,matrix frame arrow arc ps dvips c,gnore,design languages,smallskip,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,label this work was supported by rfbr project,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,in this section we describe the family of cuts that we will use when defining our embedding into these are cuts that we call monotone and intuitively correspond to sets that only cross every ray at most once we also describe a specific shifting operation that will allow us to modify a cut in order to adapt to the finer geometry of a given space let be a pyramid with basepoint and let we say that is monotone or monotone when is clear from the context if and for any ray in is a prefix of in particular this implies that is a connected subgraph see figure let be a monotone cut we define the vertex boundary of denoted by to be the set of all such that all children of are not in we also define the edge boundary of denoted by to be finally we define the graph see figure let be a pyramid let be the skeleton of let and then we denote by the set of all vertices such that is an ancestor of in and let be a monotone cut let and let with let be a decomposition of with and for any we define a partition by setting and we define the odd shift of to be the cut given by similarly we define the even shift of to be the cut given by we say that a cut is a shift of if it is either the odd or the even shift of see figure for an example,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,zz jr
6 0.2992 cm,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,keywords smart grid simulation network flow,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,after the overview on the range of functionalities of the different power system simulators we apply four of them to the same problem and compare the results we selected four of the simulators from table matpower psat interpss and gridlab-d we used the ieee bus test case to perform power flow analysis this exemplary power system scenario is publicly available in the ieee common data format the input files exist for many simulators including matpower psat with simulink and gridlab-d the provided files have been used for the simulation the demonstrated interpss results originate from the interpss loadflow study guide this test case is frequently used in studies five of fourteen buses are at high nominal value and nine at middle voltages nominal value one at figure shows the results of the power flow analyses of the four simulators the top two charts show the four bus variables the predefined ones in a black square busses with generators are marked with a bold g branches containing a transformer with a t in figure a the bus voltages in multiples of the nominal value and voltage angles are shown the psat angle values of the middle voltage buses are slightly below the matching others figure b depicts the total active power and reactive power for all busses the high and middle voltage busses are separated and have different scales the convention for shown data is power producers with positive and consumers with negative sign deviating values can only be seen for the reactive power of bus six the power values for load busses are given figure c shows the absolute values of transmitted active and reactive power in each branch for interpss no data are available see conclusion gridlab-d provides only the complex line current the lines transmitted power is calculated from the from-bus-voltage and the conjugate line current according to the branches are in order of ascending bus numbers while active power results are quite consistent those for reactive power show the highest variation between the simulators the results of the four simulators match quite well in average but nevertheless there are marked differences in some areas the provided files and used models are not absolutely equal which could cause the differences at specific points we found the following examples phase shift of transformers is not included in all simulators and psat assumes five degrees at the branch from bus four to nine an additional reactive load is included at bus nine of the gridlab-d model the pf calculation needs an iterative solver most programs use newton-raphson while gridlab-d uses the gauss-seidel method the branches transmitted power is calculated from the analysis results and calculation methods for this differ,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,65j 65m
7 0.2989 arrows,a,abstract,fig,program summary,long write-up,arrows automata shapes,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,in this section we show that non-positively curved planar metrics can be embedded with constant-distortion into a certain type of unweighted planar graphs that we call funnels intuitively a funnel is obtained by taking the union of a tree having all its leaves at the same level with a collection of cycles where every cycle spans all the vertices in a single layer of the tree let be an unweighted planar graph and let we say that is a funnel with basepoint if the following conditions are satisfied there exists a collection of pairwise vertex-disjoint cycles such that for notational convenience we allow a cycle to consist of a single vertex in which case it has no edges moreover we have we refer to each as a layer of for every the graph has exactly two connected components one with vertex set and another with vertex set for every every has exactly one neighbor we refer to as the parent of in particular is the parent of all vertices in for every every has at least one neighbor we refer to every such as a child of let be a path in between and a vertex we say that is a ray we denote by the family of all funnel graphs figure depicts an example of a funnel we will use the following two facts about metric spaces of non-positive curvature see e.g let be a geodesic metric space of non-positive curvature let and let be a geodesic between and then the function with is convex let be a geodesic metric space of non-positive curvature and let let be a geodesic between and and let be a geodesic between and then the function with is non-decreasing recall that for a metric space and some an net in is a maximal subset such that for any we have let be a simply-connected surface and let be a non-positively curved metric on let be a finite set of points then admits an embedding into a funnel with constant distortion by scaling we may assume w.l.o.g that the minimum distance in is at least note that scaling results into a metric which is still of non-positive curvature let be an arbitrary point for any let denote the unique geodesic between and let for any integer let since is non-positively curved we have that for every the set is a disk see e.g let be the cycle in bounding let let be an net in note that since is non-positively curved there exists a unique geodesic between any pair of points this implies that the subspace is a simplicial tree for every we define an net of as follows suppose that is already defined let be the set of points such that intersects let note that for any there exists such that therefore we can set to be a maximal subset such that is an net this concludes the definition of the sequence of subsets note that we define a graph with the set of edges is defined as follows for every we add a unit-length edge for any two points such that and appear consecutively in a clockwise traversal of moreover for every let be such that let be the point in the intersection of with if then we add the unit-length edge otherwise let be the first point in that we visit in a clockwise traversal of starting from we add the unit-length edge edge this concludes the definition of the graph it is straightforward to check that is a funnel with basepoint we can now define an embedding by mapping every points to its nearest neighbor in it remains to verify that has constant distortion observe that the set contains a net in and therefore for any we have since the minimum distance in is at least this implies that is an injection and for any we have it therefore suffices to show that for any we have we first show that for any we have to that end it suffices to show that for any edge we have we consider first case where there exists such that and are consecutive in let be the arc of between and that does not contain any other points in by the triangle inequality there exists such that and since is an net in it follows that there exists such that let be the geodesic between and the arc intersects either or assume w.l.o.g that it intersects at some points by lemma we have that as we travel along the distance to is a convex function this implies that we conclude that next we consider the case where and for some let be the point where intersects arguing as above we have that therefore this concludes that proof that for any edge we have and therefore for any we have it remains to show that for any we have we consider first the case where there exists such that the case is trivial since contains only let be a geodesic between and by lemma we have let be the unique point in and let be the unique point in by lemma we have let be the parent of and let be the parent of in let be the points in that appear between and along for any pick a child of with and for any the curve intersects by the above discussion we have that the distance between any two such consecutive intersection points is therefore the path in that visits the vertices in this order has length and therefore next we consider the case where there exists such that and this case is identical to the case above by replacing with we therefore also obtain in this case finally we consider the case of arbitrary points let be the geodesic between and the curve can be decomposed into consecutive segments such that every such segment is contained in the closure of for some consider such a segment there exists with and such that and let be the nearest neighbor of in and let be the nearest neighbor of in since is a net for and is a net for we have by the above analysis we have therefore we obtain we conclude that as required,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,in this section we describe the family of cuts that we will use when defining our embedding into these are cuts that we call monotone and intuitively correspond to sets that only cross every ray at most once we also describe a specific shifting operation that will allow us to modify a cut in order to adapt to the finer geometry of a given space let be a pyramid with basepoint and let we say that is monotone or monotone when is clear from the context if and for any ray in is a prefix of in particular this implies that is a connected subgraph see figure let be a monotone cut we define the vertex boundary of denoted by to be the set of all such that all children of are not in we also define the edge boundary of denoted by to be finally we define the graph see figure let be a pyramid let be the skeleton of let and then we denote by the set of all vertices such that is an ancestor of in and let be a monotone cut let and let with let be a decomposition of with and for any we define a partition by setting and we define the odd shift of to be the cut given by similarly we define the even shift of to be the cut given by we say that a cut is a shift of if it is either the odd or the even shift of see figure for an example,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches
8 0.2966 and or,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,keywords smart grid simulation network flow,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,after the overview on the range of functionalities of the different power system simulators we apply four of them to the same problem and compare the results we selected four of the simulators from table matpower psat interpss and gridlab-d we used the ieee bus test case to perform power flow analysis this exemplary power system scenario is publicly available in the ieee common data format the input files exist for many simulators including matpower psat with simulink and gridlab-d the provided files have been used for the simulation the demonstrated interpss results originate from the interpss loadflow study guide this test case is frequently used in studies five of fourteen buses are at high nominal value and nine at middle voltages nominal value one at figure shows the results of the power flow analyses of the four simulators the top two charts show the four bus variables the predefined ones in a black square busses with generators are marked with a bold g branches containing a transformer with a t in figure a the bus voltages in multiples of the nominal value and voltage angles are shown the psat angle values of the middle voltage buses are slightly below the matching others figure b depicts the total active power and reactive power for all busses the high and middle voltage busses are separated and have different scales the convention for shown data is power producers with positive and consumers with negative sign deviating values can only be seen for the reactive power of bus six the power values for load busses are given figure c shows the absolute values of transmitted active and reactive power in each branch for interpss no data are available see conclusion gridlab-d provides only the complex line current the lines transmitted power is calculated from the from-bus-voltage and the conjugate line current according to the branches are in order of ascending bus numbers while active power results are quite consistent those for reactive power show the highest variation between the simulators the results of the four simulators match quite well in average but nevertheless there are marked differences in some areas the provided files and used models are not absolutely equal which could cause the differences at specific points we found the following examples phase shift of transformers is not included in all simulators and psat assumes five degrees at the branch from bus four to nine an additional reactive load is included at bus nine of the gridlab-d model the pf calculation needs an iterative solver most programs use newton-raphson while gridlab-d uses the gauss-seidel method the branches transmitted power is calculated from the analysis results and calculation methods for this differ,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,65j 65m
9 0.2959 h,hc,x,automata,xxxx,arrows calc,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,label this work was supported by rfbr project
10 0.2767 r,theorem,proof,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,label this work was supported by rfbr project,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,in this section we describe the family of cuts that we will use when defining our embedding into these are cuts that we call monotone and intuitively correspond to sets that only cross every ray at most once we also describe a specific shifting operation that will allow us to modify a cut in order to adapt to the finer geometry of a given space let be a pyramid with basepoint and let we say that is monotone or monotone when is clear from the context if and for any ray in is a prefix of in particular this implies that is a connected subgraph see figure let be a monotone cut we define the vertex boundary of denoted by to be the set of all such that all children of are not in we also define the edge boundary of denoted by to be finally we define the graph see figure let be a pyramid let be the skeleton of let and then we denote by the set of all vertices such that is an ancestor of in and let be a monotone cut let and let with let be a decomposition of with and for any we define a partition by setting and we define the odd shift of to be the cut given by similarly we define the even shift of to be the cut given by we say that a cut is a shift of if it is either the odd or the even shift of see figure for an example,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme
11 0.2681 ff,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,65j 65m,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,label this work was supported by rfbr project,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem
12 0.2662 design algorithms performance,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,65j 65m,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,label this work was supported by rfbr project,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem
13 0.2645 t,68r,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,label this work was supported by rfbr project,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,in this section we describe the family of cuts that we will use when defining our embedding into these are cuts that we call monotone and intuitively correspond to sets that only cross every ray at most once we also describe a specific shifting operation that will allow us to modify a cut in order to adapt to the finer geometry of a given space let be a pyramid with basepoint and let we say that is monotone or monotone when is clear from the context if and for any ray in is a prefix of in particular this implies that is a connected subgraph see figure let be a monotone cut we define the vertex boundary of denoted by to be the set of all such that all children of are not in we also define the edge boundary of denoted by to be finally we define the graph see figure let be a pyramid let be the skeleton of let and then we denote by the set of all vertices such that is an ancestor of in and let be a monotone cut let and let with let be a decomposition of with and for any we define a partition by setting and we define the odd shift of to be the cut given by similarly we define the even shift of to be the cut given by we say that a cut is a shift of if it is either the odd or the even shift of see figure for an example,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme
14 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
15 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
16 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
17 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
18 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
19 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
20 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
21 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
22 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
23 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
24 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
25 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
26 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
27 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
28 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
29 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
30 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
31 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
32 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
33 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
34 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
35 0.2636 major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
36 0.2626 v,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,65j 65m
37 0.2607 ieee,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,65j 65m
38 0.2584 case,let,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,after the overview on the range of functionalities of the different power system simulators we apply four of them to the same problem and compare the results we selected four of the simulators from table matpower psat interpss and gridlab-d we used the ieee bus test case to perform power flow analysis this exemplary power system scenario is publicly available in the ieee common data format the input files exist for many simulators including matpower psat with simulink and gridlab-d the provided files have been used for the simulation the demonstrated interpss results originate from the interpss loadflow study guide this test case is frequently used in studies five of fourteen buses are at high nominal value and nine at middle voltages nominal value one at figure shows the results of the power flow analyses of the four simulators the top two charts show the four bus variables the predefined ones in a black square busses with generators are marked with a bold g branches containing a transformer with a t in figure a the bus voltages in multiples of the nominal value and voltage angles are shown the psat angle values of the middle voltage buses are slightly below the matching others figure b depicts the total active power and reactive power for all busses the high and middle voltage busses are separated and have different scales the convention for shown data is power producers with positive and consumers with negative sign deviating values can only be seen for the reactive power of bus six the power values for load busses are given figure c shows the absolute values of transmitted active and reactive power in each branch for interpss no data are available see conclusion gridlab-d provides only the complex line current the lines transmitted power is calculated from the from-bus-voltage and the conjugate line current according to the branches are in order of ascending bus numbers while active power results are quite consistent those for reactive power show the highest variation between the simulators the results of the four simulators match quite well in average but nevertheless there are marked differences in some areas the provided files and used models are not absolutely equal which could cause the differences at specific points we found the following examples phase shift of transformers is not included in all simulators and psat assumes five degrees at the branch from bus four to nine an additional reactive load is included at bus nine of the gridlab-d model the pf calculation needs an iterative solver most programs use newton-raphson while gridlab-d uses the gauss-seidel method the branches transmitted power is calculated from the analysis results and calculation methods for this differ,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,65j 65m
39 0.2584 b,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,label this work was supported by rfbr project,65j 65m,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation
40 0.2554 cor corresponding author tel fax,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,label this work was supported by rfbr project,65j 65m,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation
41 0.2523 figure,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,after the overview on the range of functionalities of the different power system simulators we apply four of them to the same problem and compare the results we selected four of the simulators from table matpower psat interpss and gridlab-d we used the ieee bus test case to perform power flow analysis this exemplary power system scenario is publicly available in the ieee common data format the input files exist for many simulators including matpower psat with simulink and gridlab-d the provided files have been used for the simulation the demonstrated interpss results originate from the interpss loadflow study guide this test case is frequently used in studies five of fourteen buses are at high nominal value and nine at middle voltages nominal value one at figure shows the results of the power flow analyses of the four simulators the top two charts show the four bus variables the predefined ones in a black square busses with generators are marked with a bold g branches containing a transformer with a t in figure a the bus voltages in multiples of the nominal value and voltage angles are shown the psat angle values of the middle voltage buses are slightly below the matching others figure b depicts the total active power and reactive power for all busses the high and middle voltage busses are separated and have different scales the convention for shown data is power producers with positive and consumers with negative sign deviating values can only be seen for the reactive power of bus six the power values for load busses are given figure c shows the absolute values of transmitted active and reactive power in each branch for interpss no data are available see conclusion gridlab-d provides only the complex line current the lines transmitted power is calculated from the from-bus-voltage and the conjugate line current according to the branches are in order of ascending bus numbers while active power results are quite consistent those for reactive power show the highest variation between the simulators the results of the four simulators match quite well in average but nevertheless there are marked differences in some areas the provided files and used models are not absolutely equal which could cause the differences at specific points we found the following examples phase shift of transformers is not included in all simulators and psat assumes five degrees at the branch from bus four to nine an additional reactive load is included at bus nine of the gridlab-d model the pf calculation needs an iterative solver most programs use newton-raphson while gridlab-d uses the gauss-seidel method the branches transmitted power is calculated from the analysis results and calculation methods for this differ,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,65j 65m
42 0.2512 extended abstract,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,label this work was supported by rfbr project,65j 65m,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation
43 0.2495 the authors would like to thank,this section is optional it is a location for you to acknowledge grants funding editing assistance and what have you in the present case for example the authors would like to thank gerald murray of acm for his help in codifying this author s guide and the cls and tex files that it describes,this paragraph will end the body of this sample document remember that you might still have acknowledgments or appendices brief samples of these follow there is still the bibliography to deal with and we will make a disclaimer about that here with the exception of the reference to the latex book the citations in this paper are to articles which have nothing to do with the present subject and are used as examples only,acm proceedings latex text tagging,the rules about hierarchical headings discussed above for the body of the article are different in the appendices in the appendix environment the command section is used to indicate the start of each appendix with alphabetic order designation i.e the first is a the second b etc and a title if you include one so if you need hierarchical structure within an appendix start with subsection as the highest level here is an outline of the body of this document in appendix-appropriate form this section is inserted by latex you do not insert it you just add the names and information in the additionalauthors command at the start of the document generated by bibtex from your bib file run latex then bibtex then latex twice to resolve references to create the bbl file insert that bbl file into the tex source file and comment out the command thebibliography,extended abstract a full version of this paper is available as author s guide to preparing acm sig proceedings using latex and bibtex at www.acm.org eaddress.htm,the conclusion goes here,michael shell biography text here,q,john doe biography text here,jane doe biography text here,appendix one text goes here,appendix two text goes here,plain,conf yymonth d d 20yy city st country 20yy nnnn-nnnn-n yy mm nnnnnnn.nnnnnnn,fb,the acm proc article-sp document class file itself is chock-full of succinct and helpful comments if you consider yourself a moderately experienced to expert user of latex you may find reading it useful but please remember not to change it,typically the body of a paper is organized into a hierarchical structure with numbered or unnumbered headings for sections subsections sub-subsections and even smaller sections the command section that precedes this paragraph is part of such a hierarchy latex handles the numbering and placement of these headings for you when you use the appropriate heading commands around the titles of the headings if you want a sub-subsection or smaller part to be unnumbered in your output simply append an asterisk to the command name examples of both numbered and unnumbered headings will appear throughout the balance of this sample document because the entire article is contained in the document environment you can indicate the start of a new paragraph with a blank line in your input file that is why this sentence forms a separate paragraph we have already seen several typeface changes in this sample you can indicate italicized words or phrases in your text with the command textit emboldening with the command textbf and typewriter-style for instance for computer code with texttt but remember you do not have to indicate typestyle changes when such changes are part of the structural elements of your article for instance the heading of this subsection will be in a sans serif typeface but that is handled by the document class file take care with the use of the curly braces in typeface changes they mark the beginning and end of the text that is to be in the different typeface you can use whatever symbols accented characters or non-english characters you need anywhere in your document you can find a complete list of what is available in the latex user s guide you may want to display math equations in three distinct styles inline numbered or non-numbered display each of the three are discussed in the next sections a formula that appears in the running text is called an inline or in-text formula it is produced by the math environment which can be invoked with the usual begin end construction or with the short form you can use any of the symbols and structures from to available in latex this section will simply show a few examples of in-text equations in context notice how this equation set here in in-line math style looks slightly different when set in display style see next section a numbered display equation one set off by vertical space from the text and centered horizontally is produced by the equation environment an unnumbered display equation is produced by the displaymath environment again in either environment you can use any of the symbols and structures available in latex this section will just give a couple of examples of display equations in context first consider the equation shown as an inline equation above notice how it is formatted somewhat differently in the displaymath environment now we ll enter an unnumbered equation and follow it with another numbered equation just to demonstrate latex s able handling of numbering citations to articles conference proceedings or books listed in the bibliography section of your article will occur throughout the text of your article you should use bibtex to automatically produce this bibliography you simply need to insert one of several citation commands with a key of the item cited in the proper location in the tex file the key is a short reference you invent to uniquely identify each work in this sample document the key is the first author s surname and a word from the title this identifying key is included with each item in the bib file for your article the details of the construction of the bib file are beyond the scope of this sample document but more information can be found in the author s guide and exhaustive details in the latex user s guide this article shows only the plainest form of the citation command using cite this is what is stipulated in the sigs style specifications no other citation format is endorsed because tables cannot be split across pages the best placement for them is typically the top of the page nearest their initial cite to ensure this proper floating placement of tables use the environment table to enclose the table s contents and the table caption the contents of the table itself must go in the tabular environment to be aligned properly in rows and columns with the desired horizontal and vertical rules again detailed instructions on tabular material is found in the latex user s guide immediately following this sentence is the point at which table is included in the input file compare the placement of the table here with the table in the printed dvi output of this document to set a wider table which takes up the whole width of the page s live area use the environment table to enclose the table s contents and the table caption as with a single-column table this wide table will float to a location deemed more desirable immediately following this sentence is the point at which table is included in the input file again it is instructive to compare the placement of the table here with the table in the printed dvi output of this document like tables figures cannot be split across pages the best placement for them is typically the top or the bottom of the page nearest their initial cite to ensure this proper floating placement of figures use the environment figure to enclose the figure and its caption this sample document contains examples of eps and ps files to be displayable with latex more details on each of these is found in the author s guide as was the case with tables you may want a figure that spans two columns to do this and still to ensure proper floating placement of tables use the environment figure to enclose the figure and its caption note that either ps or eps formats are used use the epsfig or psfig commands as appropriate for the different file types other common constructs that may occur in your article are the forms for logical constructs like theorems axioms corollaries and proofs there are two forms one produced by the command newtheorem and the other by the command newdef perhaps the clearest and easiest way to distinguish them is to compare the two in the output of this sample document this uses the theorem environment created by the newtheorem command let be continuous on if is an antiderivative for on then the other uses the definition environment created by the newdef command definitiondefinition if is irrational then by we mean the unique number which has logarithm two lists of constructs that use one of these forms is given in the author s guidelines and don t forget to end the environment with figure not figure there is one other similar construct environment which is already set up for you i.e you must not use a newdef command to create it the proof environment here is a example of its use suppose on the contrary there exists a real number such that then which contradicts our assumption that complete rules about using these environments and using the two different creation commands are in the author s guide please consult it for more detailed instructions if you need to use another construct not listed therein which you want to have the same formatting as the theorem or the definition shown above use the newtheorem or the newdef command respectively to create it because you have just been given permission to use the newdef command to create a new form you might think you can use tex s def to create a new command please refrain from doing this remember that your latex source code is primarily intended to create camera-ready copy but may be converted to other forms e.g html if you inadvertently omit some or all of the def s recompilation will be to say the least problematic,banner above paper title short description of paper,computer society ieeetran journal latex paper template
44 0.2480 p,05c 05c,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,65j 65m
45 0.2382 i,algorithms theory,65j 65m,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,keywords smart grid simulation network flow,label this work was supported by rfbr project,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem
46 0.2359 indent 2em,primary 05c secondary 05c,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we put forward a general classification for a structural description of the entanglement present in compound entities experimentally violating bell's inequalities making use of a new entanglement scheme that we developed recently our scheme although different from the traditional one is completely compatible with standard quantum theory and enables quantum modeling in complex hilbert space for different types of situations namely situations where entangled states and product measurements appear customary quantum modeling and situations where states and measurements and evolutions between measurements are entangled nonlocal box modeling nonlocal non-marginal box modeling the role played by tsirelson's bound and marginal distribution law is emphasized specific quantum models are worked out in detail in complex hilbert space within this new entanglement scheme,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,keywords smart grid simulation network flow,65j 65m,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section
47 0.2343 10pt 0pt 10pt 0pt 10pt 0pt,3cm 3cm 3cm 3cm,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,the nonlinear inverse problem is characterized by a quadratic nonlinearity when using the scheme with linearization the nonlinear term is approximated with the first order with respect to it is possible to apply the linearized scheme of second order let us consider the approximation approximation of equation with the boundary conditions using the crank-nicolson scheme yields the linearized scheme the scheme belongs to the class of linearized schemes in comparison with the scheme it has a higher order of accuracy in time to implement we again use the decomposition in this case for we have the auxiliary function is defined as the solution of the equation further as in the case of the first-order scheme we employ the crank-nicholson scheme for numerical solving the direct problems for parabolic equations is not very often used in computational practice it is inferior to the fully implicit scheme in sense of conservation of monotonicity fulfilment of the maximum principle for the grid problem it has poor asymptotic properties for solving problems with large integration time and it is not unconditionally sm-stable scheme for this reason it is appropriate to consider another variant of linearization of this inverse problem where the second-order approximation is applied only for the nonlinear term in this case instead of we put the numerical implementation of the scheme is performed in the standard way using the decomposition
48 0.2262 px,general terms algorithms theory,this work was supported by dong-a university research fund,categories and subject descriptors i computing methodologies symbolic and algebraic manipulations algebraic algorithms,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,label this work was supported by rfbr project,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,if are metric spaces and is injective the distortion of is defined to be where for any metric space we use to denote the distortion of i.e the infimum over all numbers such that admits an embedding into with distortion for a graph we write where ranges over all shortest-path metrics supported on and for a family of graphs we write thus for a family of finite graphs if and only if every geometry supported on a graph in embeds into with distortion at most in the seminal works of linial-london-rabinovich and later aumann-rabani and gupta-newman-rabinovich-sinclair the geometry of graphs is related to the classical study of the relationship between flows and cuts a multi-commodity flow instance in is specified by a pair of non-negative mappings and we write for the value of the maximum concurrent flow in this instance which is the maximal value such that can be simultaneously routed between every pair while not violating the given edge capacities a natural upper bound on is given by the sparsity of any cut where is the indicator function for membership in we write for the maximum gap between the value of the flow and the upper bounds given by over all multi-commodity flow instances on this is the multi-commodity max-flow min-cut gap for the fundamental connection between embeddings into and multi-commodity flows is captured in the following result for every graph in particular combined with the techniques of this implies that for any graph there exists a approximation for the general sparsest cut problem it has been shown by that for general graphs and there has since been a lot of effort in trying to prove that is bounded by some universal constant for interesting classes of graphs the most well-known open case is the so-called planar embedding conjecture summarized in the following for every planar graph despite several attempts on resolving this question there has only been very little progress more specifically the work of okamura seymour implies that the metric induced on a single face of a planar graph embeds with constant distortion into in it is shown that for any series-parallel or outerplanar graph this result was extended to outerplanar graphs in chakrabarti et al obtained constant distortion embeddings of graphs that exclude a minor note that even the case of planar graphs of treewidth remains open we remark that the best-known upper bound on for planar graphs is due to rao while the best-known lower bound is due to lee raghavendra gupta newman rabinovich and sinclair posed the following generalization of the planar embedding conjecture which seeks to characterize the graph families such that which by theorem also characterizes all graphs with multi-commodity gap bounded by some universal constant for every family of finite graphs one has if and only if forbids some minor we note that a strengthening of the gnrs conjecture for integral multi-commodity flows has also been considered this is a seemingly harder problem and progress has been even more limited in this case at first glance it might appear that the gnrs conjecture is a vast generalization of the planar embedding conjecture since planar graphs exclude as a minor despite this lee sidiropoulos have shown that the gnrs conjecture is equivalent to the conjunction of the planar embedding conjecture with the manifestly simpler sum embedding conjecture summarized bellow for a graph family let denote the closure of under clique sums see for a more detailed exposition we note that the case is folklore while recently progress has been reported for the case by lee and poore even for however the problem remains open for any family of graphs we have if and only if for every it is therefore apparent that the planar embedding conjecture is a major step towards determining the multi-commodity gap in arbitrary graphs all previous attempts on the planar embedding conjecture have been topological in nature meaning that they seek to obtain constant-distortion embeddings by restricting the topology of the planar graph as a consequence all known methods are insufficient even for planar graphs of treewidth we depart from this paradigm by instead restricting the geometry of the planar metric for any metric we have that is the shortest-path metric of a planar graph if and only if it can be realized as a set of points in a simply-connected i.e planar surface we say that a planar metric is non-positively curved if it can be realized as a set of points in a surface of non-positive curvature see section for the definition of non-positively curved spaces this leads to a natural and very rich class of planar metrics for instance non-positively curved planar metrics include all trees all regular grids up to constant distortion and arbitrary subsets of the hyperbolic plane our main result is as follows there exists a universal constant such that every non-positively curved planar metric admits an embedding into with distortion at most since we are motivated by the applications of metric embeddings in computer science we will restrict our discussion to finite metrics we remark however that our result can be extended to obtain constant-distortion embeddings of arbitrary simply-connected surfaces of non-positive curvature into we note that embeddings of various hyperbolic spaces have been previously considered we refer to however none of the previous results captures embeddings of arbitrary non-positively curved planar metrics in fact our approach is significantly different than all previous works we now give an informal and somewhat imprecise overview of some of the main challenges that we face when trying to embed non-positively curved planar metrics into let be a metric space we will use the standard representation of as the cone of cut pseudo-metrics see section for the definition this means that in order to embed a space into with constant distortion it suffices to find a probability distribution over cuts such that the probability that any pair of points gets separated is for some normalization factor it follows by the work of lee and raghavendra see also that when seeking a constant-distortion embedding of certain spaces into it suffices to consider distributions over a specific type of cuts called monotone more precisely let be a fixed point we say that a cut is monotone w.r.t if every shortest path starting from crosses at most once let us say that a metric space is a bundle if there exist two points such that for every point there exists an geodesic containing then it is shown in that a bundle admits a constant-distortion embedding into if and only if it is a convex combination of monotone cuts i.e a convex combination of cut pseudo-metrics where every indicator set is a monotone cut it is easy to show that every finite non-positively curved metric admits an isometric embedding into a bundle we can therefore focus our efforts into finding a good distribution over monotone cuts it is convenient to demonstrate the main ideas using the following example of a pinched square let endowed with the euclidean distance the space can be embedded isometrically into by taking an appropriate distribution over random half-plane cuts e.g by choosing a uniformly random point and taking the half-plane supported by a line passing through forming a uniformly random angle with the axis let be one of the sides of and let be the quotient space obtained by contracting into a single point which we will refer to as the basepoint strictly speaking the resulting is not a space of non-positive curvature in particular there exist pairs of points in with two distinct geodesics joining them however admits a constant-distortion embedding into a planar surface of non-positive curvature so in order to simplify the exposition we may use without loss of generality it is fairly easy to see that even though might look like a triangle its geometry is far from that of a flat euclidean triangle in fact one can show that cannot be embedded into the euclidean plane with bounded distortion as a consequence embedding into requires a significantly more involved distribution over cuts such a distribution can be constructed using cuts of the following form for every we have a family of cuts that are contained inside the ball of radius from the basepoint and with boundary given by a function of period roughly speaking these cuts can be obtained by random shifts along the axis of cuts from the following infinite family here the probability of a cut decreases when it is important to note that the structure of a cut depends on the distance of its boundary to the basepoint it can be shown that this is the case for any constant distortion embedding of into moreover in an constant-distortion embedding this transition has to happen in a smooth way as suppose now that we modify the space as follows let be a ray in i.e an unbounded geodesic starting at the basepoint and let be a suffix of cutting along introduces two copies of as segments of the boundary we glue a copy of along as follows the resulting space again embeds with constant distortion into a planar metric of non-positive curvature constructing a constant-distortion embedding for requires the use of even more intricate families of cuts intuitively a single cut now has to gracefully combine information form multiple different scales let be the basepoints of the two copies of in the structure of a typical cut has to depend on the distances between and both and a naive way to address this problem would be to define a distribution over cuts for every single scale and then try to combine them into a single distribution the problem with this approach is that cuts from different scales in our example cuts for the two different copies of might not agree on their boundary this disagreement results in larger distortion every time we combine two different scales since there can be many scales this methods leads to unbounded distortion we overcome this obstacle by designing a distribution over cuts that is scale-independent this is done by starting with a distribution over cuts that handles large distances and gradually modifying it to handle smaller scales the main technical contribution of this paper is showing that in a non-positively curved surface this can be done without increasing the distortion we now review some basic definitions and notions which appear throughout the paper let and let we denote by the subgraphs of induced by i.e we will consider graphs with every edge having a non-negative length we say that a graph is unweighted if all of its edges have unit length let denote the diameter of i.e we refer to a path between two vertices as a path a cut of a graph is a partition of into we sometimes refer to a subset as a cut as well a cut gives rise to a pseudometric using indicator functions we can write the cut pseudometric as a central fact is that embeddings of finite metric spaces into are equivalent to sums of positively weighted cut metrics over that set for a simple proof of this see a cut measure on is a function for which for every every cut measure gives rise to an embedding for which where the integral is over all cuts conversely to every embedding we can associate a cut measure such that holds we will describe our proof using the definition of non-positive curvature in the sense of busemann we give here a brief overview of some of the relevant terminology and we refer the reader to for a more detailed exposition a metric space is called geodesic if for every pair of points there exists a geodesic joining them we say that is non-positively curved if for any pair of affinely parameterized geodesics the map defined by is convex as we show this property is sufficient to obtain constant-distortion embeddings of simply-connected surfaces into let be a metric space a distribution over partitions of is called lipschitz if every partition in the support of has only clusters of diameter at most and for every we denote by the infimum such that for any the metric admits a lipschitz random partition and we refer to as the modulus of decomposability of the following theorem is due to klein plotkin and rao and rao for any planar graph we have a mapping between two metric spaces and is non-contracting if for all if is any finite metric space and is a family of finite metric spaces we say that admits a stochastic embedding into if there exists a random metric space and a random non-contracting mapping such that for every the infimal such that holds is the distortion of the stochastic embedding for a graph and a graph family we write to denote the fact that stochastically embeds into a distribution over graphs in with distortion we also use the notation to denote the fact that for some universal constant we will use the following fact let be a family of graphs such that every admits an embedding into with distortion at most let be a graph such that for some then admits an embedding into with distortion at most let be a graph and let the dilation of is defined to be for two graphs a sum of with is a graph obtained by taking two disjoint copies of and and identifying a vertex with a vertex for a graph family we denote by the closure of under sums let be a graph and let be a graph with and let be the corresponding modulus of decomposability then there exists a graph family such that where and every graph in is a sum of isometric copies of the graphs and the rest of the paper is organized as follows in section we show how to embed an arbitrary non-positively curved planar metric into an unweighted graph of special structure called a funnel in section we show how to stochastically embed a funnel into a distribution over simpler graphs called pyramids in section we introduce some of the machinery that we will use when defining our embedding into more specifically we describe the basic operation of cuts that will allow to gradually modify a cut when computing our embedding using this machinery we describe our embedding in section finally in section we prove that the constructed embedding has constant distortion,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,we can store in space such that rank queries on the path between any two nodes take a total of time we compute the heavy-path decomposition of and store time rank data structures for each of the heavy paths which takes space the path between any two nodes and is a sequence of intervals of heavy paths given and for each of these intervals we compute the number of white nodes in that interval and to either side of it in the heavy path this takes a total of time and rank queries on heavy paths with this information we can perform any rank query on the path from to using a single rank query on a heavy path we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time we store the adjacency lists for s nodes with each list ordered such that black neighbours precede white neighbours with this representation we can expand a subgraph by adding only black nodes as long as this is possible using time per added node let be a connected subgraph of size with white nodes we store pointers to the white nodes in which takes space since is a tree we can find the unique paths between these nodes in a total of time notice these paths are contained in and consist of black nodes if the subgraph consisting of the white nodes and these paths has fewer than nodes then we add black nodes until it has nodes which takes a total of time it is possible to add enough black nodes without adding any white nodes because e.g we could add the remaining black nodes in,major challenges for the transition of power systems do not only tackle power electronics but also communication technology power market economy and user acceptance studies simulation is an important research method therein as it helps to avoid costly failures a common smart grid simulation platform is still missing we introduce a conceptual model of agents in multiple flow networks flow networks extend the depth of established power flow analysis through use of networks of information flow and financial transactions we use this model as a basis for comparing different power system simulators furthermore a quantitative comparison of simulators is done to facilitate the decision for a suitable tool in comprehensive smart grid simulation,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,the inverse problem of determining the pair of is nonlinear the standard approach is based on the simplest approximations in time and involves the iterative solution of the corresponding nonlinear problem for the evaluation of the approximate solution at a new level in our work we apply such approximations in time that lead to linear problems for evaluating the solution at the new time level let us define a uniform grid in time and denote finite element approximations in space are employed in the polygon we perform a triangulation and introduce for this computational grid a finite-dimensional space of finite elements using the fully implicit scheme for approximation in time we obtain the following variational problem the additional relations and take the form to evaluate at the new time level the approximate solution from or some iterative procedures are necessary in solving time-dependent problems the solution slightly varies when it pass from the previous time level to the next one this basic feature of time-dependent problems is widely used in numerical solving nonlinear problems through the application of linearization procedures we use a similar approach for the numerical solution of the inverse problem that is concerned with the identification of the lower coefficient of a parabolic equation instead of we will solve the following equation in this case the lower coefficient of the parabolic equation is taken at the upper time level whereas the approximate solution is treated at the previous time level let us consider the solution procedure of the problem in detail for the approximate solution at the new time level we introduce the following decomposition to find we employ the equation the function is determined from using the decomposition equation holds automatically for any to evaluate we apply the condition or the substitution of into yields the fundamental point of applicability of this algorithm is associated with the condition the auxiliary function is determined from the grid elliptic equation the property of having fixed sign for is followed in particular from the same property of the solution at the previous time level such constraints on the solution can be provided by the corresponding restrictions on the input data of the inverse problem in any case this problem requires special and careful consideration in this paper we assume that the constraint is satisfied in solving problem instead of we have under the condition that in this case additional restrictions are formulated on the function e.g its fixed sign in thus the computational algorithm for solving the inverse problem or based on the linearized scheme or involves the solution of two standard grid elliptic equations for the auxiliary functions equation and equation the further evaluation of from or and the final calculation from the relation
49 0.2017 the theorem is proved,set,the lemma is proved,the power grid has started its transition towards the smart grid this development increases the level of complexity in the energy system arising from the integration of distributed and renewable energy resources smart meters smart appliances and electric vehicles ev etc into the electrical grid for this reason researchers of different fields are investigating a variety of topics related to the smart grid such as dynamic price markets demand response smart meters or prediction models since the operation of a power grid is usually vital for its users opportunities for testing novel approaches are very limited therefore to evaluate the impact of new methods for future smart grids simulation has to be used most of the current simulators for smart grid scenarios originate in simulation of electric power systems control circuits or agent based markets recently development trends towards cross discipline simulations as the research field is broad it is hard to decide whether a particular simulator fits the whole smart grid system or only parts of it in this paper we answer the following questions regarding a simulator for the complete smart grid system what areas should a smart grid simulator cover which functionalities do current simulators provide how congruent are their results to answer the first question a generic model is introduced which is based on power system simulation and additionally considers two reliable circumstances firstly the smart grid optimizes energy distribution through the use of more specific information and secondly power markets are expected to manage the alignment of power demand with the current production through pricing the proposed model is based on a combination of an agent-based approach with electrical power flow flow of data in the ict network and flow of payments through the financial transaction network after sketching the desirable state of smart grid simulation we identify scopes of operation for several power system simulators available free of charge finally four of the simulators are quantitatively compared by applying them to a common test case of power flow analysis this article provides an overview and results of a discussion on simulation design for smart grids and facilitates the decision of which tools and models to be used in future research the model including agents and flow networks is described in the next section the third section contains a comparison of ten different simulators for power systems four of those are subjects of the quantitative comparison by means of a test-case in the succeeding part of the paper finally we give our conclusion,mathematical modeling of many applied problems of science and engineering results in the numerical solution of inverse problems inverse problems often belong to the class of ill-posed conditionally correct problems and therefore various regularization algorithms are employed to solve them numerically particular attention should be given to inverse problems for pdes in this case a theoretical study includes the fundamental questions of uniqueness of the solution and its stability both from the viewpoint of the theory of differential equations and from the viewpoint of the theory of optimal control for distributed systems many inverse problems are formulated as non-classical problems for pdes to solve these problems approximately emphasis is on the development of stable computational algorithms that take into account peculiarities of inverse problems among inverse problems for pdes we distinguish coefficient inverse problems which are associated with the identification of coefficients and or the right-hand side of an equation using some additional information when considering time-dependent problems the identification of the coefficient dependences on space and on time is usually separated into individual problems in some cases we have linear inverse problems e.g identification problems for the right-hand side of an equation this situation essentially simplify their study much attention is paid to the problem of determining the lower coefficient of a parabolic equation of second order where in particular the coefficient depends on time only an additional condition is most often formulated as a specification of the solution at an interior point or as the average value integrated over the whole domain the existence and uniqueness of the solution of such an inverse problem and well-posedness of this problem in various functional classes are examined for example in the works numerical methods for solving the problem of the identification of the lower coefficient of parabolic equations are considered in many works in view of the practical use we highlight separately studies dealing with numerical solving inverse problems for multidimensional parabolic equations to construct computational algorithms for the identification of the lower coefficient of a parabolic equation there is widely used the idea of transformation of the equation by introducing new unknowns that results in a linear inverse problem in this paper for a multidimensional parabolic equation we consider the problem of determining the lower coefficient that depends on time only approximation in space is performed using standard finite elements the main features of the nonlinear inverse problem are taken into account via a proper choice of the linearized approximation in time linear problems at a particular time level are solved on the basis of a special decomposition into two standard elliptic problems the paper is organized as follows in section for a parabolic equation of second order we formulate the inverse problem of the identification of the lower coefficient the computational algorithm based on the linearization scheme is described in section section presents possibilities of the schemes with the second-order approximation in time numerical results for a model 2d inverse problem are discussed in section,for simplicity we restrict ourselves to a 2d problem generalization to the 3d case is trivial let and be a bounded polygon the direct problem is formulated as follows we search such that it is the solution of the parabolic equation of second order the boundary and initial conditions are also specified where is the normal to the formulation presents the direct problem where the right-hand side coefficients of the equation as well as the boundary and initial conditions are specified let us consider the inverse problem where in equation the coefficient is unknown an additional condition is often formulated as where is a weight function in particular choosing where is the dirac function from we get we assume that the above inverse problem of finding a pair of from equations and additional conditions or is well-posed the corresponding conditions for existence and uniqueness of the solution are available in the above-mentioned works in this paper we consider only the numerical solution of these inverse problems omitting theoretical issues of the convergence of an approximate solution to the exact one from the nonlinear inverse problem we can proceed to the linear one suppose then from we get the additional conditions and to identify uniquely take the form the above transition from the nonlinear inverse problem to the linear one is in common use for numerical solving problems of identification in our work we focus on the original formulation of the inverse problem or without going to the linear problem,inverse problem control parameter parabolic partial differential equation finite element approximation difference scheme,we consider how to index strings trees and graphs for jumbled pattern matching when we are asked to return a match if one exists for example we show how given a tree containing two colours we can build a quadratic-space index with which we can find a match in time proportional to the size of the match we also show how we need only linear space if we are content with approximate matches,the power grid represents the current state of the system evolving towards the smart grid the simulation of electricity systems is a traditional field in engineering that distinguishes between dynamic and static power system analysis today s simulation software typically performs various analyses within that field as well as in related areas the software tools used originate either in simulation of power grids control circuits or agent-based markets commercial software developers therefore provide a variety of software packages those are mostly costly highly specialized and hard to modify thus are less suitable for research and or teaching we compare several freely available power system simulators as listed by the ieee task force on open source software for power systems and assess their potential capabilities in terms of the agents in multiple flow networks approach table contains a list of functionalities provided by ten different power system simulators we listed their major features and assigned them to different areas which are related to the three flow networks the areas and the abbreviations of the functionalities are explained in table the tables do not contain the simple dc-pf the dc-opf is commonly used for economical analysis to optimize welfare or benefit in accordance with a power system as it is much easier to solve it is more frequently-used than the ac version of opf the cpf analysis is used to determine the maximum load condition of a grid the 3p-pf calculates each phase of the power system instead of a aingle-phase equivalent circuit especially for asymmetric and two-phase loads the gained accuracy is worth the higher calculation effort all the power flow analyses are static or quasi-static e g in ames where twenty-four hourly values within a day are used faster processes e g transient simulation are covered under power dynamics within sa several forms of stability analysis are considered voltage and small signal stability as well as outage scenarios and short circuit simulation the plc of gridlab-d is simple programmable and assigned to the controlled device the com-links between plc-objects are specified by reliability bit rate and timeout all the energy market simulations provide different options for market rules which are not listed as separate functions in table market simulations typically use abm which is a separate feature in table the first two and oldest simulators listed in table uwpflow and tefts are designed for static and dynamic power system analysis the four simulators in the second group from matpower to matdyn are running in the mathwork matlab environment matpower is a package of matlab m-files intended as a simulation tool for researchers and educators it is easy to use and modify from the matlab-console as well as free and open source apart from the required matlab license matdyn provides dynamic power system analysis and can be seen as a completion of matpower ipsys is a scripting tool used to define manipulate and analyze electrical power systems data of a prescribed format a user can interact with single or multiple power system models through the ipsys shell a matlab interface or by using a gui psat is a gnu octave-based toolbox for electric power system analysis psat has further features like phasor measurement unit placement eigenvalue analysis facts models wind turbine models and conversion of data files it is one of the most complete freely available power system simulators with a comprehensive gui and gne in simulink the last four simulators in the list go beyond pure power system simulation the ames market package is an extensible and modular agent-based framework for studying wholesale power markets it is developed entirely in java and provides output reports through table and chart displays the hourly time steps and neglect of reactive power i e transmission losses are weaknesses but while the learning tool for agents is a clear innovation interpss is an open-source project mainly in java aimed at developing a simple to use yet powerful software system for design analysis and simulation of power systems its open and loosely coupled system architecture allows for easy import and export of components currently the project seems ill-maintained the opendss is the open source distribution system simulator dss of the electric power research institute in california its heritage is from general purpose power system harmonics analysis tools and is now a comprehensive electrical power system simulator analyses are done exclusively in frequency domain the gic analysis is really special within the presented simulators the program includes a scripting interface but it is mainly used through the provided dynamic-link library by other software e g matlab gridlab-d is a flexible simulation environment that can be integrated with a variety of third-party data management and analysis tools the core algorithm coordinates the states of millions of independent devices at its simplest gridlab-d examines in detail the interplay of every part of a distribution system with every other gridlab-d does not require the use of reduced-order models for the aggregate behavior of consumer or electrical systems the import module for climate data is a unique feature the scripting language is particularly designed for that software the development of the ongoing smart grid transition also affect simulation software as noticeable in table the distribution system is greater detailed by recent simulators the modeling paradigm changes and well-defined differential equation models get enriched e g by agent based modeling stochastic models or game theoretic approaches the simulators interconnect with other disciplines primarily to economics but also to ict systems implementation of other forms of energy or climate data are other further examples the code of recent simulation software is more modular and easier to integrate into other programs in some cases researchers still design their own software especially for development of alternative methods or for very new and specific problems the mosaik simulation framework is an example where only existing simulators are recombined to a new simulation framework an advanced gui makes the simulators accessible for researchers of different fields,this work is supported by the carinthian economic promotion fund kwf under grant project smart microgrid lab we would like to thank lizzie dawes for proofreading the paper,in this section we present our most technical result which is how to store in space an approximate index for a tree containing only two colours again an approximate match is one whose parikh vector differs from s by a factor of at most in each component in contrast with lemma we would use space without loss of generality assume we are only concerned with multisets in which there are at least as many black nodes as white nodes we can build a symmetric index for the other case notice that in this case if we can find a connected subgraph with the same size as the given multiset and in which the number of white nodes is within a factor of of the number in then the number of black nodes in is also within a factor of of the number in our main idea is to store an space data structure with which given a size we can find two connected subgraphs with size that have approximately the minimum and maximum numbers of white nodes suppose we store a subgraph with the minimum number of white nodes for each size that is a power of two and for each size such that the minimum number of white nodes is a factor of greater than the number in the preceding stored subgraph that is we store a sequence of subgraphs with total size and a sequence of subgraphs with total size the latter sequence of subgraphs has total size in the worst case because the minimum number of white nodes may stay low until we reach size nearly and then increase rapidly causing us to store about subgraphs each of size nearly however we can store this sequence of subgraphs in a total of space using the following lemma which we prove in appendix similarly we also store a subgraph with the maximum number of white nodes for each size that is a power of two and for each size such that the maximum number of white nodes is a factor of greater than the number in the preceding stored subgraph this also takes total space if we store the subgraphs with the following lemma we can store in space such that if contains a connected subgraph of size with white nodes then we can represent some such subgraph in space such that recovering this subgraph takes time if we are given a multiset such that we have subgraphs of size sampled then we can proceed as in the proof of theorem and find an exact match if there is one if we do not have subgraphs of size sampled then we use our sampled subgraphs to build subgraphs and of size with approximately minimum and maximum numbers of white nodes then proceed almost as in the proof of theorem if the number of white nodes is larger but within a factor of of the number in then we return if the number in is more than a factor of larger than the number in then there is no exact match and we return nothing if the number of white nodes is smaller but within a factor of of the number in then we return if the number in is less than a factor of smaller than the number in then there is no exact match and we return nothing in all other cases we proceed as in theorem to build we take the next larger subgraph with a minimum number of white nodes and discard nodes until it has size while leaving it connected this next larger subgraph has size less than because we sampled for every size that is a power of two has at most times more white nodes than the subgraph of size with the minimum number of white nodes because we sampled whenever the minimum number of white nodes increased by a factor of and is a tree because it is a connected subgraph of a tree it follows that discarding nodes takes time and since discarding nodes cannot increase the number of white nodes contains at most times the minimum number of white nodes to build we take the next smaller subgraph with a maximum number of white nodes and add nodes until it has size by symmetric arguments this takes time and since adding nodes cannot decrease the number of white nodes the maximum number of white nodes in a subgraph of size is at most times the number in finding the path from to takes time using the representation from lemma when is a tree containing only two colours for any positive constant we can build an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in,in the theory and practice of inverse problems for partial differential equations pdes much attention is paid to the problem of the identification of coefficients from some additional information this work deals with the problem of determining in a multidimensional parabolic equation the lower coefficient that depends on time only to solve numerically a nonlinear inverse problem linearized approximations in time are constructed using standard finite element procedures in space the computational algorithm is based on a special decomposition where the transition to a new time level is implemented via solving two standard elliptic problems the numerical results presented here for a model 2d problem demonstrate capabilities of the proposed computational algorithms for approximate solving inverse problems,suppose is a binary string i.e if there are copies of in and copies of in then for every value between and there is a position between and such that contains copies of this observation was the basis for the index in and is the basis for ours as well we store an time rank data structure for and for we store the endpoints of two substrings of length in with the most and with the fewest copies of this takes a total of space given a parikh vector we look up the left endpoints and of the substrings of length in with the most and with the fewest copies of we set and as the initial endpoints for a binary search at each step we use two rank queries to find the number of 1s in if then we stop and report this substring by its endpoints if then we set and continue if then we set and continue this search takes a total of time when is a path containing only two colours we can build an space index with which we can find a match in time,suppose is a graph containing a constant number of colours and we will be given as the vector of length whose components are the frequencies of the characters which is called the parikh vector for since there are possible multisets of size and it takes space to store pointers to a match for such a multiset there exists an space index with which we can find a match in time when has bounded treewidth we can build this index in polynomial time and we can reduce the space bound to at the cost of increasing the query time to to do the latter we store itself and pre-compute and store pointers to matches only for multisets of size at most given a multiset with we search in time for any positive constant we can build an space approximate index with which if has an exact match then in time we can find a substring whose parikh vector differs from s by at most a factor of in each component this index does not tell us whether has an exact match however since we may find such a substring even when it does not without loss of generality assume we are concerned only with multisets in which each character appears at least once we can reduce the general case to instances of this one we store a dimensional grid with each side having length for each point in this grid we store pointers to the nodes in a connected subgraph whose parikh vector is between and this takes a total of space given the parikh vector of we return the subgraph stored for the point in the grid if that subgraph exists we summarize these basic tradeoffs in the following lemma when is a graph containing a constant number of colours there exists an space index with which we can find a match in time for any positive constant there exists an space index with which in time we can find an approximate match in which each colour s frequency is within a factor of of its frequency in when has bounded treewidth we can build these indexes in polynomial time and moreover we can reduce the space of the exact index to at the cost of increasing the query time to when is a path which we can think of as a string over an alphabet of characters we can improve these bounds since contains substrings and we can specify any substring by its two endpoints we can build an space index with which we can find a match in time calculation shows we can reduce the space bound to at the cost of increasing the query time to and we can store an approximate index in space in appendix we show how in expected time we can build an index with which we can find all matches of in time as an aside we note that we can extend our approximate indexes to support approximate scaled-then-permuted pattern matching see to do this for each point in the grid for which there is no subgraph whose parikh vector is between and we store pointers to the nodes in a connected subgraph if there is one whose parikh vector is a multiple of a one between and the query time is still proportional to the size of the match returned but that may now be larger than,suppose is a string over a constant-size alphabet and then in expected time we can build an index with which given a multiset of characters we can find all matches of in worst-case time to do this we store itself and for we make a pass over and store for each multiset of size that has a match in a list of all the locations of that multiset s matches notice the lists for multisets of size are disjoint and have total length therefore with dynamic perfect hashing we use a total of expected time and space given a multiset with we return our pre-computed list of the locations of matches in time or time if we are given as a parikh vector given a multiset with we search in time,suppose is a tree containing only two colours black and white gagie hermelin landau and weimann noted that the observation in section can be extended to connected graphs if there are connected subgraphs and in with nodes each and and white nodes respectively then for every value between and there is a connected subgraph with nodes and white nodes to see why notice that we can construct a sequence of connected subgraphs with nodes such that the sequence starts with and ends with and any consecutive pair of subgraphs in the sequence differ on two nodes to build this sequence we find a path between and we root and which are trees themselves at the first and last nodes in the path or at a shared node if they are not disjoint one by one we remove nodes bottom-up in and add nodes along the path remove nodes nearest to in the path and add nodes further along the path then remove nodes from the path and add nodes top-down in suppose and are the minimum and maximum numbers of white nodes in any connected subgraphs of size and we store a path consisting of the nodes in in bottom-up order followed by the nodes in the path followed by the nodes in in top-down order if we apply theorem to this path then we obtain an space index with which given the parikh vector for a multiset with we can find a match in the graph in time notice that if then we can simply store an space lookup table with which we can find a match in time therefore applying this construction for we obtain the following theorem when is a tree containing only two colours we can build an space index with which we can find a match in time when we need space to store subgraphs with the minimum and maximum numbers of white nodes and the path between them when however those subgraphs are small and most of the space is taken up by the path we now claim we can store such that we can support fast rank queries on paths due to space constraint we leave the proof to appendix we can store in space such that rank queries on the path between any two nodes take a total of time if we store with lemma and store subgraphs with the minimum and maximum numbers of white nodes only for then our index takes only space but supports queries only for when we can use an algorithm by gagie et al to find a match in time when is a tree containing only two colours we can build an space index with which we can find a match in time when and in time otherwise,suppose we are given a connected graph on coloured nodes and a multiset of colours and asked to find a connected subgraph of whose nodes colours are exactly those in if such a subgraph exists even when is a tree there can be exponentially many such matching subgraphs when is a path however there are matches and we can find them all in time when is a path containing a constant number of colours in time we can build a space index with which we can determine in time whether there is a match when is a path containing only two colours in time we can build an bit index with which we can determine in time whether there is a match it follows that in time we can build an index of size bits with which we can find all the matches using worst-case time per match we can build an approximation of this index in time with the quality of the approximation depending on throughout this paper our model is the word-ram with bit words and we measure space in words unless stated otherwise determining whether there is a match is np-complete even when is a tree or when it contains only two colours but takes polynomial time when both has bounded treewidth and contains only a constant number of colours when contains only two colours there exists an bit index with which we can determine in time whether there is a match building this index is np-hard in general but since finding a match is self-reducible takes polynomial time when has bounded treewidth and time when is a tree at the cost of increasing the space to words this index can be generalized to return a subset of the nodes in the matches that is also a hitting set for all the matches using time worst-case time per match in the worst case however this subset of nodes is of little use in finding even a single complete match we start by presenting some basic tradeoffs in section in sections to we assume contains only two colours in section we consider the case when is a path i.e a binary string and describe an space index with which we can find a match in time in section we consider the case when is a tree and based on our index for binary strings describe an space index with which we can find a match in time if we are concerned only with multisets of size at most then we can reduce the space bound to in section we show that we can achieve the same space bound if we are content with approximate matches in the full version of this paper we will partially extend our results to graphs by working on spanning trees,the overall goal of a smart grid is to contribute to greater efficiency reliability and environmental sustainability in energy usage which requires the best possible alignment of power generation power consumption and limited storage capabilities such an alignment impacts user behavior cultural habits social norms power markets climate conditions and many other factors we propose a model that combines agent-based simulation and the notion of network flows a power system can be easily represented by a network model as in power flow simulation in the smart grid this model is extended by the flow of data in the ict network and the flow of payment through the financial transaction network the agents are decision making entities that interact with each other through the three different types of networks energy information and payment flow networks the following example helps to explain this idea to the reader let us imagine a simple smart grid scenario that includes the following entities a consumer a grid operator and a smart meter an electric vehicle ev and a switching device electrical power is transmitted from the smart meter energized by the grid operator through the switch into the storage of the ev information is transmitted by the consumer who controls the switch and connects the ev the consumer is informed by the ev about its energy demand by the smart meter about the current energy price and the switch about its state further information flows from the smart meter to the grid operator the payment flow from the consumer to the grid operator is based on billing information this simple example demonstrates that the three networks of flow i e energy information and payment are tightly interwoven a node within the corresponding network modifies the flow and can be involved in a second or third type of flow network an agent is a super node that merges several nodes from different flow networks and tries to optimize its the super node s individual utility function the consumer in the example is an agent who controls the switch including the ev the user also pays for the energy and receives information from various sources the second agent is the grid operator the operator is the recipient of the payment flow and controller of the smart meter figure depicts a more general example which considers a random power system from generation to consumer it includes five agents connected by the three flow networks the three networks are depicted by different node-symbols circles for energy hexagons for information and diamonds for payment flow each agent is associated with its controlled nodes marked by dashed lines in this case not all nodes are associated with an agent the agents form the main interconnection between the different flow networks they use all their controlled nodes to maximize their utility function measurement processes are links from an energy node to the information network functioning as an information source the opposite applies to control processes which use information this complex model of agents in multiple flow networks is generic it helps to structure and classify problems concerning the smart grid and can be scaled to any type of subsystem it is applicable on all layers from intercontinental transmission lines to household devices the model can be extended by integrating other flow networks e g the gas distribution system it is also feasible to extend the model by including evaluation of measured data each agent optimizes its utility function within its available scope of actions the utility function could be anything fitting properly into a mathematical formalism for example the reduction of costs and or maximization of profit are common for agents in an economic environment the optimization of the overall welfare is an alternative form of utility function the regular agents in a smart gird are consumers producers service providers such as grid operators and combinations of these roles within the proposed flow networks the agents control a set of nodes and agents interact with each other through flow of any type any type of social relation is not covered a complex network consists of a set of nodes interconnected by edges also called links any flow defined as the amount of media transferred per unit of time is a directed link connecting its emitter node with its receiver node the weight of the link is given by the strength of flow e g the electrical power data rate etc according to the characteristics of the flowing media and the physical network apply different constraints which are used for calculations the flow of type from a node to a node in a physical network is always limited by the capacity of its infrastructure the index includes all flow types for which the equation is valid such as energy information and payment if transmission is assumed to be lossless and the media is incompressible the flow is antisymmetric the total flow depends on the type of a node i.e whether a node is a source a sink of flow or a transmission node for a transmission node without any storage capabilities the total flow is zero further possible constraints are out of scope of this paper the principal measures in an ac grid are complex values of voltage and current for scales above transient time it is sufficient to deal with the active and reactive power or the complex apparent power network models are established in power systems engineering e g in combination with kirchhoff s law the power flow analysis is based on them and is a common method to estimate the power distribution and voltage levels in a grid modern power grid management uses much ict infrastructure which itself relies on appropriate power supply information flow can be modeled as metadata containing a sender a receiver and a transmission time the only constraints refer to minimal time and maximal capacity for transmission any processor of information or data is a node in the network identified by its address such generic models also used in information theory typically consider logical connections between nodes disregarding physical wiring nevertheless it is much harder to capture information flow in a more coherent way than in terms of electrical power one reason is that information is not well defined here it is used very generally without definition of knowledge and data the information flow is defined by data transmission rate the fact that data can be easily stored and replicated any number of times leads to different structures and flow dynamics of the information network the real ict infrastructure is highly structured and based on many technologies diverging in data rates used osi layers protocol standards transmission quality and media many control circuits in the power grid keep it working properly they are not part of an information flow network a scada system forms a clear interface between power and information flow networks in general each measurement or control process connects the information flow with the power flow network and ict usage is on progress in power system technology a node in the finance transaction network is an account that accumulates the payment flow over time the payment flow results from transferring an amount of money from the sender s to the receiver s account there is no physical transmitted media so all the losses arise from finance transaction fees and the costs of accounting the payment flow is antisymmetric and the nodes have no theoretical limit of storage capacity the maximum transmission is limited by the state of the sender s account the agent s utility function includes the state of the account the legislative system gives constraints for bilateral contracts and energy market rules those agreements constrain all financial transactions the payment flow is a simple and clearly defined way to track activities of and dependencies between agents assuming all activities of power system agents happen in an economic context all financial transactions require secure ict,with the model of agents in multiple flow networks we spanned a framework for a more complete view on the complex topic smart grid and its simulation this principal model is suitable for extension and more detailed itemization adaptable technically both to specific cases and helpful in simulation and model building we used it as a benchmark to compare ten free power system simulators whereof four are also quantitatively compared six simulators deal mainly with power system problems in different time domains functions for abm or information and payments flow are not supported in those simulators psat is the most complete of them including a comprehensive gui and chart display functions and would be a suggested first choice for power system engineering students implementation in a wider simulation environment seems possible with the command-line version matpower could work as a simpler power system component in a broader matlab based simulation platform the other four which are the newer ones come with information and or payment-flow features ames is only suitable for market simulation user model adaption and expansions to information and energy-flow would need extensive java development interpss might be comprehensive through the provided functions open structure the gui and support of user models unfortunately the source does not seem to be up to date and we could not run it openpss provides good functionalities in all fields except market simulation and is easy usable by other software with the program download comes extensive documentation including examples the development of gridlab-d is progressing its current state is illustrated by the tutorial slides including exercises the distributed modeling approach makes it different but the software can match up to traditional power system analysis all model coding and data management is until now in the user s responsibility users are expected to be researchers or developers finally the choice of the simulator depends on the research questions to be answered and possible existing simulation tools to combine with the comparison of operation area and power flow analysis simplifies the selection of a proper research tool for smart grid simulation engineers as well as economists politicians and social scientists strive for their maybe different approaches,the nonlinear inverse problem is characterized by a quadratic nonlinearity when using the scheme with linearization the nonlinear term is approximated with the first order with respect to it is possible to apply the linearized scheme of second order let us consider the approximation approximation of equation with the boundary conditions using the crank-nicolson scheme yields the linearized scheme the scheme belongs to the class of linearized schemes in comparison with the scheme it has a higher order of accuracy in time to implement we again use the decomposition in this case for we have the auxiliary function is defined as the solution of the equation further as in the case of the first-order scheme we employ the crank-nicholson scheme for numerical solving the direct problems for parabolic equations is not very often used in computational practice it is inferior to the fully implicit scheme in sense of conservation of monotonicity fulfilment of the maximum principle for the grid problem it has poor asymptotic properties for solving problems with large integration time and it is not unconditionally sm-stable scheme for this reason it is appropriate to consider another variant of linearization of this inverse problem where the second-order approximation is applied only for the nonlinear term in this case instead of we put the numerical implementation of the scheme is performed in the standard way using the decomposition
