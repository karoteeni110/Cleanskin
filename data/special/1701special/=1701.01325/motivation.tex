\section{Introduction}
\label{sec:motivation}
 The problem of outlier detection is that of finding data points
 which are unusually different from the  rest of the data set.
 Such outliers are also variously referred to as anomalies, deviants,
 discordants or abnormalities in the data. Since outliers  correspond to
 unusual observations, they are often of interest to the analyst in
 finding interesting anomalies in the underlying generating process.
 \pagebreak
 The problem of
 outlier analysis is applicable to a wide variety of domains such as
 machine monitoring, financial markets, environmental modeling and
 social network analysis. 
Correspondingly, the problem has been studied in the context of
different data types which arise in these domains, such as
multidimensional data, spatial data, and discrete sequences.
Numerous books and surveys have been written on the problem
 of outlier detection \cite{outlierbook,chandola,chandola2,hawkins}.

In this paper, we will study the problem of text outlier analysis.
The problem of text outlier analysis has become increasingly
important because of the greater prevalence of web-centric and
social media applications, which are rich in text data. Some
important applications of text outlier analysis are as follows:
\begin{itemize}
\item {\em Web Site Management:} An unusual page from a set of
articles in a web site may be flagged as an outlier. The knowledge
of such outliers may be used for web site management.
\item  {\em Sparse High Dimensional Data:} While the methods
discussed in this paper have text applications in mind, they can be
used for other sparse high dimensional domains. For example, such
methods can be used for market basket data sets. Unusual
transactions  may sometimes provide an idea of fraudulent behaviour.
\item {\em News Article Management:}   It is often desirable to
determine unusual news article from a collection of news documents. An
unusual news from a group of articles may be flagged as an
interesting outlier.
\end{itemize}
While text is an extremely important domain from the perspective of
outlier analysis, there are surprisingly few methods which are {\em
specifically focused}  on this domain, even though many generic
methods such as distance-based methods can be easily adapted to this
domain \cite{knorr,rama}, and are often used for text outlier
analysis. Domains such as text are particularly challenging for the
 problem of outlier analysis, because of their sparse high
 dimensional nature, in which only a small fraction of the words
 take on non-zero values.  Furthermore, many  words in a document
 may  be  topically irrelevant to the context of the document and add to the noise in the
 distance computations. For example, the word ``{\em Jaguar}'' may correspond
 to a car, or a cat depending on the context of the document.
     In
 particular, the significance of a word can be interpreted only in
 terms of the structure of the data within the context of a
 particular data locality.  As a result, document-to-document similarity
 measures often lose their robustness. Thus, commonly used
 outlier analysis methods for multidimensional data, such as distance-based methods, are not
 particularly effective for text data. Our experiments also validate this observation. 

In this paper, we will
  use  non-negative matrix factorization (NMF) methods to  address the
  aforementioned challenges in text anomaly detection. One
  advantage of matrix factorization methods is that they decompose  the term-document
 structure of the underlying corpus into a set of semantic term clusters and document clusters.
 The semantic nature of this decomposition provides the  context in
 which a document may be interpreted for outlier analysis.
 Thus, documents can be decomposed into word clusters, and words are
 decomposed into document clusters with a low-rank\footnote{In this paper, we use  the terms  ``low rank
approximation'' and ``matrix factorization'' interchangeably.
Similarly, we used the terms  ``anomalies'' and ``outliers''
interchangeably.} approximation.
 Outliers are therefore defined as data points which cannot be
 naturally expressed in terms of this decomposition.
   By using carefully chosen model formulations,
 one can further sharpen the matrix-factorization method to reveal
 document-centric outliers. One  challenge in this case, is that the
 design of a matrix factorization approach, which is optimized to
 anomaly detection, results in a non-standard formulation.
 Therefore, we will design an optimization solution for this model.
 The NMF model also has the advantage of providing better
 interpretability, and it can also provide insights into why a
 document should be considered an outlier.   We present extensive
experimental results  on many   data sets, and compare against a
variety of baseline methods. We show significant improvements
achieved by the approach over a variety of other methods.

This paper is organized as follows. The remainder of this section
discusses the related work.  Section \ref{sec:model} introduces the
model for outlier analysis. The algorithm to solve  this model is
provided in section \ref{sec:algorithm}. Section
\ref{sec:experimentation} provides the experimental results. The
conclusions and summary are contained in section
\ref{sec:conclusion}. Our code can be downloaded from 
\url{https://github.com/ramkikannan/outliernmf} and 
tried with any text dataset. 
