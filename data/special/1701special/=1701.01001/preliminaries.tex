\subsection{Some notation and conventions}

We assume that all random variables are defined on a common probability space $(\Omega, \mathcal{F}, \prob)$. The set of natural numbers is denoted by $\nset = \{0, 1, 2, \ldots\}$, and we let $\nsetpos = \nset \setminus \{Ê0\}$ be the positive ones. For all $(m, n) \in \nset^2$, we set $\intvect{m}{n} \eqdef \{m, m + 1, \ldots, n\}$. The set of nonnegative real numbers is denoted by $\rset_+$. For any quantities $\{ a_\ell \}_{\ell = 1}^m$, vectors are denoted by $\chunk{a}{\ell}{m} \eqdef (a_\ell, \ldots, a_m)$. 

We introduce some measure and kernel notation. Given some state space $(\Esp, \Efd)$, we denote by $\bmf{\Efd}$ and $\probmeas{\Efd}$ the spaces of bounded measurable functions and probability measures on $(\Esp, \Efd)$, respectively. For any functions $(h, h') \in \bmf{\Efd}^2$ we define the product function $h \varotimes h' : \Esp^2 \ni (x, x') \mapsto h(x) h'(x')$. The identity function $x \mapsto x$ is denoted by $\operatorname{id}$. Let $\mu$ be a measure on $(\Esp, \Efd)$; then for any $\mu$-integrable function $h$, we denote by
$$
\mu h \eqdef \int h(x) \, \mu(\rmd x)
$$
the Lebesgue integral of $h$ w.r.t. $\mu$. In addition, let $(\Esp', \Efd')$ be some other measurable space and $\genkernel$ some possibly unnormalised transition kernel $\genkernel : \Esp \times \Efd' \rightarrow \rset_+$. The kernel $\genkernel$ induces two integral operators, one acting on functions and the other on measures. More specifically, given a measure $\nu$ on $(\Esp, \Efd)$ and a measurable function $h$ on $(\Esp', \Efd')$, we define the measure 
$$
    \nu \genkernel : \Efd' \ni A \mapsto \int \genkernel(x, A) \, \nu(\rmd x) 
$$
and the function 
$$
    \genkernel h : \Esp \ni x \mapsto \int h(y) \, \genkernel(x, \rmd y),
$$
whenever these quantities are well defined. 


\subsection{Randomly perturbed Feynman-Kac models} 
\label{sec:Feynman:Kac:models}
Let $(\Xsp, \Xfd)$ and $(\Zsp, \Zfd)$ be a pair of general measurable spaces. Moreover, let $\kernel{K}$ and $\init$ be a Markov transition kernel and a probability measure on $(\Xsp, \Xfd)$, respectively, and $\{ \pot[z] : z \in \Zsp \}$ a family of real-valued, positive, and measurable \emph{potential functions} on $(\Xsp, \Xfd)$. For  all vectors $\chunk{z}{k}{m} \in \Zsp^{m - k + 1}$, we define unnormalised transition kernels
$$
    \uk[\chunk{z}{k}{m}] : \Xsp \times \Xfd \ni (x_k, A) 
    \mapsto \idotsint \1_A(x_{m + 1}) \prod_{\ell = k}^m 
    \pot[z_\ell](x_\ell) \, \mk(x_\ell, \rmd x_{\ell + 1}),
$$
with the convention $\uk[\chunk{z}{k}{m}](x, A) = \delta_x(A)$ if $m < k$ (where $\delta_x$ denotes the Dirac mass located at $x$),  
and probability measures 
\begin{equation} \label{eq:def:pred}
    \pred[\chunk{z}{k}{m}] : \Xfd \ni A 
    \mapsto \frac{\init \uk[\chunk{z}{k}{m}] \1_A}
    {\init \uk[\chunk{z}{k}{m}] \1_\Xsp}. 
\end{equation}
Using these definitions we may, given a sequence $\{ z_n \}_{n \in \nset}$ of \emph{perturbations} in $\Zsp$, express the \emph{Feynman-Kac distribution flow} $\{ \pred[\chunk{z}{0}{n}] \}_{n \in \nset}$ recursively as 
\begin{equation} \label{eq:pred:rec}
    \pred[\chunk{z}{0}{n}] 
    = \frac{\pred[\chunk{z}{0}{n - 1}] \uk[z_n]}{\pred[\chunk{z}{0}{n - 1}]  \uk[z_n] \1_\Xsp}, \quad n \in \nset 
\end{equation}
(where, by the previous convention, $\pred[\chunk{z}{0}{- 1}] = \init$). Even though the previous model may be applied in a non-temporal context, we will often refer to the index $n$ as ``time''. 

\begin{example}[partially dominated state-space models] \label{example:state:space:model}
Let $(\Xsp, \Xfd)$ be a measurable space, $\hk : \Xsp \times \Xfd \rightarrow [0, 1]$ a Markov transition kernel, and $\init$ a probability measure on $(\Xsp, \Xfd)$ (the latter being referred to as the \emph{initial distribution}). In addition, let $(\Ysp, \Yfd)$ be another measurable space and $\ed : \Xsp \times \Ysp \rightarrow \rset_+$ a Markov transition density with respect to some reference measure $\refm$ on $(\Ysp, \Yfd)$. By a general state-space model we mean the canonical version of the bivariate Markov chain $\{ (X_n, Y_n) \}_{n \in \nset}$ having transition kernel 
$$
    \Xsp \times \Ysp \times \Xfd \varotimes \Yfd \ni ((x, y), A) \mapsto \iint \1_A(x', y') \ed(x', y') \, \refm(\rmd y') \, \hk(x, \rmd x')
$$
and initial distribution 
$$
    \Xfd \varotimes \Yfd \ni A \mapsto \iint \1_A(x, y) \ed(x, y) \, \refm(\rmd y) \, \init(\rmd x).  
$$ 
Here the marginal process $\{ X_n \}_{n \in \nset}$, referred to as the \emph{state process}, is only partially observed through the \emph{observation process} $\{ Y_n \}_{n \in \nset}$. For the model  $\{ (X_n, Y_n) \}_{n \in \nset}$ defined in this way, 
\begin{itemize}
    \item[(i)] the state process is a Markov chain with transition kernel $\mk$ and initial distribution $\init$, 
    \item[(ii)] the observations are, given the states, conditionally independent and such that the marginal conditional distribution of each $Y_n$ depends on $X_n$ only and has density $\pot(X_n, \cdot)$
\end{itemize}
(we refer to \cite[Section~2.2]{cappe:moulines:ryden:2005} for details). When operating on a well-specified state-space model, a key ingredient is typically the computation of the flow of \emph{predictor distributions}, where the predictor $\pred[\chunk{y}{0}{n - 1}]$ at time $n \in \nset$ is defined as the conditional distribution of the state $X_n$Ê given the record $\chunk{y}{0}{n - 1} \in \Ysp^n$ of realised historical observations up to time $n - 1$. Using Bayes' formula (see, e.g., \cite[Section~3.2.2]{cappe:moulines:ryden:2005} for details), it is straightforwardly shown that the predictor flow satisfies a perturbed Feynman-Kac recursion \eqref{eq:pred:rec} with $(\Xsp, \Xfd)$, $\hk$, and $\init$ given above, the observations $\{ Y_n \}_{n \in \nset}$ playing the role of perturbations (i.e., $\Zsp \gets \Ysp$ and $\Zfd \gets \Yfd$), and the local likelihood functions $\{Ê\ed(\cdot, y) : y \in \Ysp \}$ playing the role of potential functions $\{Ê\pot[y] : y \in \Ysp\}$. We will return to this framework in Section~\ref{sec:numerical:study}. 
\end{example}

\subsection{Sequential Monte Carlo methods}
SMC methods approximate online the Feynman-Kac flow generated by \eqref{eq:pred:rec} and a given sequence $\{ z_n \}_{n \in \nset}$ of perturbations by propagating recursively a random sample  $\{ \epart{n}{i} \}_{i = 1}^\N$ of $\Xsp$-valued \emph{particles}. More specifically, given a particle sample $\{ \epart{n}{i} \}_{i = 1}^\N$ \emph{targeting} $\pred[\chunk{z}{0}{n - 1}]$ in the sense that for all $h \in \bmf{\Xfd}$, $\predpart[\chunk{z}{0}{n - 1}] h \backsimeq \pred[\chunk{z}{0}{n - 1}] h$ as $\N$ tends to infinity, where  
$$
    \predpart[\chunk{z}{0}{n - 1}]: \Xfd \ni A \mapsto \frac{1}{\N} \sum_{i = 1}^\N \1_A(\epart{n}{i})
$$
denotes the empirical measure associated with the particles, an updated particle sample $\{ \epart{n + 1}{i} \}_{i = 1}^\N$ approximating $\pred[\chunk{z}{0}{n}]$ is, as the perturbation $z_n$ becomes accessible, formed by Algorithm~\ref{alg:SMC}. 

\bigskip
\begin{algorithm}[H] \label{alg:SMC}
    \KwData{$\{ \epart{n}{i} \}_{i = 1}^\N$, $z_n$}
    \KwResult{$\{ \epart{n + 1}{i} \}_{i = 1}^\N$}
    set $\wgtsum{n} \gets 0$\;
    \For{$i = 1 \to \N$}{
        set $\wgt{n}{i} \gets \pot[z_n](\epart{n}{i})$\;
        set $\wgtsum{n} \gets \wgtsum{n} + \wgt{n}{i}$\;
    }
    \For {$i = 1 \to \N$}{
        draw $\ind{n + 1}{i} \sim \cat(\{ \wgt{n}{\ell} / \wgtsum{n} \}_{\ell = 1}^N)$\;
        draw $\epart{n + 1}{i} \sim \mk(\epart{n}{\ind{n + 1}{i}}, \cdot)$\;
    }
    \caption{SMC particle update}
\end{algorithm}
\bigskip
(In the algorithm above, $\cat( \{ \wgt{n}{\ell} / \wgtsum{n} \}_{\ell = 1}^N)$ denotes the categorical distribution induced by the normalised particle weights $\{ \wgt{n}{\ell} / \wgtsum{n} \}_{\ell = 1}^N$.) Algorithm~\ref{alg:SMC} is initialised at time $n = 0$ by drawing $\{ \epart{0}{i} \}_{i = 1}^\N \sim \init^{\varotimes \N}$. For all $n \in \nset$ and all $h \in \bmf{\Xfd}$, the convergence, as $\N$ tends to infinity, of $\predpart[\chunk{z}{0}{n - 1}] h$ to $\pred[\chunk{z}{0}{n - 1}] h$ Êcan be established in several probabilistic senses. In particular, the first CLT for SMC methods was provided by \cite{delmoral:guionnet:1999}, establishing that 
\begin{equation} \label{eq:CLT}
\sqrt{\N} \left( \predpart[\chunk{z}{0}{n - 1}] h - \pred[\chunk{z}{0}{n - 1}] h \right) \dlim \variance{\chunk{z}{0}{n - 1}}(h) Z,  
\end{equation}
where $Z$ is standard normally distributed and the asymptotic variance is given by $\variance{\chunk{z}{0}{n - 1}} \eqdef \variance{\chunk{z}{0}{n - 1}}[0]$ with 
\begin{equation} \label{eq:def:as:var}
\variance[2]{\chunk{z}{0}{n - 1}}[\ell] : \bmf{\Xfd} \ni h \mapsto \sum_{m = \ell}^n \frac{\pred[\chunk{z}{0}{m - 1}] \{ \uk[\chunk{z}{m}{n - 1}](h - \pred[\chunk{z}{0}{n - 1}] h) \}^2 }{(\pred[\chunk{z}{0}{m - 1}] \uk[\chunk{z}{m}{n - 1}] \1_{\Xsp})^2}
\end{equation}
(see also \cite{chopin:2004,kuensch:2005,douc:moulines:2008} for similar results). The fact that we in \eqref{eq:def:as:var} define a truncated version of the variance with only $n - \ell + 1$ terms will be clear later on. In the coming section we propose a lag-based, numerically stable estimator of the sequence $\{ \variance[2]{\chunk{z}{0}{n - 1}} \}_{n \in \nset}$ of asymptotic variances. The estimator approximates $\{Ê\variance[2]{\chunk{z}{0}{n - 1}} \}_{n \in \nset}$ online, as $n$ increases, under constant computational complexity and memory requirements. Importantly, the estimator is obtained as a by-product of the particle filter output and does not require additional simulations. The numerical stability is obtained at the price of a small bias, which may be controlled under weak assumptions on the mixing properties of the model. 
