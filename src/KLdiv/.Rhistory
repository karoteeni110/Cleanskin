x_eig$values[783]
x_eig$values[780]
x_eig$values[78]
?order
x_eig <- eigen(cov(X))
largest <- order(x_eig$values,decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
largest
show_digit(matrix(large_vecs[1,], nrow=28))
show_digit(matrix(large_vecs[2,], nrow=28))
plot(matrix(large_vecs[1,], nrow=28))
plot(matrix(large_vecs[2,], nrow=28))
show_digit(matrix(large_vecs[1,], nrow=28))
show_digit(matrix(large_vecs[2,], nrow=28))
x_eig$values[1]
x_eig$values[2]
x_eig$values[3]
order(x_eig$values,decreasing=T)[1:5]
order(x_eig$values,decreasing=T)[1:9]
x_eig <- eigen(cov(X))
largest <- sort(table(x_eig$values),decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
largest
x_eig <- eigen(cov(X))
largest <- sort(x_eig$values,decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
largest
sort(x_eig$values,decreasing=T)[:5]
sort(x_eig$values,decreasing=T)[1:5]
order(x_eig$values,decreasing=T)[1:5]
x_eig$values[1:5]
x_eig <- eigen(cov(X))
x_eig$values[1:5]
x_eig$values[1:10]
x_eig$values[1:30]
nrows(cov(X))
nrow(cov(X))
ncol(cov(X))
large_vecs[1,]
?project
lower_X1 <- t(t(X) @ large_vecs[1,])
lower_X1 <- t(t(X) * large_vecs[1,])
lower_X2 <- t(t(X) * large_vecs[2,])
plot(lower_X1,lower_X2)
lower_X1 <- t(t(X) * large_vecs[1,])
lower_X2 <- t(t(X) * large_vecs[2,])
plot(lower_X1,lower_X2,  pch = 20, cex = .5, asp = 1, col = train$y+1)
?norm
lower_X1 <- t(t(X) * large_vecs[1,] / rep(sqrt(t(X) * large_vecs[1,]), 784))
length(t(X) * large_vecs[1,])
matult
?matmult
matmult(t(X),large_vecs[1,])
lower_X1 <- t(t(X) %*% large_vecs[1,] / rep(sqrt(t(X) * large_vecs[1,]), 784))
length(t(X) %*% large_vecs[1,])
length(t(X)
)
length(X)
length(X[1,])
plot(X, pch=19)
?plot
plot(X[,1],X[,2], pch=19)
plot(X[,1],X[,3], pch=19)
x_eig <- eigen(cov(X))
largest <- sort(x_eig$values,decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
large_vecs
x_eig <- eigen(cov(X))
largest <- sort(x_eig$values,decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
large_vecs[1,1:10]
large_vecs[2,10:10]
x_eig <- eigen(cov(X))
largest <- sort(x_eig$values,decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
large_vecs[1,1:10]
large_vecs[2,1:10]
largest
x_eig <- eigen(cov(X))
largest <- order(x_eig$values,decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
large_vecs[1,1:10]
large_vecs[2,1:10]
largest
x_eig <- eigen(cov(X))
largest <- order(x_eig$values,decreasing=T)[1:2]
large_vecs <- x_eig$vectors[largest,]
large_vecs[1,500:510]
large_vecs[2,500:510]
large_vecs[2,]
x_eig$vectors
x_eig$vectors[1]
x_eig$vectors[1,]
order(x_eig$values,decreasing=T)[1:2]
x_eig$vectors[1]
x_eig$vectors[1,]
x_eig$vectors[2,]
x_eig$vectors[9,]
View(x_eig)
x_eig
max.row(x_eig$values)[1:2]
?max.col
max(x_eig$values)
x_eig <- eigen(cov(X))
large_vecs <- x_eig$vectors[1:2,]
large_vecs[1,500:510]
large_vecs[2,500:510]
x_eig$vectors
x_eig$vectors[4]
which.max(x_eig$vectors)
which.min(x_eig$vectors)
lower_X1 <- t(t(X) %*% large_vecs[,1] / rep(sqrt(t(X) * large_vecs[1,]), 784))
lower_X1 <- t(t(X) %*% large_vecs[,1] / rep(sqrt(t(X) * large_vecs[,1]), 784))
lower_X1 <- t(t(X) * large_vecs[,1] / rep(sqrt(t(X) * large_vecs[,1]), 784))
lower_X1 <- t(t(X) * large_vecs[,1])
lower_X2 <- t(t(X) * large_vecs[,2])
plot(lower_X1,lower_X2, pch = 20, cex = .5, asp = 1, col = train$y+1)
lower_X1 <- t(t(X) * large_vecs[,1])
lower_X2 <- t(t(X) * large_vecs[,2])
data.frame(lower_X1, lower_X2)
plot(lower_X1,lower_X2, pch = 20, cex = .5, asp = 1, col = train$y)
source('loadmnist.r')
load_mnist()
train$n <- 5000
train$x <- train$x[1:train$n,]
train$y <- train$y[1:train$n]
test$n <- 1000
test$x <- test$x[1:test$n,]
test$y <- test$y[1:test$n]
library(proxy)
dists <- dist(train$x, test$x)
dists[1]
# Keep an accuracy table
acc <- rep(NA,50)
n <- test$n
for (k in 1:50) {
# initialize neighbors and the predicted class
nearest <- matrix(0, ncol = k, nrow = n)
knn.class <- rep(-1, n)
for (i in 1:n) {
# k nearest points; represented by points' idx in dataset
nearest[i,] <- order(dists[,i])[1:k]
# Sort the classes by decreasing frequency, and
# pick the most frequent labels
nearest_labels <- train$y[nearest[i,]]
knn.class[i] = names(sort(table(nearest_labels), decreasing=TRUE))[1]
}
# count the number of	correct classifications and divide it by test set size
acc[k] = sum(knn.class == test$y) / test$n
}
X <- train$x
X <- t(t(X) - rep(colMeans(X), train$n))
divide_by_sd <- function(colm) {
if (sd(colm) == 0) {sdd <- 1}
else {sdd <- sd(colm)}
colm <- colm/sdd
}
X <- apply(X,2,divide_by_sd)
diag(cov(X))
plot(X[,1],X[,3], pch=19)
x_eig <- eigen(cov(X))
large_vecs <- x_eig$vectors[1:2,]
show_digit(matrix(large_vecs[1,], nrow=28))
show_digit(matrix(large_vecs[2,], nrow=28))
lower_X1 <- t(t(X) * large_vecs[,1])
lower_X2 <- t(t(X) * large_vecs[,2])
plot(lower_X1,lower_X2, pch = 20, cex = .5, asp = 1, col = train$y+1)
?nnorm
?pnorm
?rnomr
?rnorm
samples <- rnorm(1000, mean=0,sd=10)
0 in samples
samples
0<=13 && 0>=9\
0<=13 && 0>=9
m <- 1000
n <- 100
mean_in_sample <- rep(0, m)
for (i in 1:m) {
samples <- rnorm(n, mean=0,sd=10)
xbar <- mean(samples)
ci <- 1.96*sd(samples)/sqrt(n)
if (0<=xbar+ci && 0>=xbar-ci) {mean_in_sample[i] <- 1}
}
sum(mean_in_sample) / m
?sample
D_j <- sample(samples, k, replace = T)
D_j
D_j <- sample(samples, 1000, replace = T)
D_j
?pnorm
?znorm
?z
m <- 1000
n <- 100
k <- 1000
mean_in_sample <- rep(0, m)
for (i in 1:m) {
samples <- rnorm(n, mean=0,sd=10)
D_j <- sample(samples, k, replace = T)
xbar <- mean(D_j)
ci <- 1.96*sd(D_j)/sqrt(k)
if (0<=xbar+ci && 0>=xbar-ci) {mean_in_sample[i] <- 1}
}
sum(mean_in_sample) / m
m <- 1000
n <- 100
k <- 1000
mean_in_sample <- rep(0, m)
for (i in 1:m) {
# samples <- rnorm(n, mean=0,sd=10)
D_j <- sample(samples, k, replace = T)
xbar <- mean(D_j)
ci <- 1.96*sd(D_j)/sqrt(k)
if (0<=xbar+ci && 0>=xbar-ci) {mean_in_sample[i] <- 1}
}
sum(mean_in_sample) / m
m <- 1000
n <- 100
k <- 1000
mean_in_sample <- rep(0, m)
for (i in 1:m) {
# samples <- rnorm(n, mean=0,sd=10)
D_j <- sample(samples, k, replace = T)
xbar <- mean(D_j)
ci <- 1.96*sd(D_j)/sqrt(k)
if (0<=xbar+ci && 0>=xbar-ci) {mean_in_sample[i] <- 1}
}
sum(mean_in_sample)
xbar
ci
m <- 1000
n <- 100
k <- 1000
mean_in_sample <- rep(0, m)
samples <- rnorm(n, mean=0,sd=10)
for (i in 1:m) {
D_j <- sample(samples, k, replace = T)
xbar <- mean(D_j)
ci <- 1.96*sd(D_j)/sqrt(k)
if (0<=xbar+ci && 0>=xbar-ci) {mean_in_sample[i] <- 1}
}
sum(mean_in_sample) / m
integer(0.8)
integer(0.9)
integer(1.9)
integer(3.9)
int(3.9)
library(ggplot2)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
abstract <- read.csv('../../data/100_1_fulltext_composition.txt', header=T)
abstract <- read.csv('100_1_fulltext_composition.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
abstract <- read.csv('100_1_abstract_composition.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("../../results/100kdata_200tp.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('100_1_abstract_composition.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_100tpc_abst_rank.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
abstract <- read.csv('100_1_abstract_composition.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
library(ggplot2)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
abstract <- read.csv('100_1_abstract_composition.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
abstract <- read.csv('100_1_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_100_1.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
dev.off()
library(ggplot2)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
abstract <- read.csv('100_130_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_100_130.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('70_130_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
?read.csv
abstract <- read.csv('50_130_kld.txt', header=T, re)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_50_130.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('10_130_kld.txt', header=T, re)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_10_130.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('50_130_kld.txt', header=T, re)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_50_130.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
View(abstract2)
View(abstract)
library(ggplot2)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
abstract <- read.csv('50_130_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_50_130.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('30_130_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_30_130.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5.5,7.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
View(abstract)
View(abstract2)
abstract <- read.csv('30_130_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_30_130.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5,6.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('30_13064_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_30_13064.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5,6.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('40_13064_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_40_13064.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5,6.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('50_13064_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_50_13064.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5,6.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('100_13064_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_100_13064.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5,6.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
intro<- read.csv('../../data/cs_kld/30_13064_introduction_kld.txt')
intro2<-summarySE(intro, measurevar = 'kld', groupvars = c('category')))
intro2<-summarySE(intro, measurevar = 'kld', groupvars = c('category'))
View(intro2)
abstract <- read.csv('./../data/cs_kld/30_13064_abalign_kld.txt', header=T)
abstract <- read.csv('../../data/cs_kld/30_13064_abalign_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_100_13064.pdf", h=7, w=6)
abstract <- read.csv('../../data/cs_kld/30_13064_abalign_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_30_13064_abalign.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(5,6.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('../../data/cs_kld/30_13064_abalign_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("gensim_30_13064_abalign.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(0.5,1.5)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
library(ggplot2)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
library(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
abstract <- read.csv('../../data/cs_kld/6kdoc_70x100/70x100_avg_kld.txt', header=T)
abstract <- read.csv('../../data/cs_kld/6kdoc_70x100/70x100_abstract_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
View(abstract2)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(1.0,2.0)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(0.5,2.0)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(0.7,1.7)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(0.8,1.8)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
abstract <- read.csv('../../data/cs_kld/6kdoc_70x100/70x100_abstract_kld.txt', header=T)
abstract2 <- summarySE(abstract, measurevar = 'kld', groupvars = c('category'))
pdf("70x100_avg.pdf", h=7, w=6)
ggplot(abstract2, aes(x=reorder(category, kld, FUN=mean), y=kld)) + geom_errorbar(aes(ymin=kld-ci, ymax=kld+ci)) + geom_point() + coord_flip() + ylab('KL divergence (bits)') + xlab('') + scale_y_continuous(limits=c(0.8,1.8)) + theme_bw()# ,breaks=c(2.0,2.2,2.4,2.6,2.8,3.0)) + theme_bw()
dev.off()
